{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster en Ciencia de Datos</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "## \n",
    "\n",
    "#### Alumnos: Xavier Ricci y Guillermo Monzón\n",
    "\n",
    "## PRÁCTICA 2:\n",
    "#### CONTENIDO  \n",
    "\n",
    "<div id='id00'/>\n",
    "\n",
    "\n",
    "[1. PRESENTACIÓN DE LA PRÁCTICA Y DESCRIPCIÓN DEL *DATASET*](#id1)\n",
    "\n",
    "[2. LIMPIEZA DE DATOS](#id2)\n",
    "\n",
    "   [2.1 Pclass](#id21)  \n",
    "   [2.2 Name](#id22)   \n",
    "   [2.3 Sex](#id23)  \n",
    "   [2.4 Sibsp](#id24)  \n",
    "   [2.5 Parch](#id25)   \n",
    "   [2.6 Age](#id26)  \n",
    "   [2.7 Fare](#id27)  \n",
    "   [2.8 Ticket](#id28)  \n",
    "   [2.9 Cabin](#id29)   \n",
    "   [2.10 Embarked](#id210)   \n",
    "     \n",
    "[3. ANÁLISIS DE LOS DATOS Y CONCLUSIONES](#id3)\n",
    "\n",
    "   [3.1. Modelos de regresión](#id31)    \n",
    "   [3.2. Combinación de modelos de regresión](#id32)  \n",
    "   [3.3. Modelo Neuronal](#id33)  \n",
    "   [3.4. Combinación de modelos neuronales](#id34)     \n",
    "\n",
    "* * * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id1'/> \n",
    "\n",
    "### [1. PRESENTACIÓN DE LA PRÁCTICA Y DESCRIPCIÓN DEL *DATASET* ](#id00)\n",
    "\n",
    "Hemos escogido estudiar el dataset del Titanic de kaggle.com, porque se trata de un reto en el que participan personas que se dedican al análisis de datos de todo el mundo y nos queríamos participar en este reto. Se trata de una forma de medir nuestras capacidades dentro de este mundo profesional, ya que, aunque esta es una competición para principiantes, en ella participan muchos profesionales y equipos de personas. \n",
    "Nuestro reto inicial, era conseguir estar dentro de la lista del 10% con mejores resultados de los 23 mil equipos participantes. Cabe destacar que, aunque la mayoría de personas en esta lista están participando con códigos propios, también hay muchas personas que utilizan métodos tramposos, ya sea simplemente copiando los resultados finales y consiguiendo un imposible 100% de aciertos o utilizando los códigos de otros con alto rendimiento. \n",
    "Es de lógica entender que en cualquier situación natural estamos hablando de probabilidades a partir de una cantidad limitada de datos. Aunque se tuvieran miles de datos de cada uno de los pasajeros del Titanic una hora antes del accidente, sería imposible predecir todas las circunstancias que llevan a la supervivencia de cada una de las personas. Los que resbalaron, los que decidieron ceder su asiente en un bote salvavidas, los que pisaron a otra persona para ocupar su lugar… son circunstancias impredecibles que no se pueden calcular a partir de una docena de características. \n",
    "Entendemos que a base de mandar resultados se puede ir ajustando las respuestas a las correctas, aunque eso no sería la creación de un modelo de predicción, sino una especie de proceso de descubrimiento de una clave, y este no es nuestro objetivo. \n",
    "A decir verdad, nuestra sensación es que solo con los datos originales, nos parece fantástico poder superar el 80% de aciertos. \n",
    "\n",
    "Para llevar a cabo este estudio, los responsables de Kaggle, nos ofrecen un listado de  891 personas con 11 características y el resultado de supervivencia o no de cada uno de ellos. A partir de estos datos se nos propone predecir la supervivencia de 418 pasajeros a partir de las mismas 11 caracteristicas. \n",
    " Para decidir los datos de interés a analizar entendemos que primero es necesario conocer los datos en profundidad y ver su estado, así, que empezamos directamente con el limpiado de los datos, para posteriormente decidir cuales son realmente útiles para nuestra predicción. \n",
    "\n",
    "Los atributos del dataset son los siguientes:  \n",
    "\n",
    "- **PassengerId:** \n",
    "- **Survived:** indicador de supervivencia (0 - sobrevive / 1 - muere).\n",
    "- **Pclass:** indicador de la clase del billete (1 - primera / 2 - segunda / 3 - tercera).\n",
    "- **Name:** nombre del pasajero.\n",
    "- **Sex:** sex (male - hombre  / female - mujer).\n",
    "- **Age**: edad en años (si es menor de un año se estima de forma fraccionaria).\n",
    "- **SibSp:** \n",
    "- **Parch:**\n",
    "- **Ticket:** número de ticket.\n",
    "- **Fare:** tarifa.\n",
    "- **Cabin:** número de camarote.\n",
    "- **Embarked:** puerto de embarque (C - Cherbourg / Q - Queenstown / S - Southamton).\n",
    "\n",
    "Así pues, una vez realizado un proceso de limpieza del conjunto de datos trataremos de determinar cómo pudo afectar a las posibilidades de superviviencia del pasaje del Titanic en función de sus caracterísitcas: edad, sexo, clase, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-98d25ab9fe53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as plot\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset import\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos ambos *datasets* para tener una visión conjunta de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unimos ambos datasets\n",
    "fullData = pd.concat([train, test], ignore_index=True, sort=False)\n",
    "fullData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1046 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "fullData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train NA</th>\n",
       "      <th>test NA</th>\n",
       "      <th>fullData NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Survived</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pclass</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Name</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sex</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>177</td>\n",
       "      <td>86.0</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cabin</td>\n",
       "      <td>687</td>\n",
       "      <td>327.0</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train NA  test NA  fullData NA\n",
       "PassengerId         0      0.0            0\n",
       "Survived            0      NaN          418\n",
       "Pclass              0      0.0            0\n",
       "Name                0      0.0            0\n",
       "Sex                 0      0.0            0\n",
       "Age               177     86.0          263\n",
       "SibSp               0      0.0            0\n",
       "Parch               0      0.0            0\n",
       "Ticket              0      0.0            0\n",
       "Fare                0      1.0            1\n",
       "Cabin             687    327.0         1014\n",
       "Embarked            2      0.0            2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData_NA = fullData.isna().sum()\n",
    "train_NA = train.isna().sum()\n",
    "test_NA = test.isna().sum()\n",
    "\n",
    "pd.concat([train_NA, test_NA, fullData_NA], axis=1, sort = False, keys = ['train NA', 'test NA', 'fullData NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que entre los datos hay muchos datos vacíos, especialmente en *Cabin* y en *Age*, también observamos 2 valores vacíos en *Embarked* y uno en *Fare*. Todos ellos serán tratados adecuadamente en el apartado de limpieza de datos.  \n",
    "\n",
    "También vemos que de las 11 atributos 2 son floats, 5 son integers y 5 son objetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vemos algunas distribuciones iniciales de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.616162\n",
       "1.0    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData['Survived'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un 62% de los pasajeros murieron mientras que un 38 % se salvaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e69a4688>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, podemos observar como un 63% de los pasajeros de PRIMERA CLASE sobrevivió al naufragio. Un 47 % para SEGUNDA CLASE y los que viajaban en TERCERA CLASE tan sólo sobrevivió un 24 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e6a97d88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se observa que las mujeres sobreviven significativamente más que los hombres.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion relacionamos algunas variables, para ver su importancia en la supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporando la **edad** a este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "soberviven = 'soberviven'\n",
    "mueren = 'mueren'\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
    "mujeres = fullData[fullData['Sex']=='female']\n",
    "hombres = fullData[fullData['Sex']=='male']\n",
    "ax = sns.distplot(mujeres[mujeres['Survived']==1].Age.dropna(), bins=18, label = soberviven, ax = axes[0], kde =False)\n",
    "ax = sns.distplot(mujeres[mujeres['Survived']==0].Age.dropna(), bins=40, label = mueren, ax = axes[0], kde =False)\n",
    "ax.legend()\n",
    "ax.set_title('Mujeres')\n",
    "ax = sns.distplot(hombres[hombres['Survived']==1].Age.dropna(), bins=18, label = soberviven, ax = axes[1], kde = False)\n",
    "ax = sns.distplot(hombres[hombres['Survived']==0].Age.dropna(), bins=40, label = mueren, ax = axes[1], kde = False)\n",
    "ax.legend()\n",
    "_ = ax.set_title('Hombres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los niños también tienen tasas de supervivencia muy superiores comparados con los adultos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra característica que podemos observar de un análisis previo de los datos es que lo pasajeros que embarcan en el puerto francés de Chebourg sobreviven de forma notoriamente superior a los pasajeros del resto de puertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked  Survived\n",
       "0        C  0.553571\n",
       "1        Q  0.389610\n",
       "2        S  0.336957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e6d8c948>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Embarked', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El puerto de de embarque también parece ser un factor importante a la hora de predecir la supervivencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id2'/>\n",
    "\n",
    "## [2. LIMPIEZA DE DATOS](#id00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la limpieza y ajuste de los datos vamos a ir tratando variable a variable del dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos eliminando las variables *PassengerId* y *Survived*, pues no aportan nada para el análisis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id21'/> \n",
    "\n",
    "### [2.1 Pclass](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullData[fullData['Pclass'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id22'/> \n",
    "\n",
    "### [2.2 Name](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullData[fullData['Name'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la varible *name* podemos determinar el titutlo que nos va a ser útil más adelante. Procedemos a extraer esta información. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData['Title'] = fullData.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(fullData['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              757\n",
       "Miss            260\n",
       "Mrs             197\n",
       "Master           61\n",
       "Dr                8\n",
       "Rev               8\n",
       "Col               4\n",
       "Ms                2\n",
       "Mlle              2\n",
       "Major             2\n",
       "Dona              1\n",
       "Don               1\n",
       "Jonkheer          1\n",
       "Lady              1\n",
       "Capt              1\n",
       "Sir               1\n",
       "the Countess      1\n",
       "Mme               1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Agunas notas sobre los títulos:\n",
    "\n",
    "Nobles: the Countess, lady is what you use to address someone of Nobility.  \n",
    "\n",
    "Mlle = Miss\n",
    "\n",
    "Madame = Mrs.  Usually, a servant (in Britain) addersses her Mistress as Madame.  But only if the mistress is married. \n",
    "\n",
    "\n",
    "Master = title for an underage male. If a person is under 18. En el caso del titanic todos los masters son de menos de 14.5 años. \n",
    "\n",
    "Colonel is a honorary title of conferred by several states in the US and certain military units of the Commonwealth of Nations.\n",
    "\n",
    "\n",
    "\"Ms\" is a recent term for those ladies who don't think anyone needs to know whether they are married or not, like the generic \n",
    "\n",
    "\n",
    "Jonkheer is an honorific in the Low Countries denoting the lowest rank within the nobility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que relación tienen con el índice de supervivencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " de 517, Mr sobreviven: 81, un 0.15667311411992263\n",
      " de 125, Mrs sobreviven: 99, un 0.792\n",
      " de 182, Miss sobreviven: 127, un 0.6978021978021978\n",
      " de 40, Master sobreviven: 23, un 0.575\n",
      " de 1, Don sobreviven: 0, un 0.0\n",
      " de 6, Rev sobreviven: 0, un 0.0\n",
      " de 7, Dr sobreviven: 3, un 0.42857142857142855\n",
      " de 1, Mme sobreviven: 1, un 1.0\n",
      " de 1, Ms sobreviven: 1, un 1.0\n",
      " de 2, Major sobreviven: 1, un 0.5\n",
      " de 1, Lady sobreviven: 1, un 1.0\n",
      " de 1, Sir sobreviven: 1, un 1.0\n",
      " de 2, Mlle sobreviven: 2, un 1.0\n",
      " de 2, Col sobreviven: 1, un 0.5\n",
      " de 1, Capt sobreviven: 0, un 0.0\n",
      " de 1, the Countess sobreviven: 1, un 1.0\n",
      " de 1, Jonkheer sobreviven: 0, un 0.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d14b9a26f04d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtitulos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitulo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtitulos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msobrevivenxtitulo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitulo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-d14b9a26f04d>\u001b[0m in \u001b[0;36msobrevivenxtitulo\u001b[1;34m(titulo)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtitulo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtitulo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\" de {(a+b)}, {titulo} sobreviven: {b}, un {b/(a+b)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtitulos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def sobrevivenxtitulo(titulo):\n",
    "    a=(len(fullData[(fullData['Survived']==0) & (fullData['Title']==titulo)]))\n",
    "    b=(len(fullData[(fullData['Survived']==1) & (fullData['Title']==titulo)]))\n",
    "    print(f\" de {(a+b)}, {titulo} sobreviven: {b}, un {b/(a+b)}\")\n",
    "\n",
    "titulos = pd.unique(fullData['Title'])\n",
    "for titulo in titulos:\n",
    "    sobrevivenxtitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos datos esperamos extraer la importancia de la clase y la profesion, para poderlos agrupar en conjuntos más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observamos los siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los hombres:\n",
    "\n",
    "Sr (Adultos en general): Con muy poco indice de supervivencia. Apenas el 15% sobreviven.\n",
    "\n",
    "Master (Jovenes): Aunque a primera vista parecia que Master podia referirse a la clase social aparte de a la edad comprobamos a continuacion que simplemente se refiere a los menores de 15 anyos. De los jovenes el 57% sobreviven\n",
    "\n",
    "Reverendos: Vemos que todos mueren (6 de 6 ya empieza a ser un valor interesante) 0% sobreviven\n",
    "\n",
    "Doctores: 2 de 6 el 33% sobreviven\n",
    "\n",
    "Major, Col y Capt (Militares) vemos que los rangos militares sobreviven en un 3/5, un 60% sobreviven\n",
    "\n",
    "Los nobles: Sir, Don y Jonkheer 1/3 baja al 33.3% sobreviven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las mujeres:\n",
    "\n",
    "Mrs y Mme (Casadas): Con muy alto indice de supervivencia del 79% sobreviven\n",
    "\n",
    "Miss y Mille (Solteras 0 y 63 años): 69% sobreviven\n",
    "\n",
    "El resto son muy pocos casos para generalizar pero vemos que una doctora sobrevive y que la Lady y la Countess sobreviven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                          Name     Sex  \\\n",
       "1304         1305       NaN       3            Spector, Mr. Woolf    male   \n",
       "1305         1306       NaN       1  Oliva y Ocana, Dona. Fermina  female   \n",
       "1306         1307       NaN       3  Saether, Mr. Simon Sivertsen    male   \n",
       "1307         1308       NaN       3           Ware, Mr. Frederick    male   \n",
       "1308         1309       NaN       3      Peter, Master. Michael J    male   \n",
       "\n",
       "       Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "1304   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "1305  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "1306  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "1307   NaN      0      0              359309    8.0500   NaN        S  \n",
       "1308   NaN      1      1                2668   22.3583   NaN        C  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset import\n",
    "dataTrainXY = pd.read_csv(\"./train.csv\")\n",
    "dataTestX = pd.read_csv(\"./test.csv\")\n",
    "frames = [dataTrainXY,dataTestX]\n",
    "DF = pd.concat(frames, ignore_index=True, sort=False)\n",
    "DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulo = DF.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "len(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309\n",
      "['Mr' 'Mrs' 'Miss' 'Master' 'Arist' 'Rev' 'Dr' 'Army']\n"
     ]
    }
   ],
   "source": [
    "#Los valores originales:  'Mr', 'Mrs', 'Miss', 'Master', 'Don','Sir','Jonkheer','Major', 'Capt', 'Col', 'Rev', 'Dr', 'Mme', 'Ms', 'Mlle', 'Lady',    'the Countess']\n",
    "\n",
    "# Las agrupaciones propuestas:\n",
    "# Major, Col y Capt = Militares\n",
    "# Sir, Don, Jonkheer, Lady y Countess  = Aristocratas\n",
    "# Mrs y Mme (Casadas)\n",
    "# Miss y Mlle (Solteras) tb incluyo Ms (porque entiendo que se trata de mujeres solas que querian evitar la presion social de no estar casadas)\n",
    "\n",
    "lista = []\n",
    "for word in titulo:\n",
    "    if word == 'Don':\n",
    "        lista.append('Arist')\n",
    "    elif word =='Sir':\n",
    "        lista.append('Arist')\n",
    "    elif word =='Jonkheer':\n",
    "        lista.append('Arist')\n",
    "    \n",
    "    elif word == 'Major':\n",
    "        lista.append('Army')\n",
    "    elif word =='Col':\n",
    "        lista.append('Army')\n",
    "    elif word =='Capt':\n",
    "        lista.append('Army')\n",
    "            \n",
    "        \n",
    "    elif word =='Mme':\n",
    "        lista.append('Mrs')      \n",
    "        \n",
    "    elif word =='Mlle':\n",
    "        lista.append('Miss')      \n",
    "        \n",
    "    elif word =='Ms':\n",
    "        lista.append('Miss')  \n",
    "        \n",
    "    elif word == 'Lady':\n",
    "        lista.append('Arist')\n",
    "    elif word == 'the Countess':\n",
    "        lista.append('Arist')\n",
    "    elif word == 'Dona':\n",
    "        lista.append('Arist')\n",
    "          \n",
    "    else:\n",
    "        lista.append(word)\n",
    "print(len(lista))\n",
    "print(pd.unique(lista))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>Arist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                          Name     Sex  \\\n",
       "1304         1305       NaN       3            Spector, Mr. Woolf    male   \n",
       "1305         1306       NaN       1  Oliva y Ocana, Dona. Fermina  female   \n",
       "1306         1307       NaN       3  Saether, Mr. Simon Sivertsen    male   \n",
       "1307         1308       NaN       3           Ware, Mr. Frederick    male   \n",
       "1308         1309       NaN       3      Peter, Master. Michael J    male   \n",
       "\n",
       "       Age  SibSp  Parch              Ticket      Fare Cabin Embarked   Title  \n",
       "1304   NaN      0      0           A.5. 3236    8.0500   NaN        S      Mr  \n",
       "1305  39.0      0      0            PC 17758  108.9000  C105        C   Arist  \n",
       "1306  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S      Mr  \n",
       "1307   NaN      0      0              359309    8.0500   NaN        S      Mr  \n",
       "1308   NaN      1      1                2668   22.3583   NaN        C  Master  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['Title'] = lista\n",
    "DF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos la edad máxima de los *Master* y nos aseguramos que no haya niños no *Master*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(DF[DF['Title']==\"Master\"].Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Goodwin, Mr. Charles Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 2144</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Panula, Mr. Jaako Arnold</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3101295</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>731</td>\n",
       "      <td>732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hassan, Mr. Houssein G N</td>\n",
       "      <td>male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2699</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1121</td>\n",
       "      <td>1122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Sweet, Mr. George Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220845</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                         Name   Sex   Age  \\\n",
       "683           684       0.0       3  Goodwin, Mr. Charles Edward  male  14.0   \n",
       "686           687       0.0       3     Panula, Mr. Jaako Arnold  male  14.0   \n",
       "731           732       0.0       3     Hassan, Mr. Houssein G N  male  11.0   \n",
       "896           897       NaN       3   Svensson, Mr. Johan Cervin  male  14.0   \n",
       "1121         1122       NaN       2  Sweet, Mr. George Frederick  male  14.0   \n",
       "\n",
       "      SibSp  Parch   Ticket     Fare Cabin Embarked Title  \n",
       "683       5      2  CA 2144  46.9000   NaN        S    Mr  \n",
       "686       4      1  3101295  39.6875   NaN        S    Mr  \n",
       "731       0      0     2699  18.7875   NaN        C    Mr  \n",
       "896       0      0     7538   9.2250   NaN        S    Mr  \n",
       "1121      0      0   220845  65.0000   NaN        S    Mr  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos a estos niños en *Master* para unificar el criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\") , \"Title\" ] = 'Master'\n",
    "DF[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\")]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id23'/> \n",
    "\n",
    "### [2.3 Sex](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Sex* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Sex\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id24'/> \n",
    "\n",
    "### [2.4 SibSp](#id00)\n",
    "Número de hermanos / esposas-maridos a bordo. 0 si se viajaba solo.  \n",
    "Definición en el dataset:  \n",
    " *Sibling = brother, sister, stepbrother, stepsister\n",
    " *Spouse = husband, wife (mistresses and fiancés were ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Sibsp* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"SibSp\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id25'/> \n",
    "\n",
    "### [2.5 Parch](#id00)\n",
    "Número de padres / niños. 0 si se viajaba soloo niños con nanny.\n",
    "\n",
    "Definición en el dataset:  \n",
    " *Parent = mother, father\n",
    " *Child = daughter, son, stepdaughter, stepson\n",
    " *Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Parch* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Parch\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id26'/> \n",
    "\n",
    "### [2.6 Age](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La problemática de la variable *Age*, como hemos visto en el apartado de anterior, estriba en que tiene un número elevado de valores perdidos, 263 concretamente. A continuación procedemos a resolver esta problemática asignando un valor para cada uno de los registros desconocidos de la variable edad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rellenar los datos vacios con la máxima precisión posible, los agrupamos según el titulo par ver si existe alguna relación entre este y la edad, como hemos visto que sucedia con los *Master*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana de edad de los 576 Mr con Age es de 29.0. Faltan: 176 \n",
      "La mediana de edad de los 171 Mrs con Age es de 35.0. Faltan: 27 \n",
      "La mediana de edad de los 213 Miss con Age es de 22.0. Faltan: 51 \n",
      "La mediana de edad de los 58 Master con Age es de 6.0. Faltan: 8 \n",
      "La mediana de edad de los 6 Arist con Age es de 39.5. Faltan: 0 \n",
      "La mediana de edad de los 8 Rev con Age es de 41.5. Faltan: 0 \n",
      "La mediana de edad de los 7 Dr con Age es de 49.0. Faltan: 1 \n",
      "La mediana de edad de los 7 Army con Age es de 53.0. Faltan: 0 \n"
     ]
    }
   ],
   "source": [
    "def VerEdadXTitulo(titulo):\n",
    "    medianaDeEdad = np.median(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    conEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    sinEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].isna())])\n",
    "    \n",
    "    print(f\"La mediana de edad de los {conEdad} {titulo} con Age es de {medianaDeEdad}. Faltan: {sinEdad} \")\n",
    "    \n",
    "for titulo in (pd.unique(DF.Title)):\n",
    "    VerEdadXTitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que efecticamente los titulos estan relacionados con la edad. Así que utilizamos esta referencia para rellenar los datos.\n",
    "Primero corregimos los que hay menos casos: *Dr* y *Master*, asignándoles la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[(DF['Title']=='Master') & (DF[\"Age\"].isna()), \"Age\" ] = np.median(DF[(DF['Title']=='Master') & (DF[\"Age\"].notnull())]['Age'])\n",
    "DF[(DF['Title']=='Master') & (DF[\"Age\"].isna())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[(DF['Title']=='Dr') & (DF[\"Age\"].isna()), \"Age\" ] = np.median(DF[(DF['Title']=='Dr') & (DF[\"Age\"].notnull())]['Age'])\n",
    "DF[(DF['Title']=='Dr') & (DF[\"Age\"].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las edades no registradas de pasajeros con los títulos de Mr, Mrs y Miss aplicaremos una regresion lineal, a partir de las variables *Pclass*, *Fare* y *Family*. Esta última la crearemos a partir de las variables *SibSP* y *Parch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la nueva variable *Family*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Title  Family  \n",
       "0      0         A/5 21171   7.2500   NaN        S    Mr       1  \n",
       "1      0          PC 17599  71.2833   C85        C   Mrs       1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Miss       0  \n",
       "3      0            113803  53.1000  C123        S   Mrs       1  \n",
       "4      0            373450   8.0500   NaN        S    Mr       0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['Family'] = DF.SibSp + DF.Parch\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder hacer la regresion nos aseguramos primero de que no hay elementos vacios en las columnas que utilizaremos para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Pclass\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Family\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Fare\"].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1043</td>\n",
       "      <td>1044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                Name   Sex   Age  SibSp  \\\n",
       "1043         1044       NaN       3  Storey, Mr. Thomas  male  60.5      0   \n",
       "\n",
       "      Parch Ticket  Fare Cabin Embarked Title  Family  \n",
       "1043      0   3701   NaN   NaN        S    Mr       0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[DF[\"Fare\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para completar este valor vacío en el precio del billete, utilizaremos la mediana del precio de pasajeros con las mismas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title, Family]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianaPrecio = np.median(DF[(DF['Title']==\"Mr\") &   (DF['Pclass']==3)  &  (DF['Fare'].notnull()) &  (DF['Sex']=='male') & (DF[\"Embarked\"]=='S') & (DF[\"SibSp\"]== 0)& (DF[\"Parch\"]== 0)]['Fare'])\n",
    "\n",
    "DF.loc[((DF['Title']==\"Mr\") &   (DF['Pclass']==3)  &  (DF['Fare'].isna()) &  (DF['Sex']=='male') & (DF[\"Embarked\"]=='S') & (DF[\"SibSp\"]== 0)& (DF[\"Parch\"]== 0)) , \"Fare\" ] = medianaPrecio\n",
    "\n",
    "DF[DF[\"Fare\"].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos aplicar la regresión lineal y asignar la edad calculada a cada uno de los pasajeros correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#creamos un grupo segun el titulo con la edad sabida Known Age\n",
    "def RegresionEdad(Titulo):\n",
    "    KA = DF[(DF['Title']==Titulo) & (DF[\"Age\"].notnull())]\n",
    "\n",
    "\n",
    "    X = KA[['Pclass','Family','Fare']]\n",
    "    Y = KA['Age']\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X, Y)\n",
    "    print(clf.coef_)\n",
    "    print(clf.intercept_)\n",
    "\n",
    "    #creamos un grupo segun el titulo con la edad desconocida Unknown Age\n",
    "    UA = DF[(DF['Title']==Titulo) & (DF[\"Age\"].isna())]\n",
    "    X = UA[['Pclass', 'Family','Fare']]\n",
    "    Y=clf.predict(X)\n",
    "    p=0\n",
    "    for y in Y:\n",
    "        if y < 0:\n",
    "            Y[p]=0.555\n",
    "        p=p+1\n",
    "    print(Y)\n",
    "\n",
    "    DF.loc[((DF['Title']==Titulo) & (DF[\"Age\"].isna())) , \"Age\" ] = Y\n",
    "\n",
    "    print(len(DF[(DF['Title']==Titulo) & (DF[\"Age\"].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.42693337  0.30766258 -0.00930572]\n",
      "47.346634588984955\n",
      "[27.98712391 34.3717935  27.99860065 27.99235838 27.99856157 27.99235838\n",
      " 27.99092344 28.2292584  28.47941908 40.58934818 40.66173923 27.99235838\n",
      " 27.99092344 27.99092344 27.99092344 27.99235838 27.99348251 27.99092344\n",
      " 27.99371515 27.9977864  27.98522368 40.67845044 34.35271677 40.45441525\n",
      " 27.99371515 30.49524746 28.30137773 27.99235838 27.99836801 27.99371515\n",
      " 40.63122392 34.49276785 40.67775251 40.66173923 40.63587678 28.46480166\n",
      " 27.99092344 30.49524746 27.99235838 40.59400104 27.99860065 28.2292584\n",
      " 27.99235838 27.99390871 27.99235838 28.00201306 34.49276785 27.99235838\n",
      " 27.99836801 27.99371515 27.99034183 28.18769255 27.99092344 27.99371515\n",
      " 27.99092344 34.49276785 27.99394779 27.99836801 40.43580381 34.49276785\n",
      " 28.18769255 27.93128959 27.92531811 40.67263437 27.99092344 27.84110135\n",
      " 27.99860065 27.99856157 38.85588622 27.99856157 27.93090155 34.36376731\n",
      " 27.99297814 38.80241742 27.99371515 27.99092344 27.99856157 27.9847584\n",
      " 27.99092344 27.99860065 27.99235838 40.52513872 28.00022916 27.99371515\n",
      " 27.99387056 40.91970122 28.22367497 27.54010042 27.9955763  27.99235838\n",
      " 27.99235838 27.99348251 34.49276785 27.54010042 40.67263437 27.92159583\n",
      " 34.49276785 27.99235838 27.99235838 40.64052964 27.93090155 28.14876393\n",
      " 27.99860065 27.99371515 27.99383147 28.77060309 27.99371515 40.63405472\n",
      " 40.91970122 28.00115973 27.54010042 27.99371515 27.99856157 27.99092344\n",
      " 40.64332135 30.49524746 27.99856157 27.97743014 27.99235838 27.99235838\n",
      " 28.47941908 27.54010042 40.67263437 27.99371515 34.34779218 28.22367497\n",
      " 27.99092344 27.99235838 34.39311941 28.23899032 27.99348251 27.99092344\n",
      " 27.99371515 27.99371515 27.9847584  28.00592891 28.30137773 27.99371515\n",
      " 28.31359149 40.43708335 40.67263437 27.99235838 28.00069444 27.9955763\n",
      " 27.99856157 27.99371515 40.67775251 40.68015618 28.00022916 27.99092344\n",
      " 27.99251285 27.99243562 27.9955763  27.99371515 27.99235838 40.91970122\n",
      " 27.9955763  27.99371515 27.99860065 27.99836801 27.99856157 27.99092344\n",
      " 40.55119473 27.99856157 28.47941908 34.35275585 27.99534365 27.99860065\n",
      " 30.49524746 27.99251285 27.99371515 28.23895217 27.99371515 34.37295671\n",
      " 27.99092344 27.99092344]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "RegresionEdad(\"Mr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.74769791  0.66373108  0.02333152]\n",
      "43.65725666172304\n",
      "[29.58273318 42.991843   31.09733281 40.8565235  30.4395326  40.75741524\n",
      " 42.69154765 30.45353151 29.58283117 41.4904596  29.60198169 30.45353151\n",
      " 40.78332086 31.26327825 30.41522815 40.78652894 41.65222637 39.64877834\n",
      " 31.95248035 34.65182279 32.66326411 39.55632719 29.60343991 31.09733281\n",
      " 30.41513249 37.67418104 29.75247   ]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "RegresionEdad(\"Mrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.30362954 -3.24208237  0.02215794]\n",
      "33.80173248648246\n",
      "[21.06543066 21.06256786 21.06256786 21.06339878 18.18387563 14.90209289\n",
      "  0.555      21.06256786  8.48680388 21.05813627 17.96903672 17.99220949\n",
      " 21.06256786 21.06256786 21.06256786 25.4681239  31.95504792 14.92185112\n",
      " 21.06543066 21.06543066 21.06256786  8.48680388  8.48680388 21.05989118\n",
      " 21.06921524 21.06256786 14.57840312 25.92568526 17.99220949 21.06432277\n",
      " 21.07115406 21.06219782 21.06229088  0.555       0.555      11.68420034\n",
      " 21.06921524 21.06256786 21.06321487 14.92185112 21.06219782  0.555\n",
      " 21.23429185 21.06543066 21.06256786 21.06921524 17.99220949 21.06256786\n",
      " 21.06256786 21.06192085 21.06256786]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "RegresionEdad(\"Miss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a hacer un último ajuste sobre la variable *Title*. De forma que tengamos la correspondiente equivalencia femenina para el valor *Master*. A estos valores los clasificaremos como *Girl*\n",
    "\n",
    "De igual modo vamos a crear una separación para los pasajeros mayores de 60. Clasificándolos como *MrSenior* para los hombres mayores de 60 años y *MrSSenior* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.065431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>21.062568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1291</td>\n",
       "      <td>1292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Caroline</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36928</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1293</td>\n",
       "      <td>1294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Gibson, Miss. Dorothy Winifred</td>\n",
       "      <td>female</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112378</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1299</td>\n",
       "      <td>1300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Riordan, Miss. Johanna Hannah\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.061921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334915</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1301</td>\n",
       "      <td>1302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Naughton, Miss. Hannah</td>\n",
       "      <td>female</td>\n",
       "      <td>21.062568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365237</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1303</td>\n",
       "      <td>1304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Henriksson, Miss. Jenny Lovisa</td>\n",
       "      <td>female</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347086</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                             Name     Sex  \\\n",
       "2               3       1.0       3           Heikkinen, Miss. Laina  female   \n",
       "11             12       1.0       1         Bonnell, Miss. Elizabeth  female   \n",
       "22             23       1.0       3      McGowan, Miss. Anna \"Annie\"  female   \n",
       "28             29       1.0       3    O'Dwyer, Miss. Ellen \"Nellie\"  female   \n",
       "32             33       1.0       3         Glynn, Miss. Mary Agatha  female   \n",
       "...           ...       ...     ...                              ...     ...   \n",
       "1291         1292       NaN       1          Bonnell, Miss. Caroline  female   \n",
       "1293         1294       NaN       1   Gibson, Miss. Dorothy Winifred  female   \n",
       "1299         1300       NaN       3  Riordan, Miss. Johanna Hannah\"\"  female   \n",
       "1301         1302       NaN       3           Naughton, Miss. Hannah  female   \n",
       "1303         1304       NaN       3   Henriksson, Miss. Jenny Lovisa  female   \n",
       "\n",
       "            Age  SibSp  Parch            Ticket      Fare Cabin Embarked  \\\n",
       "2     26.000000      0      0  STON/O2. 3101282    7.9250   NaN        S   \n",
       "11    58.000000      0      0            113783   26.5500  C103        S   \n",
       "22    15.000000      0      0            330923    8.0292   NaN        Q   \n",
       "28    21.065431      0      0            330959    7.8792   NaN        Q   \n",
       "32    21.062568      0      0            335677    7.7500   NaN        Q   \n",
       "...         ...    ...    ...               ...       ...   ...      ...   \n",
       "1291  30.000000      0      0             36928  164.8667    C7        S   \n",
       "1293  22.000000      0      1            112378   59.4000   NaN        C   \n",
       "1299  21.061921      0      0            334915    7.7208   NaN        Q   \n",
       "1301  21.062568      0      0            365237    7.7500   NaN        Q   \n",
       "1303  28.000000      0      0            347086    7.7750   NaN        S   \n",
       "\n",
       "     Title  Family  \n",
       "2     Miss       0  \n",
       "11    Miss       0  \n",
       "22    Miss       0  \n",
       "28    Miss       0  \n",
       "32    Miss       0  \n",
       "...    ...     ...  \n",
       "1291  Miss       0  \n",
       "1293  Miss       1  \n",
       "1299  Miss       0  \n",
       "1301  Miss       0  \n",
       "1303  Miss       0  \n",
       "\n",
       "[202 rows x 14 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[((DF[\"Age\"]<15)&(DF[\"Title\"]==\"Miss\")) , \"Title\" ] = 'Girl'\n",
    "DF[(DF[\"Title\"]==\"Miss\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[((DF[\"Age\"]>60)&(DF[\"Title\"]==\"Mr\")) , \"Title\" ] = 'MrSenior'\n",
    "len(DF[(DF[\"Title\"]==\"MrSenior\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[((DF[\"Age\"]>60)&(DF[\"Title\"]==\"Mrs\")) , \"Title\" ] = 'MrSSenior'\n",
    "len(DF[(DF[\"Title\"]==\"MrSSenior\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e6f93ec8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recapitulando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana de edad de los 727 Mr con Age es de 28.0. Faltan: 0 \n",
      "La mediana de edad de los 192 Mrs con Age es de 34.82591139706831. Faltan: 0 \n",
      "La mediana de edad de los 202 Miss con Age es de 22.0. Faltan: 0 \n",
      "La mediana de edad de los 66 Master con Age es de 6.0. Faltan: 0 \n",
      "La mediana de edad de los 62 Girl con Age es de 5.0. Faltan: 0 \n",
      "La mediana de edad de los 6 Arist con Age es de 39.5. Faltan: 0 \n",
      "La mediana de edad de los 25 MrSenior con Age es de 64.0. Faltan: 0 \n",
      "La mediana de edad de los 8 Rev con Age es de 41.5. Faltan: 0 \n",
      "La mediana de edad de los 8 Dr con Age es de 49.0. Faltan: 0 \n",
      "La mediana de edad de los 7 Army con Age es de 53.0. Faltan: 0 \n",
      "La mediana de edad de los 6 MrSSenior con Age es de 63.5. Faltan: 0 \n"
     ]
    }
   ],
   "source": [
    "def VerEdadXTitulo(titulo):\n",
    "    medianaDeEdad = np.median(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    conEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    sinEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].isna())])\n",
    "    \n",
    "    print(f\"La mediana de edad de los {conEdad} {titulo} con Age es de {medianaDeEdad}. Faltan: {sinEdad} \")\n",
    "    \n",
    "for titulo in (pd.unique(DF.Title)):\n",
    "    VerEdadXTitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id27'/> \n",
    "\n",
    "### [2.7 Fare](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos podido observar que hay un grupo de personas que no pagan el billete y que en la variable Ticket aparece la anotación LINE. En general son hombres que viajan solos y embarcaron en el puerto de Southamton y que en su mayoria murieron (al margen de la clase en que viajaran). Se podría deducir de ello que se trata de personas con alguna relacion especial con la compañía propietaria del barco. Se opta por identficarles como Empleados en la variable Title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Parkes, Mr. Francis \"Frank\"</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Campbell, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Frost, Mr. Anthony Wood \"Archie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>633</td>\n",
       "      <td>634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Parr, Mr. William Henry Marsh</td>\n",
       "      <td>male</td>\n",
       "      <td>40.919701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>732</td>\n",
       "      <td>733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Knight, Mr. Robert J</td>\n",
       "      <td>male</td>\n",
       "      <td>34.492768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815</td>\n",
       "      <td>816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>40.919701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>822</td>\n",
       "      <td>823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Reuchlin, Jonkheer. John George</td>\n",
       "      <td>male</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Arist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1157</td>\n",
       "      <td>1158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Chisholm, Mr. Roderick Robert Crispin</td>\n",
       "      <td>male</td>\n",
       "      <td>40.919701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1263</td>\n",
       "      <td>1264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Ismay, Mr. Joseph Bruce</td>\n",
       "      <td>male</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B52 B54 B56</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass                                   Name  \\\n",
       "179           180       0.0       3                    Leonard, Mr. Lionel   \n",
       "263           264       0.0       1                  Harrison, Mr. William   \n",
       "271           272       1.0       3           Tornquist, Mr. William Henry   \n",
       "277           278       0.0       2            Parkes, Mr. Francis \"Frank\"   \n",
       "302           303       0.0       3        Johnson, Mr. William Cahoone Jr   \n",
       "413           414       0.0       2         Cunningham, Mr. Alfred Fleming   \n",
       "466           467       0.0       2                  Campbell, Mr. William   \n",
       "481           482       0.0       2       Frost, Mr. Anthony Wood \"Archie\"   \n",
       "597           598       0.0       3                    Johnson, Mr. Alfred   \n",
       "633           634       0.0       1          Parr, Mr. William Henry Marsh   \n",
       "674           675       0.0       2             Watson, Mr. Ennis Hastings   \n",
       "732           733       0.0       2                   Knight, Mr. Robert J   \n",
       "806           807       0.0       1                 Andrews, Mr. Thomas Jr   \n",
       "815           816       0.0       1                       Fry, Mr. Richard   \n",
       "822           823       0.0       1        Reuchlin, Jonkheer. John George   \n",
       "1157         1158       NaN       1  Chisholm, Mr. Roderick Robert Crispin   \n",
       "1263         1264       NaN       1                Ismay, Mr. Joseph Bruce   \n",
       "\n",
       "       Sex        Age  SibSp  Parch  Ticket  Fare        Cabin Embarked  \\\n",
       "179   male  36.000000      0      0    LINE   0.0          NaN        S   \n",
       "263   male  40.000000      0      0  112059   0.0          B94        S   \n",
       "271   male  25.000000      0      0    LINE   0.0          NaN        S   \n",
       "277   male  34.492768      0      0  239853   0.0          NaN        S   \n",
       "302   male  19.000000      0      0    LINE   0.0          NaN        S   \n",
       "413   male  34.492768      0      0  239853   0.0          NaN        S   \n",
       "466   male  34.492768      0      0  239853   0.0          NaN        S   \n",
       "481   male  34.492768      0      0  239854   0.0          NaN        S   \n",
       "597   male  49.000000      0      0    LINE   0.0          NaN        S   \n",
       "633   male  40.919701      0      0  112052   0.0          NaN        S   \n",
       "674   male  34.492768      0      0  239856   0.0          NaN        S   \n",
       "732   male  34.492768      0      0  239855   0.0          NaN        S   \n",
       "806   male  39.000000      0      0  112050   0.0          A36        S   \n",
       "815   male  40.919701      0      0  112058   0.0         B102        S   \n",
       "822   male  38.000000      0      0   19972   0.0          NaN        S   \n",
       "1157  male  40.919701      0      0  112051   0.0          NaN        S   \n",
       "1263  male  49.000000      0      0  112058   0.0  B52 B54 B56        S   \n",
       "\n",
       "      Title  Family  \n",
       "179      Mr       0  \n",
       "263      Mr       0  \n",
       "271      Mr       0  \n",
       "277      Mr       0  \n",
       "302      Mr       0  \n",
       "413      Mr       0  \n",
       "466      Mr       0  \n",
       "481      Mr       0  \n",
       "597      Mr       0  \n",
       "633      Mr       0  \n",
       "674      Mr       0  \n",
       "732      Mr       0  \n",
       "806      Mr       0  \n",
       "815      Mr       0  \n",
       "822   Arist       0  \n",
       "1157     Mr       0  \n",
       "1263     Mr       0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[DF[\"Fare\"]<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Fare\"]<1), \"Title\" ] = 'Empleados'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, para no distorsionar la variable *Fare* se decide asignarles,en este caso, el valor de la media de la variable *Fare* según la clase a la que pertenezcan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==1), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==1)][\"Fare\"])\n",
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==2), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==2)][\"Fare\"])\n",
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==3), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==3)][\"Fare\"])\n",
    "#DF[DF[\"Title\"]==\"Empleados\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e6d5ca08>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez eliminado el precio ilógico de 0, vemos que hay un outlayer entre los precios altos, lo analizamos y lo justamos a los siguientes precios más elevados para evitar que se distorsione el analisis general de este dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>679</td>\n",
       "      <td>680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>737</td>\n",
       "      <td>738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1234</td>\n",
       "      <td>1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "258           259       1.0       1   \n",
       "679           680       1.0       1   \n",
       "737           738       1.0       1   \n",
       "1234         1235       NaN       1   \n",
       "\n",
       "                                                   Name     Sex   Age  SibSp  \\\n",
       "258                                    Ward, Miss. Anna  female  35.0      0   \n",
       "679                  Cardeza, Mr. Thomas Drake Martinez    male  36.0      0   \n",
       "737                              Lesurer, Mr. Gustave J    male  35.0      0   \n",
       "1234  Cardeza, Mrs. James Warburton Martinez (Charlo...  female  58.0      0   \n",
       "\n",
       "      Parch    Ticket      Fare        Cabin Embarked Title  Family  \n",
       "258       0  PC 17755  512.3292          NaN        C  Miss       0  \n",
       "679       1  PC 17755  512.3292  B51 B53 B55        C    Mr       1  \n",
       "737       0  PC 17755  512.3292         B101        C    Mr       0  \n",
       "1234      1  PC 17755  512.3292  B51 B53 B55        C   Mrs       1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[(DF[\"Fare\"] == max(DF[\"Fare\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Mark</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>MrSenior</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Ethel Flora</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mrs. Mark (Mary McDougald)</td>\n",
       "      <td>female</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                 Name  \\\n",
       "27            28       0.0       1       Fortune, Mr. Charles Alexander   \n",
       "88            89       1.0       1           Fortune, Miss. Mabel Helen   \n",
       "341          342       1.0       1       Fortune, Miss. Alice Elizabeth   \n",
       "438          439       0.0       1                    Fortune, Mr. Mark   \n",
       "944          945       NaN       1           Fortune, Miss. Ethel Flora   \n",
       "960          961       NaN       1  Fortune, Mrs. Mark (Mary McDougald)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch Ticket   Fare        Cabin Embarked     Title  \\\n",
       "27     male  19.0      3      2  19950  263.0  C23 C25 C27        S        Mr   \n",
       "88   female  23.0      3      2  19950  263.0  C23 C25 C27        S      Miss   \n",
       "341  female  24.0      3      2  19950  263.0  C23 C25 C27        S      Miss   \n",
       "438    male  64.0      1      4  19950  263.0  C23 C25 C27        S  MrSenior   \n",
       "944  female  28.0      3      2  19950  263.0  C23 C25 C27        S      Miss   \n",
       "960  female  60.0      1      4  19950  263.0  C23 C25 C27        S       Mrs   \n",
       "\n",
       "     Family  \n",
       "27        5  \n",
       "88        5  \n",
       "341       5  \n",
       "438       5  \n",
       "944       5  \n",
       "960       5  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The next tarife after 512 is:\n",
    "DF[(DF[\"Fare\"]== max(DF[DF[\"Fare\"] != max(DF[\"Fare\"])][\"Fare\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[(DF[\"Fare\"] == max(DF[\"Fare\"])), \"Fare\" ] =  263\n",
    "max(DF[\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un siguiente paso categorizamos los precios para facilitar la posterior creacion de modelos de prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['precio'] = pd.qcut(DF[\"Fare\"], 10, labels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e72d10c8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id28'/> \n",
    "\n",
    "### [3.8 Ticket](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Ticket\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al intentar analizar los Tickets en detalle vemos que se trata de un dato muy confuso que en algunos casos es numérico y en otros es alfanumérico, para unificar el criterio de forma simple, recogemos solo los numeros finales ignorando las letras iniciales. Posteriormente, si finalmente decidimos que este aspecto es relevante podría ser interesante volver a este apartado para recoger también las letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Puesto que la mayoria no tienen letras recuperamos solo el ultimo numero.\n",
    "\n",
    "billetes = []\n",
    "for ticket in DF[\"Ticket\"]:\n",
    "    billetes.append(ticket.split()[-1])\n",
    "    \n",
    "len(billetes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Title  Family precio  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S    Mr       1      1   \n",
       "1      0          PC 17599  71.2833   C85        C   Mrs       1      9   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Miss       0      3   \n",
       "3      0            113803  53.1000  C123        S   Mrs       1      9   \n",
       "4      0            373450   8.0500   NaN        S    Mr       0      3   \n",
       "\n",
       "   billete  \n",
       "0    21171  \n",
       "1    17599  \n",
       "2  3101282  \n",
       "3   113803  \n",
       "4   373450  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['billete'] = billetes\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e732c788>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF.loc[(DF['billete']=='LINE'), \"billete\" ] = '99999'\n",
    "DF['billete'] = DF['billete'].astype(int)\n",
    "plt.figure()\n",
    "DF.boxplot(['billete'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corregimos los valores extremos dandoles un valor cercano al siguiente valor máximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e73c9888>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF.loc[(DF['billete']>400000), \"billete\" ] = 400000\n",
    "plt.figure()\n",
    "DF.boxplot(['billete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159559.19022154316"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1280x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare DF\n",
    "x_var = 'billete'\n",
    "groupby_var = 'Pclass'\n",
    "df_agg = DF.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [DF[x_var].values.tolist() for i, DF in df_agg]\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, 80, stacked=True, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(DF[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.xticks(ticks=bins[::3], labels=[round(b,1) for b in bins[::3]])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esta representacion visual, vemos que el número de billlete tiene claramente alguna relación con la clase, especialmente a partir del billete número 40000 aproximadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo esta apreciación visual categorizamos la variable *billete* en 5 grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "DF['billete'] = DF['billete'].astype(int)\n",
    "DF.loc[ DF['billete'] <= 40000, 'billete'] = 1\n",
    "DF.loc[(DF['billete'] > 40000) & (DF['billete'] <= 104000), 'billete'] = 2\n",
    "DF.loc[(DF['billete'] > 104000) & (DF['billete'] <= 170000), 'billete'] = 3\n",
    "DF.loc[(DF['billete'] > 170000) & (DF['billete'] <= 252000), 'billete'] = 4\n",
    "DF.loc[ DF['billete'] > 252000, 'billete'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1280x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare DF\n",
    "x_var = 'billete'\n",
    "groupby_var = 'Pclass'\n",
    "df_agg = DF.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [DF[x_var].values.tolist() for i, DF in df_agg]\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, 5, stacked=True, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(DF[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "#plt.xticks(ticks=bins[::3], labels=[round(b,1) for b in bins[::3]])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id29'/> \n",
    "\n",
    "### [2.9 Cabin](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Cabin\"].isna()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo que las letras hacen referencia a las distintas cubiertas del barco y considerando este hecho un factor primordial un la supervivencia, recogemos estos datos y rellenamos los desconocidos con la letra U de Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rellenamos los vacios con un codigo:\n",
    "for l in DF['Cabin']:\n",
    "    DF['Cabin'] = DF['Cabin'].fillna(\"U0\")\n",
    "len(DF[DF[\"Cabin\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U0', 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148', 'B45', 'B36', 'A21', 'D34', 'A9', 'C31', 'B61', 'C53',\n",
       "       'D43', 'C130', 'C132', 'C55 C57', 'C116', 'F', 'A29', 'C6', 'C28',\n",
       "       'C51', 'C97', 'D22', 'B10', 'E45', 'E52', 'A11', 'B11', 'C80',\n",
       "       'C89', 'F E46', 'B26', 'F E57', 'A18', 'E60', 'E39 E41',\n",
       "       'B52 B54 B56', 'C39', 'B24', 'D40', 'D38', 'C105'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(DF[\"Cabin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estas letras, creamos una clasificación numérica para facilitar su analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planta = []\n",
    "letras = []    \n",
    "planta.append(DF['Cabin'])\n",
    "for letra in planta[0]:\n",
    "    if letra[0]== \"A\":\n",
    "        letras.append(1)\n",
    "    elif letra[0]== \"B\":\n",
    "        letras.append(2)  \n",
    "    elif letra[0]== \"C\":\n",
    "        letras.append(3)\n",
    "    elif letra[0]== \"D\":\n",
    "        letras.append(4)\n",
    "    elif letra[0]== \"E\":\n",
    "        letras.append(5)\n",
    "    elif letra[0]== \"F\":\n",
    "        letras.append(6)\n",
    "    elif letra[0]== \"G\":\n",
    "        letras.append(7)\n",
    "    else:\n",
    "        letras.append(8)\n",
    "        \n",
    "\n",
    "len(letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 5, 7, 4, 1, 2, 6], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['Planta'] = letras\n",
    "pd.unique(DF['Planta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180e7f04848>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Prueba = DF[DF.Survived.notnull()]\n",
    "sns.barplot(x='Planta', y='Survived', data=Prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id210'/> \n",
    "\n",
    "### [2.10 Embarked](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Embarked* tan sólo tiene dos valores perdidos. Vamos a tratar darle un valor a estos dos registros a partir de los\n",
    "de la variable *Fare*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF[DF[\"Embarked\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>830</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MrSSenior</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62       1.0       1                        Icard, Miss. Amelie   \n",
       "829          830       1.0       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked      Title  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN       Miss   \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN  MrSSenior   \n",
       "\n",
       "     Family precio  billete  Planta  \n",
       "61        0     10        3       2  \n",
       "829       0     10        3       2  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[DF[\"Embarked\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que no hay rasgos que nos indiquen el lugar de embarque, elegimos el puerto donde subieron la mayoria de personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title, Family, precio, billete, Planta]\n",
       "Index: []"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.loc[( DF[\"Embarked\"].isna()), \"Embarked\" ] = 'S'\n",
    "DF[DF[\"Embarked\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id3'/>\n",
    "\n",
    "# [3. Análisis de los datos y conclusiones](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar la limpieza y preparación de nuestro *dateset* realizamos unos últimos ajustes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF2=DF\n",
    "len(DF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de probar modelos, para evitar el sobre entrenamiento, ahora que ya conocemos los datos seleccionados, seleccionamos los apartados que nos parecen más relevantes y eliminamos los que aportan menos informacion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age Embarked Title  Family precio  billete  \\\n",
       "0       0.0       3    male  22.0        S    Mr       1      1        1   \n",
       "1       1.0       1  female  38.0        C   Mrs       1      9        1   \n",
       "2       1.0       3  female  26.0        S  Miss       0      3        5   \n",
       "3       1.0       1  female  35.0        S   Mrs       1      9        3   \n",
       "4       0.0       3    male  35.0        S    Mr       0      3        5   \n",
       "\n",
       "   Planta  \n",
       "0       8  \n",
       "1       3  \n",
       "2       8  \n",
       "3       3  \n",
       "4       8  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF2=DF2.drop('PassengerId', axis=1) # Esta informacion es irrelevante\n",
    "DF2=DF2.drop('Name', axis=1) # La informacion mas relevante ya esta en Title\n",
    "DF2=DF2.drop('SibSp', axis=1) # Esta informacion ya esta en Family\n",
    "DF2=DF2.drop('Parch', axis=1) # Esta informacion ya esta en Family\n",
    "DF2=DF2.drop('Ticket', axis=1) # Esta informacion ya esta en billete\n",
    "DF2=DF2.drop('Cabin', axis=1) # Esta informacion ya esta en Planta\n",
    "DF2=DF2.drop('Fare', axis=1) # Esta informacion ya esta en precio\n",
    "\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Survived    891 non-null float64\n",
      "Pclass      1309 non-null int64\n",
      "Sex         1309 non-null object\n",
      "Age         1309 non-null float64\n",
      "Embarked    1309 non-null object\n",
      "Title       1309 non-null object\n",
      "Family      1309 non-null int64\n",
      "precio      1309 non-null category\n",
      "billete     1309 non-null int32\n",
      "Planta      1309 non-null int64\n",
      "dtypes: category(1), float64(2), int32(1), int64(3), object(3)\n",
      "memory usage: 88.7+ KB\n"
     ]
    }
   ],
   "source": [
    "DF2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2['precio']=DF2['precio'].astype(int)\n",
    "DF2['Age']=DF2['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repasamos en primer lugar los datos con los que trabajamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion conventimos los datos categoricos en numeros creando dummies cuando sea necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>Titulo_Empleados</th>\n",
       "      <th>Titulo_Girl</th>\n",
       "      <th>Titulo_Master</th>\n",
       "      <th>Titulo_Miss</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex  Age Embarked  Family  precio  billete  Planta  \\\n",
       "0       0.0       3    male   22        S       1       1        1       8   \n",
       "1       1.0       1  female   38        C       1       9        1       3   \n",
       "2       1.0       3  female   26        S       0       3        5       8   \n",
       "3       1.0       1  female   35        S       1       9        3       3   \n",
       "4       0.0       3    male   35        S       0       3        5       8   \n",
       "\n",
       "   Titulo_Arist  ...  Titulo_Dr  Titulo_Empleados  Titulo_Girl  Titulo_Master  \\\n",
       "0             0  ...          0                 0            0              0   \n",
       "1             0  ...          0                 0            0              0   \n",
       "2             0  ...          0                 0            0              0   \n",
       "3             0  ...          0                 0            0              0   \n",
       "4             0  ...          0                 0            0              0   \n",
       "\n",
       "   Titulo_Miss  Titulo_Mr  Titulo_MrSSenior  Titulo_MrSenior  Titulo_Mrs  \\\n",
       "0            0          1                 0                0           0   \n",
       "1            0          0                 0                0           1   \n",
       "2            1          0                 0                0           0   \n",
       "3            0          0                 0                0           1   \n",
       "4            0          1                 0                0           0   \n",
       "\n",
       "   Titulo_Rev  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titulos = pd.get_dummies(DF2['Title'], prefix = \"Titulo\")\n",
    "DF2 = pd.concat([DF2, Titulos], axis=1)\n",
    "DF2=DF2.drop('Title', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Master</th>\n",
       "      <th>Titulo_Miss</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex  Age  Family  precio  billete  Planta  \\\n",
       "0       0.0       3    male   22       1       1        1       8   \n",
       "1       1.0       1  female   38       1       9        1       3   \n",
       "2       1.0       3  female   26       0       3        5       8   \n",
       "3       1.0       1  female   35       1       9        3       3   \n",
       "4       0.0       3    male   35       0       3        5       8   \n",
       "\n",
       "   Titulo_Arist  Titulo_Army  ...  Titulo_Master  Titulo_Miss  Titulo_Mr  \\\n",
       "0             0            0  ...              0            0          1   \n",
       "1             0            0  ...              0            0          0   \n",
       "2             0            0  ...              0            1          0   \n",
       "3             0            0  ...              0            0          0   \n",
       "4             0            0  ...              0            0          1   \n",
       "\n",
       "   Titulo_MrSSenior  Titulo_MrSenior  Titulo_Mrs  Titulo_Rev  Puerto_C  \\\n",
       "0                 0                0           0           0         0   \n",
       "1                 0                0           1           0         1   \n",
       "2                 0                0           0           0         0   \n",
       "3                 0                0           1           0         0   \n",
       "4                 0                0           0           0         0   \n",
       "\n",
       "   Puerto_Q  Puerto_S  \n",
       "0         0         1  \n",
       "1         0         0  \n",
       "2         0         1  \n",
       "3         0         1  \n",
       "4         0         1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Puerto = pd.get_dummies(DF2['Embarked'], prefix = \"Puerto\")\n",
    "DF2 = pd.concat([DF2, Puerto], axis=1)\n",
    "DF2=DF2.drop('Embarked', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "      <th>Sexo_female</th>\n",
       "      <th>Sexo_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Age  Family  precio  billete  Planta  Titulo_Arist  \\\n",
       "0       0.0       3   22       1       1        1       8             0   \n",
       "1       1.0       1   38       1       9        1       3             0   \n",
       "2       1.0       3   26       0       3        5       8             0   \n",
       "3       1.0       1   35       1       9        3       3             0   \n",
       "4       0.0       3   35       0       3        5       8             0   \n",
       "\n",
       "   Titulo_Army  Titulo_Dr  ...  Titulo_Mr  Titulo_MrSSenior  Titulo_MrSenior  \\\n",
       "0            0          0  ...          1                 0                0   \n",
       "1            0          0  ...          0                 0                0   \n",
       "2            0          0  ...          0                 0                0   \n",
       "3            0          0  ...          0                 0                0   \n",
       "4            0          0  ...          1                 0                0   \n",
       "\n",
       "   Titulo_Mrs  Titulo_Rev  Puerto_C  Puerto_Q  Puerto_S  Sexo_female  \\\n",
       "0           0           0         0         0         1            0   \n",
       "1           1           0         1         0         0            1   \n",
       "2           0           0         0         0         1            1   \n",
       "3           1           0         0         0         1            1   \n",
       "4           0           0         0         0         1            0   \n",
       "\n",
       "   Sexo_male  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sexo = pd.get_dummies(DF2['Sex'], prefix = \"Sexo\")\n",
    "DF2 = pd.concat([DF2, Sexo], axis=1)\n",
    "DF2=DF2.drop('Sex', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 24 columns):\n",
      "Survived            891 non-null float64\n",
      "Pclass              1309 non-null int64\n",
      "Age                 1309 non-null int32\n",
      "Family              1309 non-null int64\n",
      "precio              1309 non-null int32\n",
      "billete             1309 non-null int32\n",
      "Planta              1309 non-null int64\n",
      "Titulo_Arist        1309 non-null uint8\n",
      "Titulo_Army         1309 non-null uint8\n",
      "Titulo_Dr           1309 non-null uint8\n",
      "Titulo_Empleados    1309 non-null uint8\n",
      "Titulo_Girl         1309 non-null uint8\n",
      "Titulo_Master       1309 non-null uint8\n",
      "Titulo_Miss         1309 non-null uint8\n",
      "Titulo_Mr           1309 non-null uint8\n",
      "Titulo_MrSSenior    1309 non-null uint8\n",
      "Titulo_MrSenior     1309 non-null uint8\n",
      "Titulo_Mrs          1309 non-null uint8\n",
      "Titulo_Rev          1309 non-null uint8\n",
      "Puerto_C            1309 non-null uint8\n",
      "Puerto_Q            1309 non-null uint8\n",
      "Puerto_S            1309 non-null uint8\n",
      "Sexo_female         1309 non-null uint8\n",
      "Sexo_male           1309 non-null uint8\n",
      "dtypes: float64(1), int32(3), int64(3), uint8(17)\n",
      "memory usage: 78.1 KB\n"
     ]
    }
   ],
   "source": [
    "DF2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez finalizada la limpieza y preparación del *dataset* procedemos a separarlo para crear de nuevo los *dataset train* y *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "      <th>Sexo_female</th>\n",
       "      <th>Sexo_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Age  Family  precio  billete  Planta  Titulo_Arist  \\\n",
       "0       0.0       3   22       1       1        1       8             0   \n",
       "1       1.0       1   38       1       9        1       3             0   \n",
       "2       1.0       3   26       0       3        5       8             0   \n",
       "3       1.0       1   35       1       9        3       3             0   \n",
       "4       0.0       3   35       0       3        5       8             0   \n",
       "\n",
       "   Titulo_Army  Titulo_Dr  ...  Titulo_Mr  Titulo_MrSSenior  Titulo_MrSenior  \\\n",
       "0            0          0  ...          1                 0                0   \n",
       "1            0          0  ...          0                 0                0   \n",
       "2            0          0  ...          0                 0                0   \n",
       "3            0          0  ...          0                 0                0   \n",
       "4            0          0  ...          1                 0                0   \n",
       "\n",
       "   Titulo_Mrs  Titulo_Rev  Puerto_C  Puerto_Q  Puerto_S  Sexo_female  \\\n",
       "0           0           0         0         0         1            0   \n",
       "1           1           0         1         0         0            1   \n",
       "2           0           0         0         0         1            1   \n",
       "3           1           0         0         0         1            1   \n",
       "4           0           0         0         0         1            0   \n",
       "\n",
       "   Sexo_male  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training = DF2[DF2.Survived.notnull()]\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los datos Training (con información del target) creamos dos sets uno X con todos las caracteristicas y otro Y con el target (la supervivencia o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Training.loc[:, Training.columns != 'Survived']\n",
    "Y=Training.loc[:, Training.columns == 'Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, creamos dos *datasets* de subconjuntos de train y test. Uno para el entrenamiento de los modelos (X_train, y_train) y otro para su validacion (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También creamos un dataset con los datos limpios para hacer la predicción que se mandará a Kaggle al que llamamos XtestFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>Titulo_Empleados</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "      <th>Sexo_female</th>\n",
       "      <th>Sexo_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age  Family  precio  billete  Planta  Titulo_Arist  Titulo_Army  \\\n",
       "891       3   34       0       2        5       8             0            0   \n",
       "892       3   47       1       1        5       8             0            0   \n",
       "893       2   62       0       4        4       8             0            0   \n",
       "894       3   27       0       4        5       8             0            0   \n",
       "895       3   22       2       5        5       8             0            0   \n",
       "\n",
       "     Titulo_Dr  Titulo_Empleados  ...  Titulo_Mr  Titulo_MrSSenior  \\\n",
       "891          0                 0  ...          1                 0   \n",
       "892          0                 0  ...          0                 0   \n",
       "893          0                 0  ...          0                 0   \n",
       "894          0                 0  ...          1                 0   \n",
       "895          0                 0  ...          0                 0   \n",
       "\n",
       "     Titulo_MrSenior  Titulo_Mrs  Titulo_Rev  Puerto_C  Puerto_Q  Puerto_S  \\\n",
       "891                0           0           0         0         1         0   \n",
       "892                0           1           0         0         0         1   \n",
       "893                1           0           0         0         1         0   \n",
       "894                0           0           0         0         0         1   \n",
       "895                0           1           0         0         0         1   \n",
       "\n",
       "     Sexo_female  Sexo_male  \n",
       "891            0          1  \n",
       "892            1          0  \n",
       "893            0          1  \n",
       "894            0          1  \n",
       "895            1          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing = DF2[DF2.Survived.isnull()]\n",
    "XtestFinal=Testing.loc[:, Testing.columns != 'Survived']\n",
    "XtestFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuacion crearemos diversos modelos y comprobaremos su efectividad con la finanalidad de participar en la competición activa en Kaggle: \n",
    "\n",
    "  #### 1. Modelos de regresión.\n",
    "  #### 2. Combinación de modelos regresión.\n",
    "  #### 3. Modelo de redes neuronal.\n",
    "  #### 4. Combinación del modelo de red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id31'/>\n",
    "\n",
    "### [1. Modelos de regresión](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestFinal = Testing.loc[:, Testing.columns != 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.gradient_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\MARTA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.63888889, 0.75      , 0.80555556, 0.91428571, 0.82857143]),\n",
       " 0.7874603174603175,\n",
       " array([0.63888889, 0.72222222, 0.77777778, 0.94285714, 0.82857143]),\n",
       " 0.782063492063492,\n",
       " array([0.55555556, 0.66666667, 0.75      , 0.88571429, 0.65714286]),\n",
       " 0.703015873015873,\n",
       " array([0.58333333, 0.66666667, 0.80555556, 0.8       , 0.71428571]),\n",
       " 0.7139682539682539]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Escogemos las funciones con las que queremos generar modelos para predecir la supervivencia\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = LogisticRegressionCV()\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "# Creamos un vector en el que recogeremos los resultados de la precision de cada metodo en funcion de un proceso de cross validation sobre los datos X_train, y_train \n",
    "resultados =[]\n",
    "\n",
    "# Creamos un df para recoger los resultados de la prediccion final de cada uno de los metodos\n",
    "submission= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "models = [logreg, logreg_cv, rf, gboost]\n",
    "\n",
    "for model in models:\n",
    "    clf=model\n",
    "    Crossval = cross_val_score(clf,X_train, y_train.values.ravel(), cv = 5, scoring='accuracy')\n",
    "    #recogemos la precision de cada una de las 5 cross validation y también la media total.\n",
    "    resultados.append(Crossval)\n",
    "    resultados.append(np.mean(Crossval))\n",
    "    \n",
    "    # A continuacion, entrenamos el metodo una vez mas, pero ahora con todos los datos para cada uno de los metodos\n",
    "    # ravel() returns contiguous flattened array\n",
    "    clf.fit(X, Y.values.ravel())\n",
    "    \n",
    "    # A partir del metodo entrenado, se recoge una prediccion a partir de los datos sin taget para entregar, en el df submission\n",
    "    submission[str(model)] = clf.predict(XtestFinal).astype(int)\n",
    "\n",
    "# Identificamos cada columna del df con el nombre del metodo de predicción\n",
    "submission.columns = ['PassengerId','logreg', 'logreg_cv', 'rf', 'gboost']\n",
    "resultados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>Titulo_Empleados</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "      <th>Sexo_female</th>\n",
       "      <th>Sexo_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pclass  Age  Family  precio  billete  Planta  Titulo_Arist  Titulo_Army  \\\n",
       "891        3   34       0       2        5       8             0            0   \n",
       "892        3   47       1       1        5       8             0            0   \n",
       "893        2   62       0       4        4       8             0            0   \n",
       "894        3   27       0       4        5       8             0            0   \n",
       "895        3   22       2       5        5       8             0            0   \n",
       "...      ...  ...     ...     ...      ...     ...           ...          ...   \n",
       "1304       3   27       0       3        1       8             0            0   \n",
       "1305       1   39       0      10        1       3             1            0   \n",
       "1306       3   38       0       1        5       8             0            0   \n",
       "1307       3   27       0       3        5       8             0            0   \n",
       "1308       3    6       2       6        1       8             0            0   \n",
       "\n",
       "      Titulo_Dr  Titulo_Empleados  ...  Titulo_Mr  Titulo_MrSSenior  \\\n",
       "891           0                 0  ...          1                 0   \n",
       "892           0                 0  ...          0                 0   \n",
       "893           0                 0  ...          0                 0   \n",
       "894           0                 0  ...          1                 0   \n",
       "895           0                 0  ...          0                 0   \n",
       "...         ...               ...  ...        ...               ...   \n",
       "1304          0                 0  ...          1                 0   \n",
       "1305          0                 0  ...          0                 0   \n",
       "1306          0                 0  ...          1                 0   \n",
       "1307          0                 0  ...          1                 0   \n",
       "1308          0                 0  ...          0                 0   \n",
       "\n",
       "      Titulo_MrSenior  Titulo_Mrs  Titulo_Rev  Puerto_C  Puerto_Q  Puerto_S  \\\n",
       "891                 0           0           0         0         1         0   \n",
       "892                 0           1           0         0         0         1   \n",
       "893                 1           0           0         0         1         0   \n",
       "894                 0           0           0         0         0         1   \n",
       "895                 0           1           0         0         0         1   \n",
       "...               ...         ...         ...       ...       ...       ...   \n",
       "1304                0           0           0         0         0         1   \n",
       "1305                0           0           0         1         0         0   \n",
       "1306                0           0           0         0         0         1   \n",
       "1307                0           0           0         0         0         1   \n",
       "1308                0           0           0         1         0         0   \n",
       "\n",
       "      Sexo_female  Sexo_male  \n",
       "891             0          1  \n",
       "892             1          0  \n",
       "893             0          1  \n",
       "894             0          1  \n",
       "895             1          0  \n",
       "...           ...        ...  \n",
       "1304            0          1  \n",
       "1305            1          0  \n",
       "1306            0          1  \n",
       "1307            0          1  \n",
       "1308            0          1  \n",
       "\n",
       "[418 rows x 23 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtestFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en general los resultados son bastante inestables. Por ejemplo, vemos que los resultados del método de Random Forest Classifier oscila entre el 69 y el 94% de aciertos según donde se haya hecho el corte de la cross validation. Aún así, este metodo es el que consigue de media un mayor numero de aciertos, llegando al 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>logreg</th>\n",
       "      <th>logreg_cv</th>\n",
       "      <th>rf</th>\n",
       "      <th>gboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  logreg  logreg_cv  rf  gboost\n",
       "891           892       0          0   0       0\n",
       "892           893       0          0   0       0\n",
       "893           894       0          0   0       0\n",
       "894           895       0          0   0       0\n",
       "895           896       1          1   1       1\n",
       "...           ...     ...        ...  ..     ...\n",
       "1304         1305       0          0   0       0\n",
       "1305         1306       1          1   1       1\n",
       "1306         1307       0          0   0       0\n",
       "1307         1308       0          0   0       0\n",
       "1308         1309       1          1   1       1\n",
       "\n",
       "[418 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los resultados predichos generados por el metodo Random Forest Classifier creamos un csv para comprobar su grado de acierto en Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived\n",
       "891           892         0\n",
       "892           893         0\n",
       "893           894         0\n",
       "894           895         0\n",
       "895           896         1\n",
       "...           ...       ...\n",
       "1304         1305         0\n",
       "1305         1306         1\n",
       "1306         1307         0\n",
       "1307         1308         0\n",
       "1308         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_rf= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "submission_rf['Survived'] =  submission.rf\n",
    "submission_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf.to_csv(\"Submision_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un 0.79425 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id32'/>\n",
    "\n",
    "### [2. Combinación de modelos de regresión](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechamos para hacer también un combinado de los resultados de los 3 métodos con los mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>logreg</th>\n",
       "      <th>logreg_cv</th>\n",
       "      <th>rf</th>\n",
       "      <th>gboost</th>\n",
       "      <th>suma_mejores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  logreg  logreg_cv  rf  gboost  suma_mejores\n",
       "891           892       0          0   0       0             0\n",
       "892           893       0          0   0       0             0\n",
       "893           894       0          0   0       0             0\n",
       "894           895       0          0   0       0             0\n",
       "895           896       1          1   1       1             1\n",
       "...           ...     ...        ...  ..     ...           ...\n",
       "1304         1305       0          0   0       0             0\n",
       "1305         1306       1          1   1       1             1\n",
       "1306         1307       0          0   0       0             0\n",
       "1307         1308       0          0   0       0             0\n",
       "1308         1309       1          1   1       1             1\n",
       "\n",
       "[418 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['suma_mejores']=(np.round((submission.logreg+submission.logreg_cv + submission.rf)/3)).astype(int) \n",
    "submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived\n",
       "891           892         0\n",
       "892           893         0\n",
       "893           894         0\n",
       "894           895         0\n",
       "895           896         1\n",
       "...           ...       ...\n",
       "1304         1305         0\n",
       "1305         1306         1\n",
       "1306         1307         0\n",
       "1307         1308         0\n",
       "1308         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission_suma_mejores= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "submission_suma_mejores['Survived'] =  submission.suma_mejores\n",
    "submission_suma_mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_suma_mejores.to_csv(\"Submision_suma_mejores1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta predicción ha conseguido un 0.78947 en Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id33'/>\n",
    "\n",
    "### [3. Modelo de red neuronal](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion preparamos los datos para utilizar una red neuronal completamente conectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Family</th>\n",
       "      <th>precio</th>\n",
       "      <th>billete</th>\n",
       "      <th>Planta</th>\n",
       "      <th>Titulo_Arist</th>\n",
       "      <th>Titulo_Army</th>\n",
       "      <th>Titulo_Dr</th>\n",
       "      <th>...</th>\n",
       "      <th>Titulo_Mr</th>\n",
       "      <th>Titulo_MrSSenior</th>\n",
       "      <th>Titulo_MrSenior</th>\n",
       "      <th>Titulo_Mrs</th>\n",
       "      <th>Titulo_Rev</th>\n",
       "      <th>Puerto_C</th>\n",
       "      <th>Puerto_Q</th>\n",
       "      <th>Puerto_S</th>\n",
       "      <th>Sexo_female</th>\n",
       "      <th>Sexo_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Age  Family    precio  billete    Planta  \\\n",
       "0       0.0     1.0  0.2750     0.1  0.000000      0.0  1.000000   \n",
       "1       1.0     0.0  0.4750     0.1  0.888889      0.0  0.285714   \n",
       "2       1.0     1.0  0.3250     0.0  0.222222      1.0  1.000000   \n",
       "3       1.0     0.0  0.4375     0.1  0.888889      0.5  0.285714   \n",
       "4       0.0     1.0  0.4375     0.0  0.222222      1.0  1.000000   \n",
       "\n",
       "   Titulo_Arist  Titulo_Army  Titulo_Dr  ...  Titulo_Mr  Titulo_MrSSenior  \\\n",
       "0           0.0          0.0        0.0  ...        1.0               0.0   \n",
       "1           0.0          0.0        0.0  ...        0.0               0.0   \n",
       "2           0.0          0.0        0.0  ...        0.0               0.0   \n",
       "3           0.0          0.0        0.0  ...        0.0               0.0   \n",
       "4           0.0          0.0        0.0  ...        1.0               0.0   \n",
       "\n",
       "   Titulo_MrSenior  Titulo_Mrs  Titulo_Rev  Puerto_C  Puerto_Q  Puerto_S  \\\n",
       "0              0.0         0.0         0.0       0.0       0.0       1.0   \n",
       "1              0.0         1.0         0.0       1.0       0.0       0.0   \n",
       "2              0.0         0.0         0.0       0.0       0.0       1.0   \n",
       "3              0.0         1.0         0.0       0.0       0.0       1.0   \n",
       "4              0.0         0.0         0.0       0.0       0.0       1.0   \n",
       "\n",
       "   Sexo_female  Sexo_male  \n",
       "0          0.0        1.0  \n",
       "1          1.0        0.0  \n",
       "2          1.0        0.0  \n",
       "3          1.0        0.0  \n",
       "4          0.0        1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizamos por el max-min scaling para que los numeros dentro del rango [0,1]\n",
    "DF2 = (DF2 - DF2.min()) / (DF2.max() - DF2.min())\n",
    "DF2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = DF2[DF2.Survived.notnull()]\n",
    "X=Training.loc[:, Training.columns != 'Survived']\n",
    "Y=Training.loc[:, Training.columns == 'Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.2)\n",
    "\n",
    "Testing = DF2[DF2.Survived.isna()]\n",
    "XtestFinal = Testing.loc[:, Testing.columns != 'Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 23)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-a71990b7768e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creación de la red neuronal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Creación de la red neuronal\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "# Modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model.add(Dense(23, input_shape=(23,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Capas ocultas\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "    \n",
    "# Capa de salida con funcion sigmoide que da un numero entre 0 y 1\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingClassifier' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-01432eb0cde8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GradientBoostingClassifier' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# learning\n",
    "model.fit(X_train, y_train, nb_epoch=400, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47478944675288215, 0.8181818127632141]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluamos ahora el metodo sobre todos los datos de los que conocemos la respuesta\n",
    "\n",
    "results = model.evaluate(X, Y, batch_size=30)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo hemos hecho correr varias veces hasta conseguir un resultado superior al 81%\n",
    "\n",
    "Seguimos entrenando el mismo metodo con los datos del test antes de mandarlo a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.5056 - accuracy: 0.8081\n",
      "Epoch 2/400\n",
      " 30/891 [>.............................] - ETA: 0s - loss: 0.2994 - accuracy: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 200us/step - loss: 0.4534 - accuracy: 0.8171\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4466 - accuracy: 0.8058\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.4289 - accuracy: 0.8103\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4271 - accuracy: 0.8092\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4453 - accuracy: 0.8159\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4198 - accuracy: 0.8328\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4213 - accuracy: 0.8204\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.4122 - accuracy: 0.8328\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4034 - accuracy: 0.8373\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4210 - accuracy: 0.8159\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4100 - accuracy: 0.8350\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4250 - accuracy: 0.8316\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.4249 - accuracy: 0.8272\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4006 - accuracy: 0.8451\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4209 - accuracy: 0.8204\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4182 - accuracy: 0.8227\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4388 - accuracy: 0.8081\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4196 - accuracy: 0.8204\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4125 - accuracy: 0.8361\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4010 - accuracy: 0.8339\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4160 - accuracy: 0.8328\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4050 - accuracy: 0.8339\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4059 - accuracy: 0.8294\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4017 - accuracy: 0.8361\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4008 - accuracy: 0.8384\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4203 - accuracy: 0.8260\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.4032 - accuracy: 0.8485\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.3995 - accuracy: 0.8361\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.3980 - accuracy: 0.8361\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.4087 - accuracy: 0.8350\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4070 - accuracy: 0.8227\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3985 - accuracy: 0.8328\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3954 - accuracy: 0.8418\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4088 - accuracy: 0.8328\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4032 - accuracy: 0.8384\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4211 - accuracy: 0.8137\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3905 - accuracy: 0.8361\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4031 - accuracy: 0.8361\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3974 - accuracy: 0.8305\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4302 - accuracy: 0.8215\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3951 - accuracy: 0.8395\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4006 - accuracy: 0.8350\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4031 - accuracy: 0.8339\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4077 - accuracy: 0.8283\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3991 - accuracy: 0.8328\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3931 - accuracy: 0.8395\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4031 - accuracy: 0.8361\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4042 - accuracy: 0.8361\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3947 - accuracy: 0.8227\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3948 - accuracy: 0.8373\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4062 - accuracy: 0.8339\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4043 - accuracy: 0.8204\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3979 - accuracy: 0.8384\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3931 - accuracy: 0.8406\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3909 - accuracy: 0.8373\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3944 - accuracy: 0.8440\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4072 - accuracy: 0.8316\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3970 - accuracy: 0.8294\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3975 - accuracy: 0.8384\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3992 - accuracy: 0.8429\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4047 - accuracy: 0.8373\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3939 - accuracy: 0.8350\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4055 - accuracy: 0.8227\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3923 - accuracy: 0.8339\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3922 - accuracy: 0.8350\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4064 - accuracy: 0.8384\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3892 - accuracy: 0.8474\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3986 - accuracy: 0.8395\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4039 - accuracy: 0.8316\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3943 - accuracy: 0.8429\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3969 - accuracy: 0.8272\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3999 - accuracy: 0.8294\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3938 - accuracy: 0.8260\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3890 - accuracy: 0.8384\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3919 - accuracy: 0.8485\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3818 - accuracy: 0.8406\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4054 - accuracy: 0.8294\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3942 - accuracy: 0.8361\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3879 - accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3986 - accuracy: 0.8328\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3991 - accuracy: 0.8373\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3965 - accuracy: 0.8395\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3786 - accuracy: 0.8530\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3962 - accuracy: 0.8451\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3913 - accuracy: 0.8384\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3968 - accuracy: 0.8361\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4072 - accuracy: 0.8361\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3937 - accuracy: 0.8429\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3886 - accuracy: 0.8395\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3946 - accuracy: 0.8350\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3811 - accuracy: 0.8507\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3810 - accuracy: 0.8474\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4034 - accuracy: 0.8305\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3924 - accuracy: 0.8316\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3947 - accuracy: 0.8373\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3883 - accuracy: 0.8361\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3964 - accuracy: 0.8384\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3976 - accuracy: 0.8451\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3780 - accuracy: 0.8507\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3769 - accuracy: 0.8485\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3813 - accuracy: 0.8451\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3797 - accuracy: 0.8361\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3992 - accuracy: 0.8283\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3893 - accuracy: 0.8339\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3679 - accuracy: 0.8541\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3831 - accuracy: 0.8361\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3982 - accuracy: 0.8373\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3876 - accuracy: 0.8440\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3617 - accuracy: 0.8530\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3821 - accuracy: 0.8384\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3803 - accuracy: 0.8451\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3911 - accuracy: 0.8316\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3792 - accuracy: 0.8373\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3825 - accuracy: 0.8474\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3968 - accuracy: 0.8406\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3979 - accuracy: 0.8238\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3904 - accuracy: 0.8440\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3897 - accuracy: 0.8350\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3995 - accuracy: 0.8316\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3812 - accuracy: 0.8462\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3908 - accuracy: 0.8373\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3838 - accuracy: 0.8339\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3930 - accuracy: 0.8272\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3996 - accuracy: 0.8406\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4021 - accuracy: 0.8373\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3923 - accuracy: 0.8406\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3902 - accuracy: 0.8429\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3794 - accuracy: 0.8384\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3855 - accuracy: 0.8395\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3971 - accuracy: 0.8373\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3926 - accuracy: 0.8384\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4024 - accuracy: 0.8328\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3834 - accuracy: 0.8530\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3918 - accuracy: 0.8384\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3914 - accuracy: 0.8373\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3847 - accuracy: 0.8328\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3998 - accuracy: 0.8361\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3890 - accuracy: 0.8418\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3783 - accuracy: 0.8485\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3894 - accuracy: 0.8418\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3994 - accuracy: 0.8373\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3807 - accuracy: 0.8429\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3788 - accuracy: 0.8429\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3863 - accuracy: 0.8440\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3852 - accuracy: 0.8384\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3824 - accuracy: 0.8395\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3926 - accuracy: 0.8361\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3820 - accuracy: 0.8440\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3854 - accuracy: 0.8350\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3853 - accuracy: 0.8339\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3699 - accuracy: 0.8451\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3812 - accuracy: 0.8462\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3744 - accuracy: 0.8474\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3884 - accuracy: 0.8418\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3892 - accuracy: 0.8395\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3867 - accuracy: 0.8462\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3827 - accuracy: 0.8373\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3881 - accuracy: 0.8328\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3910 - accuracy: 0.8462\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3726 - accuracy: 0.8418\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3760 - accuracy: 0.8451\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3778 - accuracy: 0.8474\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3801 - accuracy: 0.8451\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3775 - accuracy: 0.8339\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3887 - accuracy: 0.8328\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3853 - accuracy: 0.8440\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3705 - accuracy: 0.8451\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3848 - accuracy: 0.8328\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3823 - accuracy: 0.8440\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3892 - accuracy: 0.8395\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3866 - accuracy: 0.8429\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3778 - accuracy: 0.8406\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3833 - accuracy: 0.8373\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3842 - accuracy: 0.8406\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3761 - accuracy: 0.8406\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3707 - accuracy: 0.8519\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3789 - accuracy: 0.8406\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3745 - accuracy: 0.8563\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3628 - accuracy: 0.8519\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3664 - accuracy: 0.8496\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3670 - accuracy: 0.8418\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3802 - accuracy: 0.8418\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3597 - accuracy: 0.8530\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3810 - accuracy: 0.8429\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3824 - accuracy: 0.8361\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3842 - accuracy: 0.8350\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3875 - accuracy: 0.8260\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3952 - accuracy: 0.8350\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3840 - accuracy: 0.8384\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3909 - accuracy: 0.8474\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3805 - accuracy: 0.8294\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3727 - accuracy: 0.8429\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3818 - accuracy: 0.8204\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3741 - accuracy: 0.8406\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3892 - accuracy: 0.8440\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3747 - accuracy: 0.8530\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3884 - accuracy: 0.8305\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3737 - accuracy: 0.8440\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3796 - accuracy: 0.8507\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3851 - accuracy: 0.8507\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3791 - accuracy: 0.8339\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3794 - accuracy: 0.8507\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3831 - accuracy: 0.8418\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3652 - accuracy: 0.8485\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3790 - accuracy: 0.8328\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3761 - accuracy: 0.8507\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3765 - accuracy: 0.8429\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3784 - accuracy: 0.8429\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3640 - accuracy: 0.8530\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3774 - accuracy: 0.8485\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3794 - accuracy: 0.8406\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3749 - accuracy: 0.8462\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3659 - accuracy: 0.8485\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3727 - accuracy: 0.8462\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3887 - accuracy: 0.8440\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3750 - accuracy: 0.8474\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3775 - accuracy: 0.8440\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3820 - accuracy: 0.8451\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3657 - accuracy: 0.8462\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3713 - accuracy: 0.8496\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3766 - accuracy: 0.8406\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3815 - accuracy: 0.8485\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3666 - accuracy: 0.8485\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3676 - accuracy: 0.8563\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3777 - accuracy: 0.8373\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3751 - accuracy: 0.8429\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3744 - accuracy: 0.8418\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3645 - accuracy: 0.8462\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3821 - accuracy: 0.8451\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3757 - accuracy: 0.8395\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3688 - accuracy: 0.8485\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3779 - accuracy: 0.8406\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3762 - accuracy: 0.8462\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3700 - accuracy: 0.8507\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3723 - accuracy: 0.8406\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 217us/step - loss: 0.3850 - accuracy: 0.8462\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3700 - accuracy: 0.8530\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3698 - accuracy: 0.8429\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3792 - accuracy: 0.8474\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3775 - accuracy: 0.8496\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3844 - accuracy: 0.8384\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3733 - accuracy: 0.8328\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3761 - accuracy: 0.8406\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3858 - accuracy: 0.8418\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3763 - accuracy: 0.8373\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3608 - accuracy: 0.8620\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3750 - accuracy: 0.8451\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3903 - accuracy: 0.8350\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3791 - accuracy: 0.8406\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3757 - accuracy: 0.8373\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3778 - accuracy: 0.8305\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3575 - accuracy: 0.8485\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3836 - accuracy: 0.8339\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3719 - accuracy: 0.8418\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3631 - accuracy: 0.8519\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3741 - accuracy: 0.8485\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3685 - accuracy: 0.8507\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3847 - accuracy: 0.8316\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3632 - accuracy: 0.8418\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3800 - accuracy: 0.8339\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3673 - accuracy: 0.8485\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3855 - accuracy: 0.8418\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3682 - accuracy: 0.8474\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3608 - accuracy: 0.8451\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3715 - accuracy: 0.8530\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3932 - accuracy: 0.8361\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3613 - accuracy: 0.8485\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3637 - accuracy: 0.8395\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3954 - accuracy: 0.8283\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3912 - accuracy: 0.8485\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3718 - accuracy: 0.8451\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3690 - accuracy: 0.8462\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3768 - accuracy: 0.8361\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3722 - accuracy: 0.8485\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3748 - accuracy: 0.8474\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3761 - accuracy: 0.8429\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.3918 - accuracy: 0.8395\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3808 - accuracy: 0.8361\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3736 - accuracy: 0.8395\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3777 - accuracy: 0.8451\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3640 - accuracy: 0.8474\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3619 - accuracy: 0.8575\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3746 - accuracy: 0.8429\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3804 - accuracy: 0.8429\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3784 - accuracy: 0.8530\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3704 - accuracy: 0.8485\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3639 - accuracy: 0.8485\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3835 - accuracy: 0.8474\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3689 - accuracy: 0.8485\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3839 - accuracy: 0.8406\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3771 - accuracy: 0.8462\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3575 - accuracy: 0.8563\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3636 - accuracy: 0.8563\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3660 - accuracy: 0.8552\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3833 - accuracy: 0.8519\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3639 - accuracy: 0.8552\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3671 - accuracy: 0.8462\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3806 - accuracy: 0.8507\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3796 - accuracy: 0.8429\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3863 - accuracy: 0.8406\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3659 - accuracy: 0.8541\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3769 - accuracy: 0.8451\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3778 - accuracy: 0.8395\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3691 - accuracy: 0.8519\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3765 - accuracy: 0.8418\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3766 - accuracy: 0.8395\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3839 - accuracy: 0.8485\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3725 - accuracy: 0.8485\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3724 - accuracy: 0.8384\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3816 - accuracy: 0.8429\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3795 - accuracy: 0.8485\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3659 - accuracy: 0.8519\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3503 - accuracy: 0.8597\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3735 - accuracy: 0.8384\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3721 - accuracy: 0.8507\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3670 - accuracy: 0.8485\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3596 - accuracy: 0.8507\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3689 - accuracy: 0.8429\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3656 - accuracy: 0.8496\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3634 - accuracy: 0.8474\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3698 - accuracy: 0.8451\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3587 - accuracy: 0.8474\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3658 - accuracy: 0.8541\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3707 - accuracy: 0.8519\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3598 - accuracy: 0.8507\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3795 - accuracy: 0.8485\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3634 - accuracy: 0.8507\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3817 - accuracy: 0.8440\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3745 - accuracy: 0.8429\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3538 - accuracy: 0.8653\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3946 - accuracy: 0.8406\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3647 - accuracy: 0.8429\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3765 - accuracy: 0.8462\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3736 - accuracy: 0.8462\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3722 - accuracy: 0.8384\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3644 - accuracy: 0.8563\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3624 - accuracy: 0.8462\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3566 - accuracy: 0.8552\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3686 - accuracy: 0.8418\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3848 - accuracy: 0.8406\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3683 - accuracy: 0.8496\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3800 - accuracy: 0.8395\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3643 - accuracy: 0.8541\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3596 - accuracy: 0.8485\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3740 - accuracy: 0.8384\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3577 - accuracy: 0.8586\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3649 - accuracy: 0.8519\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3761 - accuracy: 0.8395\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3737 - accuracy: 0.8305\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3691 - accuracy: 0.8440\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3811 - accuracy: 0.8395\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3592 - accuracy: 0.8485\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3537 - accuracy: 0.8597\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3778 - accuracy: 0.8418\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3836 - accuracy: 0.8429\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3752 - accuracy: 0.8373\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3454 - accuracy: 0.8664\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3813 - accuracy: 0.8384\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3755 - accuracy: 0.8440\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3625 - accuracy: 0.8429\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3813 - accuracy: 0.8406\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3722 - accuracy: 0.8462\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3702 - accuracy: 0.8462\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3654 - accuracy: 0.8530\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3438 - accuracy: 0.8653\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3488 - accuracy: 0.8485\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3789 - accuracy: 0.8530\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3647 - accuracy: 0.8552\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3747 - accuracy: 0.8384\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3660 - accuracy: 0.8496\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3858 - accuracy: 0.8474\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3776 - accuracy: 0.8496\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3684 - accuracy: 0.8563\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3600 - accuracy: 0.8474\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3616 - accuracy: 0.8474\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3692 - accuracy: 0.8395\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3714 - accuracy: 0.8474\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3648 - accuracy: 0.8451\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3852 - accuracy: 0.8406\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3768 - accuracy: 0.8451\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3568 - accuracy: 0.8507\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3723 - accuracy: 0.8350\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3676 - accuracy: 0.8485\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3775 - accuracy: 0.8440\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3536 - accuracy: 0.8563\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3633 - accuracy: 0.8474\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3761 - accuracy: 0.8395\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3785 - accuracy: 0.8440\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3733 - accuracy: 0.8406\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3789 - accuracy: 0.8339\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3711 - accuracy: 0.8395\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 225us/step - loss: 0.3918 - accuracy: 0.8474\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3696 - accuracy: 0.8530\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3620 - accuracy: 0.8519\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3691 - accuracy: 0.8563\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3731 - accuracy: 0.8440\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3777 - accuracy: 0.8418\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3560 - accuracy: 0.8496\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3564 - accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a75d7f750>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, nb_epoch=400, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12488109]\n",
      " [0.60282683]\n",
      " [0.057751  ]\n",
      " [0.10296798]\n",
      " [0.6260485 ]\n",
      " [0.93414557]\n",
      " [0.7289775 ]\n",
      " [0.12482855]\n",
      " [0.8673719 ]\n",
      " [0.11501488]\n",
      " [0.10066053]\n",
      " [0.14466897]\n",
      " [0.9867073 ]\n",
      " [0.11535552]\n",
      " [0.98650026]\n",
      " [0.94336134]\n",
      " [0.12392384]\n",
      " [0.08911794]\n",
      " [0.36351228]\n",
      " [0.7644911 ]\n",
      " [0.11242425]\n",
      " [0.8944812 ]\n",
      " [0.9922879 ]\n",
      " [0.16551569]\n",
      " [0.9332696 ]\n",
      " [0.12724793]\n",
      " [0.9605608 ]\n",
      " [0.08871305]\n",
      " [0.3791807 ]\n",
      " [0.11114493]\n",
      " [0.11511889]\n",
      " [0.11396646]\n",
      " [0.27894914]\n",
      " [0.20730054]\n",
      " [0.5922734 ]\n",
      " [0.09148276]\n",
      " [0.4074753 ]\n",
      " [0.36289477]\n",
      " [0.10278085]\n",
      " [0.5957577 ]\n",
      " [0.11009744]\n",
      " [0.4662186 ]\n",
      " [0.1279121 ]\n",
      " [0.86420244]\n",
      " [0.98168945]\n",
      " [0.09937075]\n",
      " [0.4255661 ]\n",
      " [0.11559424]\n",
      " [0.9234055 ]\n",
      " [0.26833117]\n",
      " [0.5425145 ]\n",
      " [0.08665287]\n",
      " [0.9851521 ]\n",
      " [0.9942742 ]\n",
      " [0.08527699]\n",
      " [0.12194505]\n",
      " [0.11793986]\n",
      " [0.12802944]\n",
      " [0.11606157]\n",
      " [0.9651036 ]\n",
      " [0.09776577]\n",
      " [0.10327208]\n",
      " [0.09458116]\n",
      " [0.7753259 ]\n",
      " [0.9801549 ]\n",
      " [0.94561666]\n",
      " [0.76787585]\n",
      " [0.17203715]\n",
      " [0.6099683 ]\n",
      " [0.93589413]\n",
      " [0.73910606]\n",
      " [0.09870064]\n",
      " [0.3414641 ]\n",
      " [0.6904903 ]\n",
      " [0.9288583 ]\n",
      " [0.2153149 ]\n",
      " [0.10066053]\n",
      " [0.9330946 ]\n",
      " [0.10323974]\n",
      " [0.73910606]\n",
      " [0.9192213 ]\n",
      " [0.12827724]\n",
      " [0.12849855]\n",
      " [0.10066053]\n",
      " [0.1273078 ]\n",
      " [0.09060633]\n",
      " [0.7234878 ]\n",
      " [0.31226686]\n",
      " [0.75659215]\n",
      " [0.9922869 ]\n",
      " [0.6273861 ]\n",
      " [0.09883422]\n",
      " [0.9713967 ]\n",
      " [0.10066053]\n",
      " [0.4405527 ]\n",
      " [0.09625483]\n",
      " [0.9960302 ]\n",
      " [0.10322973]\n",
      " [0.628425  ]\n",
      " [0.10167229]\n",
      " [0.9482193 ]\n",
      " [0.12331316]\n",
      " [0.11559424]\n",
      " [0.09740064]\n",
      " [0.89008486]\n",
      " [0.17818066]\n",
      " [0.10788926]\n",
      " [0.11559424]\n",
      " [0.09187388]\n",
      " [0.22228959]\n",
      " [0.10094953]\n",
      " [0.75659215]\n",
      " [0.94437516]\n",
      " [0.7878026 ]\n",
      " [0.99776024]\n",
      " [0.09023151]\n",
      " [0.08927828]\n",
      " [0.9057268 ]\n",
      " [0.4936651 ]\n",
      " [0.96713746]\n",
      " [0.9687648 ]\n",
      " [0.13310856]\n",
      " [0.9599647 ]\n",
      " [0.09908155]\n",
      " [0.11559424]\n",
      " [0.34011173]\n",
      " [0.09468549]\n",
      " [0.7726706 ]\n",
      " [0.1138064 ]\n",
      " [0.09907687]\n",
      " [0.11158261]\n",
      " [0.5553752 ]\n",
      " [0.18192798]\n",
      " [0.10354006]\n",
      " [0.13377315]\n",
      " [0.09510073]\n",
      " [0.08908951]\n",
      " [0.10353068]\n",
      " [0.38534975]\n",
      " [0.07758164]\n",
      " [0.02356297]\n",
      " [0.99549776]\n",
      " [0.04752243]\n",
      " [0.10206518]\n",
      " [0.18728673]\n",
      " [0.12248221]\n",
      " [0.2346442 ]\n",
      " [0.09060472]\n",
      " [0.36962968]\n",
      " [0.01363745]\n",
      " [0.97499394]\n",
      " [0.11231273]\n",
      " [0.175324  ]\n",
      " [0.46025407]\n",
      " [0.13684458]\n",
      " [0.09596291]\n",
      " [0.99543345]\n",
      " [0.58022624]\n",
      " [0.44228318]\n",
      " [0.5859497 ]\n",
      " [0.7801304 ]\n",
      " [0.91595197]\n",
      " [0.81275374]\n",
      " [0.09908155]\n",
      " [0.02560672]\n",
      " [0.55999166]\n",
      " [0.4079665 ]\n",
      " [0.1193682 ]\n",
      " [0.9654628 ]\n",
      " [0.14444208]\n",
      " [0.09925425]\n",
      " [0.08918384]\n",
      " [0.11618724]\n",
      " [0.08918384]\n",
      " [0.09301001]\n",
      " [0.9909476 ]\n",
      " [0.988304  ]\n",
      " [0.43685636]\n",
      " [0.7233984 ]\n",
      " [0.9945115 ]\n",
      " [0.10323974]\n",
      " [0.36477765]\n",
      " [0.9614521 ]\n",
      " [0.09320113]\n",
      " [0.970276  ]\n",
      " [0.10704592]\n",
      " [0.98036444]\n",
      " [0.11656985]\n",
      " [0.02305263]\n",
      " [0.09118551]\n",
      " [0.13177776]\n",
      " [0.3696295 ]\n",
      " [0.94162846]\n",
      " [0.05403492]\n",
      " [0.9946548 ]\n",
      " [0.10999063]\n",
      " [0.9944866 ]\n",
      " [0.657977  ]\n",
      " [0.09791484]\n",
      " [0.6115146 ]\n",
      " [0.9441793 ]\n",
      " [0.8753482 ]\n",
      " [0.69688433]\n",
      " [0.97448975]\n",
      " [0.09595037]\n",
      " [0.23167348]\n",
      " [0.89587   ]\n",
      " [0.09692815]\n",
      " [0.9529077 ]\n",
      " [0.09937075]\n",
      " [0.17260781]\n",
      " [0.09908155]\n",
      " [0.09890452]\n",
      " [0.9541019 ]\n",
      " [0.36931697]\n",
      " [0.32158726]\n",
      " [0.75659215]\n",
      " [0.12958008]\n",
      " [0.911994  ]\n",
      " [0.09228957]\n",
      " [0.920555  ]\n",
      " [0.09870064]\n",
      " [0.9120978 ]\n",
      " [0.09465945]\n",
      " [0.94398654]\n",
      " [0.49530977]\n",
      " [0.09473991]\n",
      " [0.75659215]\n",
      " [0.10848197]\n",
      " [0.10611549]\n",
      " [0.9599437 ]\n",
      " [0.9812044 ]\n",
      " [0.12254953]\n",
      " [0.11559424]\n",
      " [0.51322824]\n",
      " [0.09463331]\n",
      " [0.04718119]\n",
      " [0.08988827]\n",
      " [0.86438143]\n",
      " [0.95052314]\n",
      " [0.91945887]\n",
      " [0.8081285 ]\n",
      " [0.18759766]\n",
      " [0.09228957]\n",
      " [0.79082376]\n",
      " [0.44641513]\n",
      " [0.95552874]\n",
      " [0.12320545]\n",
      " [0.9671375 ]\n",
      " [0.61909777]\n",
      " [0.98453414]\n",
      " [0.09846622]\n",
      " [0.5332274 ]\n",
      " [0.09085593]\n",
      " [0.10823938]\n",
      " [0.09653288]\n",
      " [0.09320113]\n",
      " [0.1017462 ]\n",
      " [0.9723666 ]\n",
      " [0.09465945]\n",
      " [0.11961436]\n",
      " [0.09465945]\n",
      " [0.96545494]\n",
      " [0.78210837]\n",
      " [0.08707476]\n",
      " [0.10066053]\n",
      " [0.02657571]\n",
      " [0.09653291]\n",
      " [0.2480869 ]\n",
      " [0.10132086]\n",
      " [0.4263982 ]\n",
      " [0.11559424]\n",
      " [0.97258747]\n",
      " [0.90045494]\n",
      " [0.08918384]\n",
      " [0.9131    ]\n",
      " [0.09308663]\n",
      " [0.10199249]\n",
      " [0.09963426]\n",
      " [0.09891045]\n",
      " [0.34293222]\n",
      " [0.8753482 ]\n",
      " [0.75659215]\n",
      " [0.81043696]\n",
      " [0.7331269 ]\n",
      " [0.11745209]\n",
      " [0.09742182]\n",
      " [0.44763902]\n",
      " [0.27924848]\n",
      " [0.09228957]\n",
      " [0.12143365]\n",
      " [0.7289775 ]\n",
      " [0.08918384]\n",
      " [0.66967416]\n",
      " [0.11537328]\n",
      " [0.09995106]\n",
      " [0.96540606]\n",
      " [0.11114493]\n",
      " [0.38497034]\n",
      " [0.10159087]\n",
      " [0.10790932]\n",
      " [0.41595802]\n",
      " [0.11057216]\n",
      " [0.10248724]\n",
      " [0.75659215]\n",
      " [0.966017  ]\n",
      " [0.20737013]\n",
      " [0.88190055]\n",
      " [0.3945462 ]\n",
      " [0.42291445]\n",
      " [0.1013189 ]\n",
      " [0.08871305]\n",
      " [0.09925425]\n",
      " [0.610166  ]\n",
      " [0.9432696 ]\n",
      " [0.9384359 ]\n",
      " [0.39853242]\n",
      " [0.10195151]\n",
      " [0.09883422]\n",
      " [0.11130345]\n",
      " [0.09740064]\n",
      " [0.29723918]\n",
      " [0.16104093]\n",
      " [0.4294043 ]\n",
      " [0.9988972 ]\n",
      " [0.09258562]\n",
      " [0.7460903 ]\n",
      " [0.09346822]\n",
      " [0.09106624]\n",
      " [0.1015799 ]\n",
      " [0.9730023 ]\n",
      " [0.43794617]\n",
      " [0.08918384]\n",
      " [0.78628665]\n",
      " [0.10066053]\n",
      " [0.5165253 ]\n",
      " [0.10327208]\n",
      " [0.12857309]\n",
      " [0.08967558]\n",
      " [0.9428446 ]\n",
      " [0.1052689 ]\n",
      " [0.10402513]\n",
      " [0.04756129]\n",
      " [0.93025523]\n",
      " [0.9501775 ]\n",
      " [0.719453  ]\n",
      " [0.10353068]\n",
      " [0.8052722 ]\n",
      " [0.10270393]\n",
      " [0.9780656 ]\n",
      " [0.9477757 ]\n",
      " [0.09595045]\n",
      " [0.09962153]\n",
      " [0.12096882]\n",
      " [0.81018466]\n",
      " [0.33571285]\n",
      " [0.96986794]\n",
      " [0.09451213]\n",
      " [0.11559424]\n",
      " [0.5473313 ]\n",
      " [0.01571751]\n",
      " [0.9502002 ]\n",
      " [0.94859844]\n",
      " [0.10296798]\n",
      " [0.9745772 ]\n",
      " [0.0376673 ]\n",
      " [0.09060639]\n",
      " [0.29600185]\n",
      " [0.9387088 ]\n",
      " [0.08753771]\n",
      " [0.11060551]\n",
      " [0.9914202 ]\n",
      " [0.03199813]\n",
      " [0.1172401 ]\n",
      " [0.96397126]\n",
      " [0.9950545 ]\n",
      " [0.3468789 ]\n",
      " [0.09991506]\n",
      " [0.36608115]\n",
      " [0.13416272]\n",
      " [0.11559424]\n",
      " [0.11466822]\n",
      " [0.6048029 ]\n",
      " [0.62037575]\n",
      " [0.08936501]\n",
      " [0.9617499 ]\n",
      " [0.09510073]\n",
      " [0.137456  ]\n",
      " [0.10788926]\n",
      " [0.23319998]\n",
      " [0.4179769 ]\n",
      " [0.9638822 ]\n",
      " [0.9082662 ]\n",
      " [0.10101226]\n",
      " [0.11971533]\n",
      " [0.9847564 ]\n",
      " [0.11087358]\n",
      " [0.9393532 ]\n",
      " [0.09468549]\n",
      " [0.101116  ]\n",
      " [0.9952716 ]\n",
      " [0.10630059]\n",
      " [0.9812044 ]\n",
      " [0.38905376]\n",
      " [0.68769205]\n",
      " [0.5947675 ]\n",
      " [0.11153555]\n",
      " [0.14100203]\n",
      " [0.7801304 ]\n",
      " [0.77098036]\n",
      " [0.75659215]\n",
      " [0.99580723]\n",
      " [0.44964534]\n",
      " [0.09228957]\n",
      " [0.98972607]\n",
      " [0.11722648]\n",
      " [0.10066053]\n",
      " [0.91922134]]\n"
     ]
    }
   ],
   "source": [
    "# creamos un df para la entrega a Kaggle\n",
    "submission_NN= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "prediccion = model.predict(XtestFinal)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived\n",
       "891           892         0\n",
       "892           893         1\n",
       "893           894         0\n",
       "894           895         0\n",
       "895           896         1\n",
       "...           ...       ...\n",
       "1304         1305         0\n",
       "1305         1306         1\n",
       "1306         1307         0\n",
       "1307         1308         0\n",
       "1308         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobreviven = np.round(prediccion)\n",
    "arr = np.array(sobreviven)\n",
    "data=arr.flatten()\n",
    "submission_NN['Survived']=data\n",
    "submission_NN['Survived'] = submission_NN['Survived'].astype(int)\n",
    "submission_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN.to_csv(\"Submision_NN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un   0.80382  en Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratar de mejorar este resultado se crea una función específica. Esta funcion recoge la precision sobre los datos test en el *dataframe* contador para valorar si añadiendo una capa o aumentando o reduciendo el numero de neuronas y su activacion se pueden mejorar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_0(activacion, neurona, capa):\n",
    "    #print('dentro')\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(23, input_shape=(23,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activacion))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    for x in range(capa):\n",
    "        # hidden layers\n",
    "        model.add(Dense(neurona))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activacion))\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "    \n",
    "    model.add(Dense(neurona, activation=\"relu\"))    \n",
    "           \n",
    "    # output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # model compile for binary classification\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # learning\n",
    "    model.fit(X_train, y_train, nb_epoch=400, batch_size=30)\n",
    "    \n",
    "    \n",
    "    result = model.evaluate(X_test, y_test, batch_size=30)\n",
    "\n",
    "    #LO ENTRENAMOS CON TODOS LOS DATOS PARA SACAR LOS RESULTADOS FINALES\n",
    "    \n",
    "    model.fit(X, Y, nb_epoch=400, batch_size=30)\n",
    "    \n",
    "    sobreviven = np.round(model.predict(XtestFinal))\n",
    "    arr = np.array(sobreviven)\n",
    "    data=arr.flatten()\n",
    "\n",
    "    \n",
    "    return result,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 25, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.6838 - accuracy: 0.6180\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 369us/step - loss: 0.6081 - accuracy: 0.6404\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.6462 - accuracy: 0.6573\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5959 - accuracy: 0.7135\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.5841 - accuracy: 0.6517\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.6255 - accuracy: 0.6348\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.5928 - accuracy: 0.6966\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6045 - accuracy: 0.6742\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5836 - accuracy: 0.6685\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5885 - accuracy: 0.6742\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5639 - accuracy: 0.7022\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.5798 - accuracy: 0.7079\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.5771 - accuracy: 0.7472\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.5211 - accuracy: 0.7247\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5459 - accuracy: 0.7303\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.5366 - accuracy: 0.7360\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.5687 - accuracy: 0.7303\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.5313 - accuracy: 0.7753\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.5103 - accuracy: 0.7303\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.5747 - accuracy: 0.6910\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4875 - accuracy: 0.7528\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.5131 - accuracy: 0.7921\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5281 - accuracy: 0.7753\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.5470 - accuracy: 0.7191\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4943 - accuracy: 0.7809\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.5274 - accuracy: 0.7753\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5212 - accuracy: 0.7584\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.5359 - accuracy: 0.7865\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.5019 - accuracy: 0.7753\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5126 - accuracy: 0.7360\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4779 - accuracy: 0.7697\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.5196 - accuracy: 0.7416\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5193 - accuracy: 0.7640\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5288 - accuracy: 0.7640\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4977 - accuracy: 0.7921\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4974 - accuracy: 0.7865\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.4727 - accuracy: 0.7809\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.5074 - accuracy: 0.7528\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4809 - accuracy: 0.8146\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4826 - accuracy: 0.7978\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4718 - accuracy: 0.8146\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4536 - accuracy: 0.7921\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.5090 - accuracy: 0.7978\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4739 - accuracy: 0.8258\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5102 - accuracy: 0.7472\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4406 - accuracy: 0.8258\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4595 - accuracy: 0.8090\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4811 - accuracy: 0.7753\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4835 - accuracy: 0.7978\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4581 - accuracy: 0.8258\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4785 - accuracy: 0.8146\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4794 - accuracy: 0.7753\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4374 - accuracy: 0.8258\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4727 - accuracy: 0.7921\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5204 - accuracy: 0.7753\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4524 - accuracy: 0.8090\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4390 - accuracy: 0.8258\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4729 - accuracy: 0.8146\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.4127 - accuracy: 0.8371\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4379 - accuracy: 0.8146\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4712 - accuracy: 0.8146\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4218 - accuracy: 0.8371\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4620 - accuracy: 0.8090\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4679 - accuracy: 0.8146\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3966 - accuracy: 0.8258\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4807 - accuracy: 0.7921\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4660 - accuracy: 0.8146\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.4779 - accuracy: 0.8258\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4278 - accuracy: 0.8146\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4348 - accuracy: 0.8315\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.4320 - accuracy: 0.8371\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.4607 - accuracy: 0.7753\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.4482 - accuracy: 0.8090\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4327 - accuracy: 0.8315\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.4104 - accuracy: 0.8539\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4302 - accuracy: 0.8258\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.4433 - accuracy: 0.8146\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4478 - accuracy: 0.8427\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4288 - accuracy: 0.8371\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4287 - accuracy: 0.8539\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4139 - accuracy: 0.8539\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.4040 - accuracy: 0.8652\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4492 - accuracy: 0.8258\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4103 - accuracy: 0.8427\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7921\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3989 - accuracy: 0.8315\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.4466 - accuracy: 0.8034\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.4182 - accuracy: 0.8539\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3598 - accuracy: 0.8483\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4285 - accuracy: 0.8315\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4529 - accuracy: 0.7865\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3921 - accuracy: 0.8146\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4369 - accuracy: 0.8034\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.4157 - accuracy: 0.8596\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4451 - accuracy: 0.8202\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3969 - accuracy: 0.8427\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4138 - accuracy: 0.8371\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3791 - accuracy: 0.8315\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.4242 - accuracy: 0.8483\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4007 - accuracy: 0.8539\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.4055 - accuracy: 0.8483\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4307 - accuracy: 0.8483\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.4148 - accuracy: 0.7753\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4175 - accuracy: 0.8258\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4022 - accuracy: 0.8483\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3978 - accuracy: 0.8652\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3913 - accuracy: 0.8371\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4317 - accuracy: 0.8202\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4024 - accuracy: 0.8258\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4918 - accuracy: 0.8034\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4055 - accuracy: 0.8652\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4492 - accuracy: 0.7697\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4163 - accuracy: 0.8090\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.4336 - accuracy: 0.8146\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3649 - accuracy: 0.8652\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4288 - accuracy: 0.8315\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4177 - accuracy: 0.8034\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4024 - accuracy: 0.8315\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4220 - accuracy: 0.8371\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3985 - accuracy: 0.8371\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4177 - accuracy: 0.8146\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4338 - accuracy: 0.8202\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3860 - accuracy: 0.8539\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4152 - accuracy: 0.8427\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3958 - accuracy: 0.8539\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3762 - accuracy: 0.8652\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4196 - accuracy: 0.8090\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4240 - accuracy: 0.8539\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3737 - accuracy: 0.8427\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3880 - accuracy: 0.8315\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4205 - accuracy: 0.8258\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3885 - accuracy: 0.8315\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.3796 - accuracy: 0.8371\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3954 - accuracy: 0.8315\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.4018 - accuracy: 0.8427\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3960 - accuracy: 0.8483\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4034 - accuracy: 0.8539\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4059 - accuracy: 0.8427\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3988 - accuracy: 0.8539\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3638 - accuracy: 0.8708\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3967 - accuracy: 0.8371\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4045 - accuracy: 0.8258\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3946 - accuracy: 0.8427\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.3623 - accuracy: 0.8708\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3935 - accuracy: 0.8202\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3757 - accuracy: 0.8596\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3523 - accuracy: 0.8539\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3513 - accuracy: 0.8596\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3539 - accuracy: 0.8652\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4538 - accuracy: 0.8427\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3832 - accuracy: 0.8315\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4025 - accuracy: 0.8371\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3850 - accuracy: 0.8427\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3524 - accuracy: 0.8315\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3995 - accuracy: 0.8315\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.3761 - accuracy: 0.8652\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 165us/step - loss: 0.3967 - accuracy: 0.8539\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4199 - accuracy: 0.8371\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3499 - accuracy: 0.8652\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3562 - accuracy: 0.8652\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3348 - accuracy: 0.8315\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3552 - accuracy: 0.8483\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.3984 - accuracy: 0.8258\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3458 - accuracy: 0.8820\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.3711 - accuracy: 0.8427\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3931 - accuracy: 0.8258\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4008 - accuracy: 0.8146\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3587 - accuracy: 0.8483\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4199 - accuracy: 0.8258\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4060 - accuracy: 0.8315\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3899 - accuracy: 0.8483\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3496 - accuracy: 0.8258\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.3801 - accuracy: 0.8371\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.3297 - accuracy: 0.8596\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3968 - accuracy: 0.8315\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3703 - accuracy: 0.8708\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3398 - accuracy: 0.8820\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4046 - accuracy: 0.8315\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3784 - accuracy: 0.8539\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.3235 - accuracy: 0.8708\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3553 - accuracy: 0.8539\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3771 - accuracy: 0.8539\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3781 - accuracy: 0.8315\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.4066 - accuracy: 0.8258\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3653 - accuracy: 0.8090\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3605 - accuracy: 0.8483\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3851 - accuracy: 0.8539\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.3657 - accuracy: 0.8596\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3723 - accuracy: 0.8596\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3401 - accuracy: 0.8596\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3688 - accuracy: 0.8539\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3236 - accuracy: 0.8820\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3231 - accuracy: 0.8652\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3657 - accuracy: 0.8764\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3418 - accuracy: 0.8652\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3384 - accuracy: 0.8652\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.4029 - accuracy: 0.8371\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3872 - accuracy: 0.8315\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3203 - accuracy: 0.8708\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.3724 - accuracy: 0.8258\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3596 - accuracy: 0.8371\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3331 - accuracy: 0.8708\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4022 - accuracy: 0.8146\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.3454 - accuracy: 0.8427\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3350 - accuracy: 0.8539\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.3920 - accuracy: 0.8539\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3535 - accuracy: 0.8315\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.3307 - accuracy: 0.8708\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.3800 - accuracy: 0.8371\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3349 - accuracy: 0.8483\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3306 - accuracy: 0.8708\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4022 - accuracy: 0.8427\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4148 - accuracy: 0.8371\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.3301 - accuracy: 0.8539\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 180us/step - loss: 0.3478 - accuracy: 0.8539\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.3842 - accuracy: 0.8371\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3637 - accuracy: 0.8315\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.3236 - accuracy: 0.8876\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3549 - accuracy: 0.8539\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3168 - accuracy: 0.8483\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3526 - accuracy: 0.8596\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3297 - accuracy: 0.8652\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3490 - accuracy: 0.8876\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3204 - accuracy: 0.8989\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4131 - accuracy: 0.8483\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3717 - accuracy: 0.8427\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3587 - accuracy: 0.8708\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3347 - accuracy: 0.8708\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3406 - accuracy: 0.8652\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3508 - accuracy: 0.8483\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.3690 - accuracy: 0.8427\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.3242 - accuracy: 0.8596\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3601 - accuracy: 0.8427\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3496 - accuracy: 0.8483\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3407 - accuracy: 0.8427\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3879 - accuracy: 0.8371\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3675 - accuracy: 0.8371\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3243 - accuracy: 0.8371\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3511 - accuracy: 0.8596\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3430 - accuracy: 0.8596\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3333 - accuracy: 0.8820\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.3265 - accuracy: 0.8483\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3419 - accuracy: 0.8258\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3199 - accuracy: 0.8315\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3452 - accuracy: 0.8371\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4021 - accuracy: 0.8202\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3342 - accuracy: 0.8539\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3612 - accuracy: 0.8652\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3148 - accuracy: 0.8820\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3394 - accuracy: 0.8652\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3673 - accuracy: 0.8596\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3669 - accuracy: 0.8539\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.2740 - accuracy: 0.8933\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3456 - accuracy: 0.8764\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3104 - accuracy: 0.8708\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.2882 - accuracy: 0.8652\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.3361 - accuracy: 0.8652\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3323 - accuracy: 0.8596\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3623 - accuracy: 0.8539\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3438 - accuracy: 0.8315\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3669 - accuracy: 0.8427\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3669 - accuracy: 0.8202\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.2854 - accuracy: 0.8989\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3314 - accuracy: 0.8652\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3692 - accuracy: 0.8483\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.3653 - accuracy: 0.8202\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3303 - accuracy: 0.8596\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3777 - accuracy: 0.8596\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3585 - accuracy: 0.8427\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3465 - accuracy: 0.8596\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.3366 - accuracy: 0.8539\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.3577 - accuracy: 0.8483\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3063 - accuracy: 0.8652\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3028 - accuracy: 0.8876\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.3552 - accuracy: 0.8315\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3090 - accuracy: 0.8539\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3510 - accuracy: 0.8652\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3289 - accuracy: 0.8427\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4120 - accuracy: 0.7978\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.3508 - accuracy: 0.8483\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3371 - accuracy: 0.8764\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.3353 - accuracy: 0.8596\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3172 - accuracy: 0.8764\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.3495 - accuracy: 0.8652\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3570 - accuracy: 0.8539\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3644 - accuracy: 0.8652\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3448 - accuracy: 0.8596\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4205 - accuracy: 0.8596\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3300 - accuracy: 0.8652\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.3487 - accuracy: 0.8764\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.3041 - accuracy: 0.8876\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.3196 - accuracy: 0.8764\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3005 - accuracy: 0.8933\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3471 - accuracy: 0.8483\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2923 - accuracy: 0.8764\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3209 - accuracy: 0.8764\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3099 - accuracy: 0.8652\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.3703 - accuracy: 0.8483\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3579 - accuracy: 0.8483\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.2955 - accuracy: 0.9045\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3612 - accuracy: 0.8483\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3351 - accuracy: 0.8876\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3139 - accuracy: 0.8708\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3101 - accuracy: 0.8539\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3596 - accuracy: 0.8708\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3181 - accuracy: 0.8764\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.2833 - accuracy: 0.8708\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3247 - accuracy: 0.8764\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3252 - accuracy: 0.8764\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3663 - accuracy: 0.8596\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3247 - accuracy: 0.8820\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3327 - accuracy: 0.8371\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 169us/step - loss: 0.3287 - accuracy: 0.8708\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.3490 - accuracy: 0.8820\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.3272 - accuracy: 0.8652\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.3420 - accuracy: 0.8876\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.3323 - accuracy: 0.8596\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.2862 - accuracy: 0.8933\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.3182 - accuracy: 0.8820\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.3136 - accuracy: 0.8764\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.3096 - accuracy: 0.8708\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3291 - accuracy: 0.8596\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.3434 - accuracy: 0.8764\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.3587 - accuracy: 0.8539\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2972 - accuracy: 0.8652\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3611 - accuracy: 0.8258\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3207 - accuracy: 0.8596\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3194 - accuracy: 0.8876\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3682 - accuracy: 0.8483\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.3049 - accuracy: 0.8764\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3170 - accuracy: 0.8539\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.3045 - accuracy: 0.8933\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.3335 - accuracy: 0.8483\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.3446 - accuracy: 0.8539\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.3415 - accuracy: 0.8596\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3157 - accuracy: 0.8764\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3530 - accuracy: 0.8652\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2996 - accuracy: 0.8820\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.2820 - accuracy: 0.8933\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3207 - accuracy: 0.8820\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3036 - accuracy: 0.8708\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3170 - accuracy: 0.8876\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3267 - accuracy: 0.8876\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2769 - accuracy: 0.8933\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.2813 - accuracy: 0.9045\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3166 - accuracy: 0.8820\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3117 - accuracy: 0.8876\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3073 - accuracy: 0.8876\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3257 - accuracy: 0.8652\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.3637 - accuracy: 0.8371\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3198 - accuracy: 0.8933\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2975 - accuracy: 0.8876\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3308 - accuracy: 0.8596\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3154 - accuracy: 0.8820\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3191 - accuracy: 0.8876\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3094 - accuracy: 0.8820\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3126 - accuracy: 0.8708\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.3236 - accuracy: 0.8539\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2947 - accuracy: 0.8933\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.2889 - accuracy: 0.8989\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.2947 - accuracy: 0.8708\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.3102 - accuracy: 0.8596\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.3004 - accuracy: 0.8764\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3051 - accuracy: 0.8820\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3114 - accuracy: 0.8652\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3154 - accuracy: 0.8652\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.3596 - accuracy: 0.8820\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3264 - accuracy: 0.8483\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3463 - accuracy: 0.8652\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.2852 - accuracy: 0.8820\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.2964 - accuracy: 0.8989\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2776 - accuracy: 0.8764\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3308 - accuracy: 0.8708\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.3134 - accuracy: 0.8708\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.3004 - accuracy: 0.8764\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.3761 - accuracy: 0.8596\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3944 - accuracy: 0.8539\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 255us/step - loss: 0.3159 - accuracy: 0.8708\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3451 - accuracy: 0.8483\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.3003 - accuracy: 0.8820\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3377 - accuracy: 0.8483\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.3225 - accuracy: 0.8596\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3128 - accuracy: 0.8764\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3176 - accuracy: 0.8652\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3467 - accuracy: 0.8596\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.3187 - accuracy: 0.8652\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3446 - accuracy: 0.8764\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3364 - accuracy: 0.8708\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.3374 - accuracy: 0.8652\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3382 - accuracy: 0.8539\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.2693 - accuracy: 0.9213\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.3213 - accuracy: 0.8539\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.3826 - accuracy: 0.8539\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.3291 - accuracy: 0.8427\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.3342 - accuracy: 0.8652\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2751 - accuracy: 0.8876\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.2867 - accuracy: 0.9101\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.3145 - accuracy: 0.8596\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.2671 - accuracy: 0.9101\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.3474 - accuracy: 0.8820\n",
      "713/713 [==============================] - 0s 680us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.5043 - accuracy: 0.8002\n",
      "Epoch 2/400\n",
      " 30/891 [>.............................] - ETA: 0s - loss: 0.7121 - accuracy: 0.7000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 195us/step - loss: 0.4664 - accuracy: 0.8036\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.4501 - accuracy: 0.8002\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.4491 - accuracy: 0.8114\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4272 - accuracy: 0.8126\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4235 - accuracy: 0.8159\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4530 - accuracy: 0.7946\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4361 - accuracy: 0.8159\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.4288 - accuracy: 0.8182\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.4232 - accuracy: 0.8272\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4323 - accuracy: 0.8159\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4294 - accuracy: 0.8159\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4132 - accuracy: 0.8260\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4165 - accuracy: 0.8227\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4166 - accuracy: 0.8204\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.4165 - accuracy: 0.8204\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.4090 - accuracy: 0.8316\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.4231 - accuracy: 0.8137\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.4398 - accuracy: 0.8204\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.4207 - accuracy: 0.8305\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.4278 - accuracy: 0.8092\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.4188 - accuracy: 0.8294\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4310 - accuracy: 0.8215\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4326 - accuracy: 0.8227\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4123 - accuracy: 0.8350\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4264 - accuracy: 0.8361\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4134 - accuracy: 0.8193\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4163 - accuracy: 0.8193\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4221 - accuracy: 0.8204\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4128 - accuracy: 0.8283\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4262 - accuracy: 0.8182\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4206 - accuracy: 0.8215\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4172 - accuracy: 0.8215\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4015 - accuracy: 0.8339\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4224 - accuracy: 0.8227\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.3936 - accuracy: 0.8328\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4130 - accuracy: 0.8283\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4128 - accuracy: 0.8283\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4098 - accuracy: 0.8305\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4105 - accuracy: 0.8260\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3845 - accuracy: 0.8440\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4287 - accuracy: 0.8305\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4100 - accuracy: 0.8294\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4087 - accuracy: 0.8215\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.4213 - accuracy: 0.8305\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4068 - accuracy: 0.8350\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3987 - accuracy: 0.8350\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4105 - accuracy: 0.8373\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3972 - accuracy: 0.8339\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4140 - accuracy: 0.8182\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.4103 - accuracy: 0.8316\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4110 - accuracy: 0.8316\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3998 - accuracy: 0.8316\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4113 - accuracy: 0.8294\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4019 - accuracy: 0.8361\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4045 - accuracy: 0.8283\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.4056 - accuracy: 0.8249\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4052 - accuracy: 0.8249\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3994 - accuracy: 0.8272\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4021 - accuracy: 0.8283\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4060 - accuracy: 0.8328\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4210 - accuracy: 0.8305\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4111 - accuracy: 0.8283\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4053 - accuracy: 0.8328\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3946 - accuracy: 0.8395\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4076 - accuracy: 0.8350\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3944 - accuracy: 0.8328\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3935 - accuracy: 0.8384\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3826 - accuracy: 0.8384\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4097 - accuracy: 0.8294\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4120 - accuracy: 0.8328\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4007 - accuracy: 0.8283\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3974 - accuracy: 0.8406\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.4111 - accuracy: 0.8272\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4021 - accuracy: 0.8305\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3991 - accuracy: 0.8361\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3981 - accuracy: 0.8418\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3988 - accuracy: 0.8384\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4076 - accuracy: 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4136 - accuracy: 0.8249\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4023 - accuracy: 0.8260\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4021 - accuracy: 0.8328\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3967 - accuracy: 0.8384\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3960 - accuracy: 0.8373\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.3950 - accuracy: 0.8485\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3957 - accuracy: 0.8406\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4143 - accuracy: 0.8305\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3981 - accuracy: 0.8429\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3772 - accuracy: 0.8451\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4037 - accuracy: 0.8305\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.3998 - accuracy: 0.8440\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3802 - accuracy: 0.8373\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3824 - accuracy: 0.8462\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3821 - accuracy: 0.8418\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3969 - accuracy: 0.8395\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4029 - accuracy: 0.8361\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4062 - accuracy: 0.8361\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4019 - accuracy: 0.8496\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4121 - accuracy: 0.8238\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3944 - accuracy: 0.8350\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4078 - accuracy: 0.8272\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3771 - accuracy: 0.8451\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3928 - accuracy: 0.8406\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.3873 - accuracy: 0.8418\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3807 - accuracy: 0.8373\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.3894 - accuracy: 0.8440\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3858 - accuracy: 0.8395\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3821 - accuracy: 0.8328\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4041 - accuracy: 0.8260\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3943 - accuracy: 0.8305\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3867 - accuracy: 0.8496\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4080 - accuracy: 0.8384\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3828 - accuracy: 0.8485\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4078 - accuracy: 0.8283\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3894 - accuracy: 0.8361\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3943 - accuracy: 0.8418\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3989 - accuracy: 0.8339\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3775 - accuracy: 0.8519\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4083 - accuracy: 0.8294\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3823 - accuracy: 0.8395\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.3972 - accuracy: 0.8373\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3910 - accuracy: 0.8406\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3982 - accuracy: 0.8260\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.3976 - accuracy: 0.8373\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.3986 - accuracy: 0.8316\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.3993 - accuracy: 0.8350\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4104 - accuracy: 0.8361\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.3813 - accuracy: 0.8451\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3971 - accuracy: 0.8440\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.3942 - accuracy: 0.8193\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.3911 - accuracy: 0.8440\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3861 - accuracy: 0.8485\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3835 - accuracy: 0.8373\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3868 - accuracy: 0.8429\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3850 - accuracy: 0.8305\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4026 - accuracy: 0.8227\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3764 - accuracy: 0.8462\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3913 - accuracy: 0.8339\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3990 - accuracy: 0.8305\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3940 - accuracy: 0.8507\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3962 - accuracy: 0.8316\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3881 - accuracy: 0.8462\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3922 - accuracy: 0.8328\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3840 - accuracy: 0.8530\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3947 - accuracy: 0.8496\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3972 - accuracy: 0.8361\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4009 - accuracy: 0.8260\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3989 - accuracy: 0.8294\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3964 - accuracy: 0.8305\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3827 - accuracy: 0.8474\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3882 - accuracy: 0.8429\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.4041 - accuracy: 0.8350\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3888 - accuracy: 0.8418\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3789 - accuracy: 0.8373\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.3781 - accuracy: 0.8406\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3790 - accuracy: 0.8507\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.3725 - accuracy: 0.8451\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3859 - accuracy: 0.8395\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.3752 - accuracy: 0.8440\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.3767 - accuracy: 0.8406\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3896 - accuracy: 0.8429\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3858 - accuracy: 0.8474\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3917 - accuracy: 0.8361\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3784 - accuracy: 0.8474\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3860 - accuracy: 0.8451\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3869 - accuracy: 0.8395\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.3969 - accuracy: 0.8361\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3878 - accuracy: 0.8395\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.3717 - accuracy: 0.8496\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3824 - accuracy: 0.8563\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3992 - accuracy: 0.8350\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3778 - accuracy: 0.8485\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.3746 - accuracy: 0.8418\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4080 - accuracy: 0.8316\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3994 - accuracy: 0.8361\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3960 - accuracy: 0.8294\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3854 - accuracy: 0.8541\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3792 - accuracy: 0.8451\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3850 - accuracy: 0.8519\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3880 - accuracy: 0.8451\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.3765 - accuracy: 0.8563\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3839 - accuracy: 0.8361\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3755 - accuracy: 0.8395\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3736 - accuracy: 0.8474\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3795 - accuracy: 0.8440\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4083 - accuracy: 0.8283\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4015 - accuracy: 0.8294\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4061 - accuracy: 0.8429\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3846 - accuracy: 0.8384\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.3762 - accuracy: 0.8474\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3813 - accuracy: 0.8429\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3751 - accuracy: 0.8519\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3723 - accuracy: 0.8474\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3685 - accuracy: 0.8519\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3757 - accuracy: 0.8485\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.3721 - accuracy: 0.8575\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.3895 - accuracy: 0.8283\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3740 - accuracy: 0.8485\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3789 - accuracy: 0.8451\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3906 - accuracy: 0.8395\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3813 - accuracy: 0.8384\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3896 - accuracy: 0.8373\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3905 - accuracy: 0.8350\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3776 - accuracy: 0.8485\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.3724 - accuracy: 0.8406\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3996 - accuracy: 0.8272\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3889 - accuracy: 0.8429\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3820 - accuracy: 0.8462\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3821 - accuracy: 0.8406\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3821 - accuracy: 0.8552\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3756 - accuracy: 0.8418\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3893 - accuracy: 0.8406\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3740 - accuracy: 0.8406\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.3971 - accuracy: 0.8462\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.3842 - accuracy: 0.8384\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.3754 - accuracy: 0.8440\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.3794 - accuracy: 0.8418\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.3665 - accuracy: 0.8541\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3973 - accuracy: 0.8361\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3854 - accuracy: 0.8451\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3745 - accuracy: 0.8485\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3905 - accuracy: 0.8373\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3981 - accuracy: 0.8395\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3818 - accuracy: 0.8395\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3820 - accuracy: 0.8462\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3904 - accuracy: 0.8373\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.3829 - accuracy: 0.8384\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3750 - accuracy: 0.8541\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 173us/step - loss: 0.3883 - accuracy: 0.8395\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3777 - accuracy: 0.8440\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3862 - accuracy: 0.8496\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3697 - accuracy: 0.8451\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3720 - accuracy: 0.8474\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3659 - accuracy: 0.8519\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3732 - accuracy: 0.8406\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 157us/step - loss: 0.3876 - accuracy: 0.8519\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3731 - accuracy: 0.8462\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3862 - accuracy: 0.8384\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3876 - accuracy: 0.8350\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3907 - accuracy: 0.8350\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3645 - accuracy: 0.8575\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3700 - accuracy: 0.8496\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3786 - accuracy: 0.8451\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3852 - accuracy: 0.8384\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3652 - accuracy: 0.8519\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3785 - accuracy: 0.8361\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3680 - accuracy: 0.8496\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3831 - accuracy: 0.8451\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.3899 - accuracy: 0.8406\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3908 - accuracy: 0.8339\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3879 - accuracy: 0.8350\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3930 - accuracy: 0.8373\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3737 - accuracy: 0.8462\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3957 - accuracy: 0.8462\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3809 - accuracy: 0.8395\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3768 - accuracy: 0.8406\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4029 - accuracy: 0.8339\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3752 - accuracy: 0.8552\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3735 - accuracy: 0.8418\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.3629 - accuracy: 0.8474\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.3862 - accuracy: 0.8451\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3815 - accuracy: 0.8507\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.3969 - accuracy: 0.8373\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.3846 - accuracy: 0.8328\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3815 - accuracy: 0.8496\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3677 - accuracy: 0.8541\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3736 - accuracy: 0.8575\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3863 - accuracy: 0.8373\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3882 - accuracy: 0.8395\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3769 - accuracy: 0.8485\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3860 - accuracy: 0.8350\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3843 - accuracy: 0.8474\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3939 - accuracy: 0.8373\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3695 - accuracy: 0.8440\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3711 - accuracy: 0.8474\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3889 - accuracy: 0.8406\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3794 - accuracy: 0.8384\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3760 - accuracy: 0.8429\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3835 - accuracy: 0.8474\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3761 - accuracy: 0.8395\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3801 - accuracy: 0.8530\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3782 - accuracy: 0.8485\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3698 - accuracy: 0.8451\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3853 - accuracy: 0.8384\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3669 - accuracy: 0.8496\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3959 - accuracy: 0.8395\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3784 - accuracy: 0.8440\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3900 - accuracy: 0.8384\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3733 - accuracy: 0.8519\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3831 - accuracy: 0.8462\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3736 - accuracy: 0.8462\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3570 - accuracy: 0.8507\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3811 - accuracy: 0.8406\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3772 - accuracy: 0.8462\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3829 - accuracy: 0.8496\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3848 - accuracy: 0.8361\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3842 - accuracy: 0.8395\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3764 - accuracy: 0.8507\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3672 - accuracy: 0.8597\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3698 - accuracy: 0.8406\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3845 - accuracy: 0.8462\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3621 - accuracy: 0.8395\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3558 - accuracy: 0.8474\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3895 - accuracy: 0.8361\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.3855 - accuracy: 0.8305\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3801 - accuracy: 0.8440\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3850 - accuracy: 0.8316\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3856 - accuracy: 0.8384\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3874 - accuracy: 0.8294\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3633 - accuracy: 0.8597\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3711 - accuracy: 0.8474\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3670 - accuracy: 0.8530\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3713 - accuracy: 0.8451\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3780 - accuracy: 0.8485\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.3750 - accuracy: 0.8507\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3763 - accuracy: 0.8373\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3724 - accuracy: 0.8474\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3648 - accuracy: 0.8519\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3631 - accuracy: 0.8541\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3748 - accuracy: 0.8552\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3665 - accuracy: 0.8507\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3902 - accuracy: 0.8429\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3759 - accuracy: 0.8339\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4022 - accuracy: 0.8361\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3647 - accuracy: 0.8485\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3723 - accuracy: 0.8563\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3551 - accuracy: 0.8485\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3765 - accuracy: 0.8406\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3786 - accuracy: 0.8440\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3709 - accuracy: 0.8507\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3703 - accuracy: 0.8474\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3704 - accuracy: 0.8451\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3825 - accuracy: 0.8429\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3802 - accuracy: 0.8474\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.3727 - accuracy: 0.8406\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3786 - accuracy: 0.8418\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3790 - accuracy: 0.8395\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3893 - accuracy: 0.8361\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3827 - accuracy: 0.8305\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3676 - accuracy: 0.8451\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3636 - accuracy: 0.8440\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3760 - accuracy: 0.8406\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3721 - accuracy: 0.8462\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3813 - accuracy: 0.8418\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3684 - accuracy: 0.8552\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3724 - accuracy: 0.8406\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3652 - accuracy: 0.8474\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3817 - accuracy: 0.8440\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3719 - accuracy: 0.8406\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3710 - accuracy: 0.8429\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3729 - accuracy: 0.8541\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3677 - accuracy: 0.8541\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3682 - accuracy: 0.8418\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3716 - accuracy: 0.8406\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3521 - accuracy: 0.8620\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3627 - accuracy: 0.8462\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3822 - accuracy: 0.8361\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3823 - accuracy: 0.8429\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3738 - accuracy: 0.8440\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3562 - accuracy: 0.8687\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3863 - accuracy: 0.8361\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3608 - accuracy: 0.8485\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3821 - accuracy: 0.8530\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3871 - accuracy: 0.8361\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3857 - accuracy: 0.8485\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3649 - accuracy: 0.8586\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3671 - accuracy: 0.8496\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3839 - accuracy: 0.8395\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3727 - accuracy: 0.8541\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.3666 - accuracy: 0.8541\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3711 - accuracy: 0.8519\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3752 - accuracy: 0.8406\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3713 - accuracy: 0.8519\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3833 - accuracy: 0.8361\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3744 - accuracy: 0.8395\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.3755 - accuracy: 0.8462\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3825 - accuracy: 0.8395\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3764 - accuracy: 0.8451\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3861 - accuracy: 0.8361\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3858 - accuracy: 0.8451\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3698 - accuracy: 0.8608\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3740 - accuracy: 0.8418\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3744 - accuracy: 0.8462\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3675 - accuracy: 0.8440\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3673 - accuracy: 0.8395\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3759 - accuracy: 0.8395\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3729 - accuracy: 0.8530\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3763 - accuracy: 0.8575\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3527 - accuracy: 0.8507\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3706 - accuracy: 0.8485\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3699 - accuracy: 0.8563\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 152us/step - loss: 0.3688 - accuracy: 0.8541\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3730 - accuracy: 0.8339\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3923 - accuracy: 0.8373\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3885 - accuracy: 0.8283\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.3658 - accuracy: 0.8608\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3624 - accuracy: 0.8552\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3647 - accuracy: 0.8496\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.3663 - accuracy: 0.8429\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 25, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 4s 22ms/step - loss: 0.7441 - accuracy: 0.6685\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.7042 - accuracy: 0.6236\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.7733 - accuracy: 0.6629\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.7066 - accuracy: 0.6292\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.6714 - accuracy: 0.6854\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.6334 - accuracy: 0.6854\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.6582 - accuracy: 0.6517\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.6980 - accuracy: 0.6348\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.6065 - accuracy: 0.6966\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.6560 - accuracy: 0.6573\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.5810 - accuracy: 0.7079\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.6659 - accuracy: 0.6292\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.5972 - accuracy: 0.6798\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.6281 - accuracy: 0.6292\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.5743 - accuracy: 0.6742\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.6125 - accuracy: 0.6910\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5270 - accuracy: 0.7472\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.5927 - accuracy: 0.6910\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5705 - accuracy: 0.6910\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.5665 - accuracy: 0.7079\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.5842 - accuracy: 0.7191\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5699 - accuracy: 0.6798\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.5142 - accuracy: 0.7697\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5572 - accuracy: 0.7360\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.5580 - accuracy: 0.7135\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5378 - accuracy: 0.7640\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.5884 - accuracy: 0.6854\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.5382 - accuracy: 0.7079\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5689 - accuracy: 0.6966\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5333 - accuracy: 0.7360\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5127 - accuracy: 0.7640\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.5587 - accuracy: 0.7472\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5203 - accuracy: 0.7528\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5249 - accuracy: 0.7697\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5510 - accuracy: 0.7584\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5225 - accuracy: 0.7416\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5506 - accuracy: 0.7303\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.5361 - accuracy: 0.7247\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5209 - accuracy: 0.7247\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4694 - accuracy: 0.7697\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5064 - accuracy: 0.7472\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.5126 - accuracy: 0.7640\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4694 - accuracy: 0.7472\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5234 - accuracy: 0.7247\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5201 - accuracy: 0.7472\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4849 - accuracy: 0.7697\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5304 - accuracy: 0.7360\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.5277 - accuracy: 0.7416\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4806 - accuracy: 0.7865\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4519 - accuracy: 0.7921\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5038 - accuracy: 0.7528\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5233 - accuracy: 0.7584\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.5209 - accuracy: 0.7697\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4884 - accuracy: 0.7978\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4899 - accuracy: 0.7978\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5243 - accuracy: 0.7472\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.5163 - accuracy: 0.7191\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4831 - accuracy: 0.7978\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4965 - accuracy: 0.7640\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4721 - accuracy: 0.7528\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4913 - accuracy: 0.7640\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4527 - accuracy: 0.7921\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.5425 - accuracy: 0.7472\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4997 - accuracy: 0.7640\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4655 - accuracy: 0.7528\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4611 - accuracy: 0.8146\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4318 - accuracy: 0.8090\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4946 - accuracy: 0.7809\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4630 - accuracy: 0.8315\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4503 - accuracy: 0.7978\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4764 - accuracy: 0.7921\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4401 - accuracy: 0.7697\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4724 - accuracy: 0.7753\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4811 - accuracy: 0.8034\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4301 - accuracy: 0.7921\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5162 - accuracy: 0.7584\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4863 - accuracy: 0.8090\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4529 - accuracy: 0.8090\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4451 - accuracy: 0.8034\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.5210 - accuracy: 0.7528\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.5016 - accuracy: 0.7584\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4881 - accuracy: 0.7865\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4712 - accuracy: 0.8034\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4619 - accuracy: 0.7978\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4566 - accuracy: 0.8090\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4552 - accuracy: 0.8146\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4982 - accuracy: 0.7921\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4756 - accuracy: 0.8034\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4643 - accuracy: 0.7697\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4851 - accuracy: 0.7921\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4601 - accuracy: 0.7753\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.4544 - accuracy: 0.7978\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4477 - accuracy: 0.8146\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4402 - accuracy: 0.8090\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4365 - accuracy: 0.8202\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4851 - accuracy: 0.7865\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4426 - accuracy: 0.7753\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4178 - accuracy: 0.8202\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4144 - accuracy: 0.7865\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4284 - accuracy: 0.8034\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4654 - accuracy: 0.7753\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4085 - accuracy: 0.8034\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4483 - accuracy: 0.8258\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4075 - accuracy: 0.8146\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3735 - accuracy: 0.8539\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4418 - accuracy: 0.8090\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4825 - accuracy: 0.7640\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4631 - accuracy: 0.7809\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4299 - accuracy: 0.8090\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4077 - accuracy: 0.8146\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4372 - accuracy: 0.8034\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4694 - accuracy: 0.7865\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 258us/step - loss: 0.4305 - accuracy: 0.8315\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.4566 - accuracy: 0.8258\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3870 - accuracy: 0.8596\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4194 - accuracy: 0.8090\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4117 - accuracy: 0.7978\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4196 - accuracy: 0.8146\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4173 - accuracy: 0.8034\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4228 - accuracy: 0.8146\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4204 - accuracy: 0.8034\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4509 - accuracy: 0.8371\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4480 - accuracy: 0.8090\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4185 - accuracy: 0.7809\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4590 - accuracy: 0.8034\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.3942 - accuracy: 0.8315\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4889 - accuracy: 0.7697\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4214 - accuracy: 0.8315\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4645 - accuracy: 0.7978\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4336 - accuracy: 0.8146\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4374 - accuracy: 0.7809\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4202 - accuracy: 0.8483\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4679 - accuracy: 0.8146\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4400 - accuracy: 0.8202\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4296 - accuracy: 0.8034\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4012 - accuracy: 0.8034\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4036 - accuracy: 0.8090\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3957 - accuracy: 0.8315\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4065 - accuracy: 0.8090\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4053 - accuracy: 0.8146\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4147 - accuracy: 0.8539\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4244 - accuracy: 0.8315\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4142 - accuracy: 0.8202\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4449 - accuracy: 0.8146\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4056 - accuracy: 0.8090\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3992 - accuracy: 0.8202\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4065 - accuracy: 0.8202\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4069 - accuracy: 0.8596\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3776 - accuracy: 0.8483\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4439 - accuracy: 0.7921\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4072 - accuracy: 0.8371\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4117 - accuracy: 0.8202\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4113 - accuracy: 0.8146\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4176 - accuracy: 0.8146\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3972 - accuracy: 0.8146\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4016 - accuracy: 0.8090\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 193us/step - loss: 0.3819 - accuracy: 0.8427\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4069 - accuracy: 0.8258\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.4261 - accuracy: 0.8146\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4265 - accuracy: 0.8371\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4579 - accuracy: 0.7978\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4056 - accuracy: 0.8202\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3636 - accuracy: 0.8146\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4131 - accuracy: 0.8034\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4302 - accuracy: 0.8034\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4194 - accuracy: 0.7865\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3725 - accuracy: 0.8483\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4284 - accuracy: 0.7978\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.3723 - accuracy: 0.8483\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3792 - accuracy: 0.8483\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3709 - accuracy: 0.8202\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3923 - accuracy: 0.8427\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3896 - accuracy: 0.8090\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3697 - accuracy: 0.8596\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3991 - accuracy: 0.8202\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.3788 - accuracy: 0.8596\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4090 - accuracy: 0.8146\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4384 - accuracy: 0.8258\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3839 - accuracy: 0.8427\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.3674 - accuracy: 0.8596\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3747 - accuracy: 0.8427\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3318 - accuracy: 0.8596\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5167 - accuracy: 0.7978\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.3785 - accuracy: 0.8146\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3756 - accuracy: 0.8427\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3867 - accuracy: 0.8146\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3942 - accuracy: 0.8258\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3657 - accuracy: 0.8483\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3687 - accuracy: 0.8258\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3960 - accuracy: 0.8539\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3432 - accuracy: 0.8596\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.3949 - accuracy: 0.8315\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3811 - accuracy: 0.8258\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4863 - accuracy: 0.8315\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.3631 - accuracy: 0.8483\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4214 - accuracy: 0.8427\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3980 - accuracy: 0.8202\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.3847 - accuracy: 0.8371\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4091 - accuracy: 0.7978\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.3991 - accuracy: 0.8371\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4052 - accuracy: 0.8315\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3933 - accuracy: 0.8483\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3804 - accuracy: 0.8596\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3999 - accuracy: 0.8146\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4205 - accuracy: 0.7978\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3534 - accuracy: 0.8596\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3370 - accuracy: 0.8708\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.3841 - accuracy: 0.8596\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3896 - accuracy: 0.8258\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3719 - accuracy: 0.8146\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4219 - accuracy: 0.8090\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.4175 - accuracy: 0.8315\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.3937 - accuracy: 0.8315\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4450 - accuracy: 0.7753\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4058 - accuracy: 0.8202\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3976 - accuracy: 0.8371\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3827 - accuracy: 0.8371\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3482 - accuracy: 0.8708\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3503 - accuracy: 0.8539\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3676 - accuracy: 0.8427\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3823 - accuracy: 0.8258\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3741 - accuracy: 0.8258\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3961 - accuracy: 0.8483\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3776 - accuracy: 0.8483\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3607 - accuracy: 0.8483\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3266 - accuracy: 0.8764\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3858 - accuracy: 0.8483\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3834 - accuracy: 0.8483\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.4224 - accuracy: 0.8202\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4120 - accuracy: 0.8146\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3817 - accuracy: 0.8371\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3833 - accuracy: 0.8596\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3981 - accuracy: 0.8315\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4069 - accuracy: 0.8315\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3601 - accuracy: 0.8596\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3785 - accuracy: 0.8034\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3175 - accuracy: 0.9045\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3878 - accuracy: 0.8483\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.3987 - accuracy: 0.8539\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4026 - accuracy: 0.7921\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3825 - accuracy: 0.8596\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.3516 - accuracy: 0.8483\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3450 - accuracy: 0.8652\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4010 - accuracy: 0.8427\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3988 - accuracy: 0.8146\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3464 - accuracy: 0.8708\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3730 - accuracy: 0.8371\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3803 - accuracy: 0.8596\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.3457 - accuracy: 0.8539\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.3688 - accuracy: 0.8315\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3700 - accuracy: 0.8539\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4061 - accuracy: 0.8315\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.3735 - accuracy: 0.8146\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3301 - accuracy: 0.8708\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.3632 - accuracy: 0.8371\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3926 - accuracy: 0.8427\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3247 - accuracy: 0.8483\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3581 - accuracy: 0.8371\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3774 - accuracy: 0.8820\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3909 - accuracy: 0.8315\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3686 - accuracy: 0.8483\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3768 - accuracy: 0.8539\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3452 - accuracy: 0.8483\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4016 - accuracy: 0.8371\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3300 - accuracy: 0.8708\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.4277 - accuracy: 0.8202\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3776 - accuracy: 0.8427\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4015 - accuracy: 0.8090\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3294 - accuracy: 0.8258\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.3694 - accuracy: 0.8371\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.3168 - accuracy: 0.8876\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3645 - accuracy: 0.8539\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3196 - accuracy: 0.8820\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4101 - accuracy: 0.8483\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4031 - accuracy: 0.8146\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.3774 - accuracy: 0.8539\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3645 - accuracy: 0.8483\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3060 - accuracy: 0.8652\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.3950 - accuracy: 0.8427\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.3709 - accuracy: 0.8483\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3655 - accuracy: 0.8483\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3719 - accuracy: 0.8371\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3956 - accuracy: 0.8539\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3433 - accuracy: 0.8596\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3355 - accuracy: 0.8596\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3841 - accuracy: 0.8652\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3760 - accuracy: 0.8652\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4005 - accuracy: 0.8427\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3480 - accuracy: 0.8427\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3624 - accuracy: 0.8427\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.3355 - accuracy: 0.8596\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3335 - accuracy: 0.8764\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.3673 - accuracy: 0.8371\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.3489 - accuracy: 0.8539\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3429 - accuracy: 0.8596\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3352 - accuracy: 0.8596\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3533 - accuracy: 0.8596\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3992 - accuracy: 0.8146\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3302 - accuracy: 0.8539\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3861 - accuracy: 0.8146\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3375 - accuracy: 0.8539\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.3665 - accuracy: 0.8652\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3992 - accuracy: 0.8034\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3303 - accuracy: 0.8820\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4172 - accuracy: 0.8146\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3215 - accuracy: 0.8596\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3359 - accuracy: 0.8764\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3381 - accuracy: 0.8539\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3263 - accuracy: 0.8315\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3559 - accuracy: 0.8315\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4003 - accuracy: 0.8315\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.3501 - accuracy: 0.8483\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 268us/step - loss: 0.3838 - accuracy: 0.8258\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3907 - accuracy: 0.8371\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3406 - accuracy: 0.8427\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3527 - accuracy: 0.8596\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3485 - accuracy: 0.8652\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3284 - accuracy: 0.8876\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3754 - accuracy: 0.8034\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 259us/step - loss: 0.3171 - accuracy: 0.8652\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3436 - accuracy: 0.8764\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 428us/step - loss: 0.3775 - accuracy: 0.8315\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.3639 - accuracy: 0.8539\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3695 - accuracy: 0.8371\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3554 - accuracy: 0.8539\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3459 - accuracy: 0.8596\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3926 - accuracy: 0.8315\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3537 - accuracy: 0.8539\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3484 - accuracy: 0.8652\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3604 - accuracy: 0.8483\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3543 - accuracy: 0.8427\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3531 - accuracy: 0.8539\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3624 - accuracy: 0.8427\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3454 - accuracy: 0.8371\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3487 - accuracy: 0.8652\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3930 - accuracy: 0.8371\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3567 - accuracy: 0.8596\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3487 - accuracy: 0.8539\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3511 - accuracy: 0.8483\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.2973 - accuracy: 0.8933\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3295 - accuracy: 0.8764\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3200 - accuracy: 0.8652\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3784 - accuracy: 0.8315\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3634 - accuracy: 0.8483\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3486 - accuracy: 0.8652\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3462 - accuracy: 0.8427\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3421 - accuracy: 0.8371\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3140 - accuracy: 0.8708\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.3620 - accuracy: 0.8652\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3613 - accuracy: 0.8483\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3398 - accuracy: 0.8989\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.3565 - accuracy: 0.8652\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3696 - accuracy: 0.8258\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3366 - accuracy: 0.8539\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.3015 - accuracy: 0.8933\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3674 - accuracy: 0.8596\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3637 - accuracy: 0.8371\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.2919 - accuracy: 0.8820\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3630 - accuracy: 0.8539\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3309 - accuracy: 0.8820\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3155 - accuracy: 0.8764\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3910 - accuracy: 0.8371\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3752 - accuracy: 0.8146\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3458 - accuracy: 0.8708\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3124 - accuracy: 0.8708\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3626 - accuracy: 0.8202\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3336 - accuracy: 0.8596\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3485 - accuracy: 0.8371\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3291 - accuracy: 0.8652\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3568 - accuracy: 0.8371\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3198 - accuracy: 0.8876\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3171 - accuracy: 0.8764\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3642 - accuracy: 0.8258\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3376 - accuracy: 0.8596\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3736 - accuracy: 0.8427\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3435 - accuracy: 0.8596\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3176 - accuracy: 0.8652\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3215 - accuracy: 0.8708\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3002 - accuracy: 0.8764\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3701 - accuracy: 0.8876\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.3175 - accuracy: 0.8652\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.3215 - accuracy: 0.8708\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3273 - accuracy: 0.8764\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3544 - accuracy: 0.8652\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.2919 - accuracy: 0.8876\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.3597 - accuracy: 0.8596\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4136 - accuracy: 0.8146\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.3073 - accuracy: 0.8483\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3221 - accuracy: 0.8708\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3450 - accuracy: 0.8539\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3361 - accuracy: 0.8539\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.2988 - accuracy: 0.8820\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3581 - accuracy: 0.8202\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.3350 - accuracy: 0.8652\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3100 - accuracy: 0.8933\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3132 - accuracy: 0.8652\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3158 - accuracy: 0.8708\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3277 - accuracy: 0.8876\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3256 - accuracy: 0.8427\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.3736 - accuracy: 0.8483\n",
      "713/713 [==============================] - 1s 847us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.5295 - accuracy: 0.7980\n",
      "Epoch 2/400\n",
      " 30/891 [>.............................] - ETA: 0s - loss: 0.4678 - accuracy: 0.7333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 191us/step - loss: 0.4657 - accuracy: 0.7991\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4913 - accuracy: 0.7868\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4561 - accuracy: 0.8036\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4491 - accuracy: 0.8114\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4437 - accuracy: 0.8137\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4171 - accuracy: 0.8227\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4255 - accuracy: 0.8316\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4252 - accuracy: 0.8215\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4555 - accuracy: 0.7935\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4238 - accuracy: 0.8193\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4265 - accuracy: 0.8260\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4131 - accuracy: 0.8182\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4231 - accuracy: 0.8283\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4298 - accuracy: 0.8339\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4252 - accuracy: 0.8148\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4265 - accuracy: 0.8204\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4398 - accuracy: 0.8249\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4384 - accuracy: 0.8249\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4509 - accuracy: 0.8092\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4152 - accuracy: 0.8238\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.4090 - accuracy: 0.8294\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4271 - accuracy: 0.8238\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4297 - accuracy: 0.8148\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4255 - accuracy: 0.8215\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.4242 - accuracy: 0.8238\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4324 - accuracy: 0.8114\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4280 - accuracy: 0.8283\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4192 - accuracy: 0.8328\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.4345 - accuracy: 0.8114\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.4170 - accuracy: 0.8215\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4105 - accuracy: 0.8249\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4263 - accuracy: 0.8103\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4207 - accuracy: 0.8114\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4139 - accuracy: 0.8159\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4271 - accuracy: 0.8227\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4077 - accuracy: 0.8361\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4021 - accuracy: 0.8373\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4319 - accuracy: 0.8092\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4127 - accuracy: 0.8316\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4162 - accuracy: 0.8249\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4249 - accuracy: 0.8272\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 190us/step - loss: 0.4238 - accuracy: 0.8294\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4097 - accuracy: 0.8215\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4132 - accuracy: 0.8249\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.4147 - accuracy: 0.8328\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4116 - accuracy: 0.8294\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4168 - accuracy: 0.8395\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4085 - accuracy: 0.8272\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.3997 - accuracy: 0.8440\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4052 - accuracy: 0.8361\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3960 - accuracy: 0.8384\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4102 - accuracy: 0.8451\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4295 - accuracy: 0.8227\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4133 - accuracy: 0.8316\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4066 - accuracy: 0.8395\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4092 - accuracy: 0.8272\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4173 - accuracy: 0.8215\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4101 - accuracy: 0.8294\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4191 - accuracy: 0.8249\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3963 - accuracy: 0.8395\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4087 - accuracy: 0.8406\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4206 - accuracy: 0.8215\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4229 - accuracy: 0.8339\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3909 - accuracy: 0.8373\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4130 - accuracy: 0.8328\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4143 - accuracy: 0.8316\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4102 - accuracy: 0.8350\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4167 - accuracy: 0.8339\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4147 - accuracy: 0.8204\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4196 - accuracy: 0.8305\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4099 - accuracy: 0.8373\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3997 - accuracy: 0.8339\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4189 - accuracy: 0.8339\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4072 - accuracy: 0.8305\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3979 - accuracy: 0.8462\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4128 - accuracy: 0.8249\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3993 - accuracy: 0.8373\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.3911 - accuracy: 0.8328\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4155 - accuracy: 0.8238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3946 - accuracy: 0.8429\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4219 - accuracy: 0.8193\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4037 - accuracy: 0.8272\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4011 - accuracy: 0.8429\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4062 - accuracy: 0.8294\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3994 - accuracy: 0.8418\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4084 - accuracy: 0.8350\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3949 - accuracy: 0.8429\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4098 - accuracy: 0.8339\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.3986 - accuracy: 0.8350\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3978 - accuracy: 0.8406\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3995 - accuracy: 0.8316\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4009 - accuracy: 0.8406\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4204 - accuracy: 0.8294\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4186 - accuracy: 0.8260\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4040 - accuracy: 0.8361\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3865 - accuracy: 0.8418\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4032 - accuracy: 0.8361\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 257us/step - loss: 0.4092 - accuracy: 0.8294\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4089 - accuracy: 0.8316\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.4038 - accuracy: 0.8283\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4071 - accuracy: 0.8294\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3811 - accuracy: 0.8339\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3822 - accuracy: 0.8451\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4036 - accuracy: 0.8373\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4031 - accuracy: 0.8328\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.3987 - accuracy: 0.8395\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4097 - accuracy: 0.8429\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3871 - accuracy: 0.8429\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3941 - accuracy: 0.8418\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4054 - accuracy: 0.8384\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3969 - accuracy: 0.8474\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3996 - accuracy: 0.8440\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3934 - accuracy: 0.8395\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3999 - accuracy: 0.8373\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4100 - accuracy: 0.8249\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3791 - accuracy: 0.8440\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3930 - accuracy: 0.8350\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4057 - accuracy: 0.8294\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3853 - accuracy: 0.8395\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3993 - accuracy: 0.8384\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3872 - accuracy: 0.8429\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3955 - accuracy: 0.8339\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3975 - accuracy: 0.8395\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3924 - accuracy: 0.8440\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4025 - accuracy: 0.8260\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4183 - accuracy: 0.8159\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3690 - accuracy: 0.8631\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3874 - accuracy: 0.8440\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3842 - accuracy: 0.8350\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4020 - accuracy: 0.8406\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4185 - accuracy: 0.8272\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4042 - accuracy: 0.8316\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3904 - accuracy: 0.8462\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3844 - accuracy: 0.8496\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3978 - accuracy: 0.8350\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3965 - accuracy: 0.8283\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3913 - accuracy: 0.8406\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3881 - accuracy: 0.8462\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4071 - accuracy: 0.8328\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3930 - accuracy: 0.8328\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3826 - accuracy: 0.8474\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4154 - accuracy: 0.8339\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3883 - accuracy: 0.8283\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3807 - accuracy: 0.8507\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4037 - accuracy: 0.8328\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3943 - accuracy: 0.8384\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3889 - accuracy: 0.8418\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3887 - accuracy: 0.8462\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3979 - accuracy: 0.8384\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3936 - accuracy: 0.8384\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3969 - accuracy: 0.8361\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4034 - accuracy: 0.8316\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3847 - accuracy: 0.8361\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4007 - accuracy: 0.8339\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3893 - accuracy: 0.8451\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3746 - accuracy: 0.8496\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4098 - accuracy: 0.8429\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3779 - accuracy: 0.8384\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3827 - accuracy: 0.8485\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.4113 - accuracy: 0.8350\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3948 - accuracy: 0.8384\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3893 - accuracy: 0.8384\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3919 - accuracy: 0.8339\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4013 - accuracy: 0.8384\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4005 - accuracy: 0.8361\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3918 - accuracy: 0.8361\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.3924 - accuracy: 0.8361\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3937 - accuracy: 0.8350\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4011 - accuracy: 0.8339\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3818 - accuracy: 0.8451\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3834 - accuracy: 0.8541\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3905 - accuracy: 0.8507\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.3835 - accuracy: 0.8350\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4083 - accuracy: 0.8305\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3977 - accuracy: 0.8350\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3948 - accuracy: 0.8395\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3793 - accuracy: 0.8440\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.3951 - accuracy: 0.8373\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3941 - accuracy: 0.8507\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3851 - accuracy: 0.8451\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3994 - accuracy: 0.8361\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3886 - accuracy: 0.8283\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3745 - accuracy: 0.8507\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4050 - accuracy: 0.8249\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3935 - accuracy: 0.8384\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3797 - accuracy: 0.8485\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3932 - accuracy: 0.8316\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4044 - accuracy: 0.8328\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3932 - accuracy: 0.8361\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3878 - accuracy: 0.8507\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3979 - accuracy: 0.8328\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3794 - accuracy: 0.8507\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3940 - accuracy: 0.8406\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3817 - accuracy: 0.8462\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3890 - accuracy: 0.8361\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3841 - accuracy: 0.8496\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3826 - accuracy: 0.8496\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3985 - accuracy: 0.8305\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3880 - accuracy: 0.8406\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3828 - accuracy: 0.8507\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3913 - accuracy: 0.8260\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3999 - accuracy: 0.8429\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3805 - accuracy: 0.8462\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3888 - accuracy: 0.8462\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3888 - accuracy: 0.8384\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3853 - accuracy: 0.8406\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4006 - accuracy: 0.8429\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3876 - accuracy: 0.8418\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3918 - accuracy: 0.8451\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3654 - accuracy: 0.8496\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3814 - accuracy: 0.8361\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3826 - accuracy: 0.8406\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3878 - accuracy: 0.8440\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3954 - accuracy: 0.8272\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3849 - accuracy: 0.8406\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3833 - accuracy: 0.8496\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3841 - accuracy: 0.8395\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3761 - accuracy: 0.8474\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3891 - accuracy: 0.8395\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3954 - accuracy: 0.8339\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 260us/step - loss: 0.3858 - accuracy: 0.8451\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3839 - accuracy: 0.8519\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3968 - accuracy: 0.8373\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3838 - accuracy: 0.8395\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3892 - accuracy: 0.8474\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3703 - accuracy: 0.8496\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3628 - accuracy: 0.8530\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3796 - accuracy: 0.8462\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3784 - accuracy: 0.8361\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3951 - accuracy: 0.8462\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3987 - accuracy: 0.8350\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3971 - accuracy: 0.8373\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3704 - accuracy: 0.8519\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3939 - accuracy: 0.8373\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3726 - accuracy: 0.8541\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 230us/step - loss: 0.4051 - accuracy: 0.8272\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3862 - accuracy: 0.8350\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3885 - accuracy: 0.8316\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3865 - accuracy: 0.8373\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3809 - accuracy: 0.8451\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3867 - accuracy: 0.8384\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3793 - accuracy: 0.8586\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4034 - accuracy: 0.8316\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3983 - accuracy: 0.8316\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3873 - accuracy: 0.8474\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3714 - accuracy: 0.8440\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3964 - accuracy: 0.8316\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3758 - accuracy: 0.8462\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4003 - accuracy: 0.8328\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3821 - accuracy: 0.8541\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3868 - accuracy: 0.8395\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3994 - accuracy: 0.8328\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3870 - accuracy: 0.8440\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3865 - accuracy: 0.8418\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3697 - accuracy: 0.8440\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3660 - accuracy: 0.8563\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3899 - accuracy: 0.8462\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3971 - accuracy: 0.8384\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3988 - accuracy: 0.8350\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3754 - accuracy: 0.8395\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3781 - accuracy: 0.8429\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3919 - accuracy: 0.8429\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3888 - accuracy: 0.8361\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3780 - accuracy: 0.8373\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3886 - accuracy: 0.8406\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3894 - accuracy: 0.8384\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3755 - accuracy: 0.8519\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4065 - accuracy: 0.8373\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3936 - accuracy: 0.8350\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3773 - accuracy: 0.8608\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3692 - accuracy: 0.8552\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3585 - accuracy: 0.8631\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3740 - accuracy: 0.8597\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3747 - accuracy: 0.8530\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3912 - accuracy: 0.8339\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3892 - accuracy: 0.8440\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3645 - accuracy: 0.8496\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3887 - accuracy: 0.8519\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3745 - accuracy: 0.8519\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3742 - accuracy: 0.8451\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3962 - accuracy: 0.8339\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3637 - accuracy: 0.8519\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3900 - accuracy: 0.8418\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3760 - accuracy: 0.8429\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3940 - accuracy: 0.8294\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3664 - accuracy: 0.8496\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3647 - accuracy: 0.8552\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3749 - accuracy: 0.8429\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3802 - accuracy: 0.8485\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3864 - accuracy: 0.8474\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3868 - accuracy: 0.8451\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3922 - accuracy: 0.8406\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3796 - accuracy: 0.8507\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3969 - accuracy: 0.8316\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3806 - accuracy: 0.8339\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3666 - accuracy: 0.8552\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3793 - accuracy: 0.8406\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3958 - accuracy: 0.8305\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3807 - accuracy: 0.8496\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3870 - accuracy: 0.8361\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3935 - accuracy: 0.8429\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3819 - accuracy: 0.8462\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3914 - accuracy: 0.8519\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3828 - accuracy: 0.8519\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3643 - accuracy: 0.8620\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3594 - accuracy: 0.8418\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3749 - accuracy: 0.8530\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3820 - accuracy: 0.8418\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3769 - accuracy: 0.8552\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3745 - accuracy: 0.8563\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3864 - accuracy: 0.8451\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3796 - accuracy: 0.8429\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3821 - accuracy: 0.8440\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3902 - accuracy: 0.8440\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3781 - accuracy: 0.8361\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3854 - accuracy: 0.8305\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3767 - accuracy: 0.8597\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3873 - accuracy: 0.8440\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3761 - accuracy: 0.8563\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3917 - accuracy: 0.8384\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3881 - accuracy: 0.8429\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3755 - accuracy: 0.8507\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3943 - accuracy: 0.8316\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3804 - accuracy: 0.8429\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3748 - accuracy: 0.8440\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3884 - accuracy: 0.8429\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3881 - accuracy: 0.8339\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4002 - accuracy: 0.8328\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3790 - accuracy: 0.8451\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3990 - accuracy: 0.8294\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3868 - accuracy: 0.8474\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3688 - accuracy: 0.8519\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3918 - accuracy: 0.8361\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3791 - accuracy: 0.8530\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3841 - accuracy: 0.8496\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3961 - accuracy: 0.8339\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3735 - accuracy: 0.8429\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3690 - accuracy: 0.8429\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3836 - accuracy: 0.8361\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3934 - accuracy: 0.8339\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.3949 - accuracy: 0.8474\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3833 - accuracy: 0.8485\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3805 - accuracy: 0.8530\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.3850 - accuracy: 0.8373\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3708 - accuracy: 0.8519\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4037 - accuracy: 0.8272\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3755 - accuracy: 0.8474\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3715 - accuracy: 0.8507\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3814 - accuracy: 0.8496\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.4061 - accuracy: 0.8462\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4025 - accuracy: 0.8384\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3882 - accuracy: 0.8429\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3834 - accuracy: 0.8440\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3822 - accuracy: 0.8440\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3767 - accuracy: 0.8552\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3670 - accuracy: 0.8429\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3762 - accuracy: 0.8406\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3526 - accuracy: 0.8664\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3818 - accuracy: 0.8451\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3804 - accuracy: 0.8462\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4020 - accuracy: 0.8339\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3816 - accuracy: 0.8418\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3660 - accuracy: 0.8552\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3828 - accuracy: 0.8418\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3870 - accuracy: 0.8395\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3764 - accuracy: 0.8496\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3851 - accuracy: 0.8406\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3702 - accuracy: 0.8496\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3756 - accuracy: 0.8451\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3723 - accuracy: 0.8418\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3586 - accuracy: 0.8440\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3825 - accuracy: 0.8451\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3887 - accuracy: 0.8339\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3885 - accuracy: 0.8474\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3633 - accuracy: 0.8496\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3794 - accuracy: 0.8384\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3798 - accuracy: 0.8429\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3728 - accuracy: 0.8507\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3880 - accuracy: 0.8462\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.3782 - accuracy: 0.8485\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3789 - accuracy: 0.8440\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3763 - accuracy: 0.8440\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3637 - accuracy: 0.8552\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3924 - accuracy: 0.8451\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.3811 - accuracy: 0.8395\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3819 - accuracy: 0.8418\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3801 - accuracy: 0.8361\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 265us/step - loss: 0.3804 - accuracy: 0.8462\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3795 - accuracy: 0.8485\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3805 - accuracy: 0.8519\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3797 - accuracy: 0.8462\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 213us/step - loss: 0.3862 - accuracy: 0.8418\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3871 - accuracy: 0.8384\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3843 - accuracy: 0.8384\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3724 - accuracy: 0.8496\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3952 - accuracy: 0.8406\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3795 - accuracy: 0.8485\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3771 - accuracy: 0.8530\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3737 - accuracy: 0.8530\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 50, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.6986 - accuracy: 0.5843\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.6569 - accuracy: 0.6742\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.6594 - accuracy: 0.6629\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.6064 - accuracy: 0.7303\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.5768 - accuracy: 0.6966\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5693 - accuracy: 0.7079\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.6102 - accuracy: 0.6854\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5430 - accuracy: 0.7528\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5532 - accuracy: 0.7303\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.5604 - accuracy: 0.7303\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5429 - accuracy: 0.7303\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5415 - accuracy: 0.7191\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5000 - accuracy: 0.7528\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.5307 - accuracy: 0.7640\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5134 - accuracy: 0.7865\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.5244 - accuracy: 0.7753\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4737 - accuracy: 0.7697\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4818 - accuracy: 0.7697\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4892 - accuracy: 0.8034\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4758 - accuracy: 0.8034\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5306 - accuracy: 0.7865\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.5357 - accuracy: 0.8034\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4806 - accuracy: 0.7921\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.5262 - accuracy: 0.7360\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4687 - accuracy: 0.7697\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4415 - accuracy: 0.8202\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4856 - accuracy: 0.7640\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4551 - accuracy: 0.7697\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5257 - accuracy: 0.7584\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4616 - accuracy: 0.7697\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5272 - accuracy: 0.7584\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5046 - accuracy: 0.7584\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4348 - accuracy: 0.8090\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4371 - accuracy: 0.8146\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4579 - accuracy: 0.7978\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4585 - accuracy: 0.7978\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4842 - accuracy: 0.7921\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4631 - accuracy: 0.7921\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4380 - accuracy: 0.7865\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4479 - accuracy: 0.7640\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4816 - accuracy: 0.7640\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4368 - accuracy: 0.7921\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4209 - accuracy: 0.8315\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4259 - accuracy: 0.7921\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4281 - accuracy: 0.8315\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4345 - accuracy: 0.7697\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4710 - accuracy: 0.8258\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4192 - accuracy: 0.7921\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4759 - accuracy: 0.7753\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4194 - accuracy: 0.8090\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4276 - accuracy: 0.8034\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4194 - accuracy: 0.7978\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4141 - accuracy: 0.8427\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4873 - accuracy: 0.7921\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4822 - accuracy: 0.7753\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.4141 - accuracy: 0.7865\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4171 - accuracy: 0.8090\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4714 - accuracy: 0.7978\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4347 - accuracy: 0.7978\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4481 - accuracy: 0.8146\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.4117 - accuracy: 0.8090\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4329 - accuracy: 0.8258\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 259us/step - loss: 0.4338 - accuracy: 0.8090\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4311 - accuracy: 0.8371\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4306 - accuracy: 0.7978\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4117 - accuracy: 0.8315\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3926 - accuracy: 0.8034\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4144 - accuracy: 0.8202\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4358 - accuracy: 0.7809\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4397 - accuracy: 0.7978\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4179 - accuracy: 0.8090\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3792 - accuracy: 0.8371\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3943 - accuracy: 0.8539\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4096 - accuracy: 0.8146\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4004 - accuracy: 0.8146\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4411 - accuracy: 0.8034\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3817 - accuracy: 0.8483\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3924 - accuracy: 0.8146\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4192 - accuracy: 0.8034\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3960 - accuracy: 0.8258\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4667 - accuracy: 0.7865\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3774 - accuracy: 0.8539\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4516 - accuracy: 0.7809\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4079 - accuracy: 0.8315\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3922 - accuracy: 0.8427\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3933 - accuracy: 0.8258\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3852 - accuracy: 0.8146\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3834 - accuracy: 0.8483\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4235 - accuracy: 0.7921\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3993 - accuracy: 0.8371\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4292 - accuracy: 0.8371\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.4212 - accuracy: 0.7921\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3573 - accuracy: 0.8427\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4663 - accuracy: 0.8034\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4074 - accuracy: 0.8258\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3928 - accuracy: 0.8315\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3925 - accuracy: 0.8315\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4166 - accuracy: 0.7978\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4096 - accuracy: 0.8539\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4455 - accuracy: 0.8146\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3861 - accuracy: 0.8427\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3761 - accuracy: 0.8427\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3876 - accuracy: 0.8146\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3948 - accuracy: 0.8146\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3814 - accuracy: 0.8315\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3817 - accuracy: 0.8427\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4127 - accuracy: 0.8315\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3837 - accuracy: 0.8427\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3793 - accuracy: 0.8258\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3941 - accuracy: 0.7978\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3615 - accuracy: 0.8034\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4059 - accuracy: 0.8315\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4132 - accuracy: 0.8427\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3789 - accuracy: 0.8539\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3937 - accuracy: 0.8539\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4158 - accuracy: 0.8539\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4037 - accuracy: 0.8315\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3597 - accuracy: 0.8427\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3921 - accuracy: 0.8427\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3897 - accuracy: 0.8371\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3829 - accuracy: 0.8258\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3519 - accuracy: 0.8427\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4226 - accuracy: 0.8202\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3925 - accuracy: 0.8090\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3693 - accuracy: 0.8539\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3745 - accuracy: 0.8539\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3820 - accuracy: 0.8371\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3803 - accuracy: 0.8427\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3677 - accuracy: 0.8427\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3342 - accuracy: 0.8427\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3749 - accuracy: 0.8539\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3627 - accuracy: 0.8315\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3493 - accuracy: 0.8483\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3780 - accuracy: 0.8315\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3430 - accuracy: 0.8596\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3573 - accuracy: 0.8708\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3844 - accuracy: 0.8034\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3373 - accuracy: 0.8483\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3246 - accuracy: 0.8652\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3937 - accuracy: 0.8315\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3446 - accuracy: 0.8539\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3577 - accuracy: 0.8596\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3797 - accuracy: 0.8596\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3248 - accuracy: 0.8652\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3880 - accuracy: 0.8315\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3570 - accuracy: 0.8764\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3961 - accuracy: 0.8315\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3749 - accuracy: 0.8371\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3669 - accuracy: 0.8427\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3919 - accuracy: 0.8427\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3604 - accuracy: 0.8483\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3902 - accuracy: 0.8371\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3571 - accuracy: 0.8371\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3350 - accuracy: 0.8427\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3542 - accuracy: 0.8652\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3779 - accuracy: 0.8427\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 226us/step - loss: 0.3780 - accuracy: 0.8258\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3716 - accuracy: 0.8483\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3476 - accuracy: 0.8539\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3646 - accuracy: 0.8371\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4005 - accuracy: 0.8315\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3761 - accuracy: 0.8539\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3632 - accuracy: 0.8146\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3670 - accuracy: 0.8315\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3458 - accuracy: 0.8652\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3563 - accuracy: 0.8427\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3824 - accuracy: 0.8427\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3334 - accuracy: 0.8652\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3458 - accuracy: 0.8483\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3281 - accuracy: 0.8596\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3409 - accuracy: 0.8539\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3965 - accuracy: 0.8539\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3293 - accuracy: 0.8708\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3390 - accuracy: 0.8596\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3304 - accuracy: 0.8539\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2864 - accuracy: 0.8933\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3082 - accuracy: 0.8596\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3452 - accuracy: 0.8596\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3397 - accuracy: 0.8539\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3937 - accuracy: 0.8202\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3295 - accuracy: 0.8427\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3285 - accuracy: 0.8708\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3330 - accuracy: 0.8764\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4168 - accuracy: 0.7978\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3411 - accuracy: 0.8483\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3410 - accuracy: 0.8708\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3605 - accuracy: 0.8708\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3770 - accuracy: 0.8427\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3264 - accuracy: 0.8371\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3672 - accuracy: 0.8315\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3375 - accuracy: 0.8708\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3747 - accuracy: 0.8483\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3582 - accuracy: 0.8427\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2971 - accuracy: 0.8764\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3416 - accuracy: 0.8427\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3429 - accuracy: 0.8652\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3235 - accuracy: 0.8708\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3314 - accuracy: 0.8876\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3452 - accuracy: 0.8539\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2905 - accuracy: 0.8820\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3601 - accuracy: 0.8596\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2993 - accuracy: 0.8764\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4461 - accuracy: 0.8427\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3495 - accuracy: 0.8596\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3208 - accuracy: 0.8596\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3007 - accuracy: 0.8989\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3877 - accuracy: 0.8483\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3292 - accuracy: 0.8596\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3687 - accuracy: 0.8258\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3410 - accuracy: 0.8202\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3361 - accuracy: 0.8539\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3624 - accuracy: 0.8708\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3227 - accuracy: 0.8652\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3421 - accuracy: 0.8371\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3245 - accuracy: 0.8483\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3472 - accuracy: 0.8708\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3211 - accuracy: 0.8596\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3185 - accuracy: 0.8596\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3184 - accuracy: 0.8652\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3751 - accuracy: 0.8202\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3399 - accuracy: 0.8652\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3454 - accuracy: 0.8876\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3377 - accuracy: 0.8708\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3022 - accuracy: 0.8764\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3481 - accuracy: 0.8596\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3826 - accuracy: 0.8315\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3519 - accuracy: 0.8371\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3386 - accuracy: 0.8708\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3392 - accuracy: 0.8933\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3430 - accuracy: 0.8427\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3370 - accuracy: 0.8596\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3369 - accuracy: 0.8371\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3375 - accuracy: 0.8764\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2991 - accuracy: 0.8708\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3050 - accuracy: 0.8820\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3380 - accuracy: 0.8539\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3333 - accuracy: 0.8764\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3215 - accuracy: 0.8539\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3446 - accuracy: 0.8371\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2944 - accuracy: 0.8708\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3149 - accuracy: 0.8876\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3390 - accuracy: 0.8652\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3285 - accuracy: 0.8539\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3554 - accuracy: 0.8483\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3304 - accuracy: 0.8315\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3235 - accuracy: 0.8820\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3221 - accuracy: 0.8539\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3611 - accuracy: 0.8483\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3141 - accuracy: 0.8933\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2918 - accuracy: 0.8708\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3224 - accuracy: 0.8652\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2797 - accuracy: 0.8989\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3062 - accuracy: 0.8652\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3027 - accuracy: 0.8652\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3021 - accuracy: 0.8764\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3058 - accuracy: 0.8596\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3257 - accuracy: 0.8708\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3090 - accuracy: 0.8652\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3244 - accuracy: 0.8876\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3653 - accuracy: 0.8764\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3198 - accuracy: 0.8820\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3194 - accuracy: 0.8596\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3233 - accuracy: 0.8876\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3537 - accuracy: 0.8371\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3286 - accuracy: 0.8539\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.2835 - accuracy: 0.9045\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3130 - accuracy: 0.8820\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3181 - accuracy: 0.8989\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3051 - accuracy: 0.8596\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3299 - accuracy: 0.8596\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3062 - accuracy: 0.8652\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3327 - accuracy: 0.8596\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3148 - accuracy: 0.8596\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2848 - accuracy: 0.8876\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3296 - accuracy: 0.8708\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3477 - accuracy: 0.8596\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3035 - accuracy: 0.8820\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3199 - accuracy: 0.8652\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3080 - accuracy: 0.8708\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3714 - accuracy: 0.8539\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3233 - accuracy: 0.8820\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3295 - accuracy: 0.8427\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2959 - accuracy: 0.8652\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3455 - accuracy: 0.8539\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3463 - accuracy: 0.8483\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3231 - accuracy: 0.8483\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2927 - accuracy: 0.8989\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2933 - accuracy: 0.8989\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3810 - accuracy: 0.8258\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3099 - accuracy: 0.8820\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3105 - accuracy: 0.8708\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3222 - accuracy: 0.8539\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2752 - accuracy: 0.9045\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3464 - accuracy: 0.8708\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2884 - accuracy: 0.8876\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3033 - accuracy: 0.8989\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.2723 - accuracy: 0.8933\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3235 - accuracy: 0.8764\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3107 - accuracy: 0.8933\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3759 - accuracy: 0.8708\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2637 - accuracy: 0.8989\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2726 - accuracy: 0.8652\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3027 - accuracy: 0.8764\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2716 - accuracy: 0.9157\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3178 - accuracy: 0.8539\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.2705 - accuracy: 0.8933\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2495 - accuracy: 0.9213\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3105 - accuracy: 0.8652\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3803 - accuracy: 0.8427\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3012 - accuracy: 0.8708\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2995 - accuracy: 0.8596\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3118 - accuracy: 0.8876\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 229us/step - loss: 0.2823 - accuracy: 0.9101\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3335 - accuracy: 0.8427\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3063 - accuracy: 0.8652\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3173 - accuracy: 0.8539\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.2816 - accuracy: 0.8596\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3331 - accuracy: 0.8652\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2702 - accuracy: 0.8989\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2612 - accuracy: 0.8876\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3019 - accuracy: 0.8764\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2780 - accuracy: 0.9101\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3085 - accuracy: 0.8876\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2846 - accuracy: 0.8652\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2730 - accuracy: 0.8989\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3222 - accuracy: 0.8596\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2748 - accuracy: 0.8989\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3523 - accuracy: 0.8652\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2702 - accuracy: 0.8933\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3183 - accuracy: 0.8876\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3429 - accuracy: 0.8708\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3500 - accuracy: 0.8652\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2997 - accuracy: 0.8820\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2917 - accuracy: 0.8933\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.2954 - accuracy: 0.8820\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3515 - accuracy: 0.8708\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.2875 - accuracy: 0.8876\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3253 - accuracy: 0.8596\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3190 - accuracy: 0.8596\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2804 - accuracy: 0.8596\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2689 - accuracy: 0.8989\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3057 - accuracy: 0.8820\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2701 - accuracy: 0.8989\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3045 - accuracy: 0.8933\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.2646 - accuracy: 0.8764\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2856 - accuracy: 0.8876\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3214 - accuracy: 0.8876\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2814 - accuracy: 0.8708\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3331 - accuracy: 0.8652\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2941 - accuracy: 0.8820\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2636 - accuracy: 0.8820\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3055 - accuracy: 0.8539\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3236 - accuracy: 0.8652\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2668 - accuracy: 0.8764\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4266 - accuracy: 0.8427\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2829 - accuracy: 0.8652\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3102 - accuracy: 0.8820\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.2639 - accuracy: 0.9045\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3177 - accuracy: 0.8764\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3071 - accuracy: 0.8708\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.2425 - accuracy: 0.8989\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2830 - accuracy: 0.8933\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2909 - accuracy: 0.8652\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3192 - accuracy: 0.8764\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2850 - accuracy: 0.8876\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2903 - accuracy: 0.8876\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3010 - accuracy: 0.8764\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2841 - accuracy: 0.9101\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.2949 - accuracy: 0.8820\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2697 - accuracy: 0.9157\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3073 - accuracy: 0.8652\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2941 - accuracy: 0.8820\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2757 - accuracy: 0.8876\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3158 - accuracy: 0.8652\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3142 - accuracy: 0.8764\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2892 - accuracy: 0.8708\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2938 - accuracy: 0.8483\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.2941 - accuracy: 0.8933\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3262 - accuracy: 0.8708\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2902 - accuracy: 0.8764\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2713 - accuracy: 0.8933\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2712 - accuracy: 0.8933\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3202 - accuracy: 0.8539\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3093 - accuracy: 0.8708\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2522 - accuracy: 0.9101\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2981 - accuracy: 0.8764\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3347 - accuracy: 0.8596\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2596 - accuracy: 0.9045\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3329 - accuracy: 0.8764\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3081 - accuracy: 0.8989\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2844 - accuracy: 0.8820\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3077 - accuracy: 0.8764\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3092 - accuracy: 0.8820\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3052 - accuracy: 0.8876\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2971 - accuracy: 0.8820\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2988 - accuracy: 0.8764\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3244 - accuracy: 0.8652\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3683 - accuracy: 0.8539\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.2818 - accuracy: 0.8820\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.2896 - accuracy: 0.8652\n",
      "713/713 [==============================] - 1s 766us/step\n",
      "Epoch 1/400\n",
      "780/891 [=========================>....] - ETA: 0s - loss: 0.5240 - accuracy: 0.7949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 231us/step - loss: 0.5237 - accuracy: 0.7946\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4685 - accuracy: 0.8002\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4438 - accuracy: 0.8047\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4535 - accuracy: 0.7980\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4340 - accuracy: 0.8260\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4420 - accuracy: 0.8092\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4461 - accuracy: 0.8126\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4496 - accuracy: 0.8159\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4212 - accuracy: 0.8238\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4486 - accuracy: 0.8092\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4414 - accuracy: 0.8081\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4227 - accuracy: 0.8238\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4257 - accuracy: 0.8092\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4325 - accuracy: 0.8260\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4284 - accuracy: 0.8159\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4269 - accuracy: 0.8148\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4183 - accuracy: 0.8294\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4258 - accuracy: 0.8227\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4279 - accuracy: 0.8227\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4310 - accuracy: 0.8350\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4285 - accuracy: 0.8114\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.4178 - accuracy: 0.8328\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4130 - accuracy: 0.8182\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4172 - accuracy: 0.8227\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4223 - accuracy: 0.8215\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4049 - accuracy: 0.8294\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4166 - accuracy: 0.8316\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4161 - accuracy: 0.8238\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4275 - accuracy: 0.8227\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4238 - accuracy: 0.8204\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4134 - accuracy: 0.8249\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3995 - accuracy: 0.8406\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3991 - accuracy: 0.8305\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.4124 - accuracy: 0.8227\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3993 - accuracy: 0.8294\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4063 - accuracy: 0.8316\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4057 - accuracy: 0.8440\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.4049 - accuracy: 0.8249\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4192 - accuracy: 0.8193\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3958 - accuracy: 0.8283\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3899 - accuracy: 0.8474\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4075 - accuracy: 0.8316\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4271 - accuracy: 0.8328\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4087 - accuracy: 0.8384\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4112 - accuracy: 0.8249\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4024 - accuracy: 0.8339\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4109 - accuracy: 0.8316\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4036 - accuracy: 0.8283\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3946 - accuracy: 0.8440\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4220 - accuracy: 0.8283\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3991 - accuracy: 0.8328\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4232 - accuracy: 0.8182\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4055 - accuracy: 0.8361\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3977 - accuracy: 0.8305\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3829 - accuracy: 0.8418\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4055 - accuracy: 0.8373\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3987 - accuracy: 0.8339\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4007 - accuracy: 0.8373\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4172 - accuracy: 0.8238\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4210 - accuracy: 0.8260\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3958 - accuracy: 0.8451\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.4151 - accuracy: 0.8305\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3975 - accuracy: 0.8485\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3939 - accuracy: 0.8406\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3890 - accuracy: 0.8507\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4018 - accuracy: 0.8339\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3883 - accuracy: 0.8395\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3910 - accuracy: 0.8316\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3942 - accuracy: 0.8418\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4122 - accuracy: 0.8339\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3905 - accuracy: 0.8283\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.3885 - accuracy: 0.8395\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3856 - accuracy: 0.8440\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3978 - accuracy: 0.8373\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3967 - accuracy: 0.8373\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3902 - accuracy: 0.8451\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3965 - accuracy: 0.8361\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4004 - accuracy: 0.8249\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3926 - accuracy: 0.8406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3902 - accuracy: 0.8361\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3976 - accuracy: 0.8485\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4144 - accuracy: 0.8294\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3990 - accuracy: 0.8283\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4013 - accuracy: 0.8294\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3852 - accuracy: 0.8384\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3977 - accuracy: 0.8418\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4020 - accuracy: 0.8305\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3838 - accuracy: 0.8384\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3778 - accuracy: 0.8496\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3891 - accuracy: 0.8384\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3890 - accuracy: 0.8485\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3876 - accuracy: 0.8350\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3989 - accuracy: 0.8350\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3709 - accuracy: 0.8406\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3873 - accuracy: 0.8373\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3833 - accuracy: 0.8507\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3850 - accuracy: 0.8406\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3869 - accuracy: 0.8496\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4083 - accuracy: 0.8272\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3985 - accuracy: 0.8373\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3949 - accuracy: 0.8440\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3906 - accuracy: 0.8294\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3897 - accuracy: 0.8395\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4002 - accuracy: 0.8395\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3838 - accuracy: 0.8440\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3764 - accuracy: 0.8563\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4023 - accuracy: 0.8350\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3809 - accuracy: 0.8485\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4057 - accuracy: 0.8339\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3759 - accuracy: 0.8485\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3859 - accuracy: 0.8373\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3831 - accuracy: 0.8350\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3852 - accuracy: 0.8373\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4079 - accuracy: 0.8238\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3747 - accuracy: 0.8496\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3843 - accuracy: 0.8384\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3820 - accuracy: 0.8440\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3814 - accuracy: 0.8384\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3768 - accuracy: 0.8530\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3866 - accuracy: 0.8339\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3894 - accuracy: 0.8361\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3858 - accuracy: 0.8395\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3897 - accuracy: 0.8406\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4064 - accuracy: 0.8339\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3665 - accuracy: 0.8474\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3851 - accuracy: 0.8440\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3924 - accuracy: 0.8339\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3829 - accuracy: 0.8339\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3862 - accuracy: 0.8395\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3814 - accuracy: 0.8384\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3882 - accuracy: 0.8395\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3866 - accuracy: 0.8451\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3784 - accuracy: 0.8451\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3959 - accuracy: 0.8339\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3901 - accuracy: 0.8496\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3801 - accuracy: 0.8507\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4002 - accuracy: 0.8429\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3913 - accuracy: 0.8350\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3835 - accuracy: 0.8395\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3782 - accuracy: 0.8507\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4012 - accuracy: 0.8339\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3844 - accuracy: 0.8474\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3669 - accuracy: 0.8485\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3668 - accuracy: 0.8507\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3768 - accuracy: 0.8395\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3839 - accuracy: 0.8507\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3760 - accuracy: 0.8440\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3837 - accuracy: 0.8474\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3905 - accuracy: 0.8328\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3828 - accuracy: 0.8485\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3781 - accuracy: 0.8406\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3749 - accuracy: 0.8541\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3716 - accuracy: 0.8462\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4032 - accuracy: 0.8361\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3873 - accuracy: 0.8507\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3762 - accuracy: 0.8418\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3750 - accuracy: 0.8406\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3932 - accuracy: 0.8429\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3733 - accuracy: 0.8519\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3710 - accuracy: 0.8440\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3800 - accuracy: 0.8507\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3713 - accuracy: 0.8406\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3862 - accuracy: 0.8350\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3843 - accuracy: 0.8373\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3813 - accuracy: 0.8451\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3775 - accuracy: 0.8485\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3942 - accuracy: 0.8316\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3908 - accuracy: 0.8316\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3815 - accuracy: 0.8429\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3762 - accuracy: 0.8552\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3967 - accuracy: 0.8361\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.3908 - accuracy: 0.8339\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3820 - accuracy: 0.8485\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3885 - accuracy: 0.8507\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3910 - accuracy: 0.8406\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3914 - accuracy: 0.8373\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3905 - accuracy: 0.8361\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3749 - accuracy: 0.8552\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3763 - accuracy: 0.8485\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3749 - accuracy: 0.8462\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3854 - accuracy: 0.8485\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3695 - accuracy: 0.8507\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3739 - accuracy: 0.8418\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3796 - accuracy: 0.8552\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3874 - accuracy: 0.8440\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3861 - accuracy: 0.8429\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3730 - accuracy: 0.8507\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3903 - accuracy: 0.8350\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3758 - accuracy: 0.8395\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3690 - accuracy: 0.8507\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3788 - accuracy: 0.8462\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.4005 - accuracy: 0.8260\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3831 - accuracy: 0.8418\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3946 - accuracy: 0.8418\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3835 - accuracy: 0.8283\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3704 - accuracy: 0.8485\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3838 - accuracy: 0.8474\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3690 - accuracy: 0.8429\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3813 - accuracy: 0.8429\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3761 - accuracy: 0.8530\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3740 - accuracy: 0.8519\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3687 - accuracy: 0.8541\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3757 - accuracy: 0.8384\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3875 - accuracy: 0.8406\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3833 - accuracy: 0.8395\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3739 - accuracy: 0.8451\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3864 - accuracy: 0.8406\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3680 - accuracy: 0.8552\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3730 - accuracy: 0.8429\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3786 - accuracy: 0.8361\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3712 - accuracy: 0.8586\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3880 - accuracy: 0.8316\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3835 - accuracy: 0.8429\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.3925 - accuracy: 0.8429\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3708 - accuracy: 0.8485\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3691 - accuracy: 0.8586\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3714 - accuracy: 0.8395\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3875 - accuracy: 0.8373\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3898 - accuracy: 0.8361\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3714 - accuracy: 0.8496\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3796 - accuracy: 0.8429\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3639 - accuracy: 0.8575\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3908 - accuracy: 0.8249\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3732 - accuracy: 0.8418\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3699 - accuracy: 0.8418\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3829 - accuracy: 0.8339\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3954 - accuracy: 0.8350\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3704 - accuracy: 0.8541\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3767 - accuracy: 0.8350\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3728 - accuracy: 0.8395\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3697 - accuracy: 0.8350\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3654 - accuracy: 0.8586\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3752 - accuracy: 0.8507\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3705 - accuracy: 0.8575\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3971 - accuracy: 0.8305\n",
      "Epoch 236/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 238us/step - loss: 0.3930 - accuracy: 0.8339\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3828 - accuracy: 0.8507\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3682 - accuracy: 0.8541\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3728 - accuracy: 0.8418\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3783 - accuracy: 0.8507\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3819 - accuracy: 0.8440\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3811 - accuracy: 0.8429\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3812 - accuracy: 0.8418\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3865 - accuracy: 0.8361\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3776 - accuracy: 0.8496\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3715 - accuracy: 0.8530\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 270us/step - loss: 0.3774 - accuracy: 0.8440\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3833 - accuracy: 0.8361\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3888 - accuracy: 0.8373\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3853 - accuracy: 0.8440\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3926 - accuracy: 0.8339\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3771 - accuracy: 0.8440\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3653 - accuracy: 0.8474\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3668 - accuracy: 0.8485\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3733 - accuracy: 0.8507\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3891 - accuracy: 0.8462\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3663 - accuracy: 0.8474\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3628 - accuracy: 0.8440\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3736 - accuracy: 0.8507\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3735 - accuracy: 0.8429\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3744 - accuracy: 0.8440\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3728 - accuracy: 0.8530\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 264us/step - loss: 0.3788 - accuracy: 0.8485\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.3713 - accuracy: 0.8519\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3835 - accuracy: 0.8373\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3813 - accuracy: 0.8429\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3686 - accuracy: 0.8552\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3784 - accuracy: 0.8530\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3712 - accuracy: 0.8474\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3609 - accuracy: 0.8586\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.3585 - accuracy: 0.8440\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3760 - accuracy: 0.8507\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3810 - accuracy: 0.8474\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.3674 - accuracy: 0.8496\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 265us/step - loss: 0.3807 - accuracy: 0.8373\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3711 - accuracy: 0.8429\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 271us/step - loss: 0.3765 - accuracy: 0.8429\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.3705 - accuracy: 0.8451\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3988 - accuracy: 0.8418\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3753 - accuracy: 0.8530\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3852 - accuracy: 0.8373\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 260us/step - loss: 0.3760 - accuracy: 0.8429\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 268us/step - loss: 0.3765 - accuracy: 0.8507\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 257us/step - loss: 0.3619 - accuracy: 0.8586\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.3817 - accuracy: 0.8418\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.3784 - accuracy: 0.8339\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 286us/step - loss: 0.3620 - accuracy: 0.8507\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3609 - accuracy: 0.8552\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.3702 - accuracy: 0.8507\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.3839 - accuracy: 0.8373\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3768 - accuracy: 0.8451\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.3697 - accuracy: 0.8451\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.3668 - accuracy: 0.8507\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.3735 - accuracy: 0.8485\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 270us/step - loss: 0.3754 - accuracy: 0.8395\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3709 - accuracy: 0.8462\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3683 - accuracy: 0.8530\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.3697 - accuracy: 0.8530\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.3757 - accuracy: 0.8406\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3673 - accuracy: 0.8485\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3734 - accuracy: 0.8440\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3881 - accuracy: 0.8429\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3755 - accuracy: 0.8462\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3805 - accuracy: 0.8496\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3801 - accuracy: 0.8451\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3599 - accuracy: 0.8597\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3918 - accuracy: 0.8440\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3706 - accuracy: 0.8395\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3646 - accuracy: 0.8586\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3749 - accuracy: 0.8384\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3664 - accuracy: 0.8474\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3658 - accuracy: 0.8496\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3834 - accuracy: 0.8384\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3656 - accuracy: 0.8530\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3731 - accuracy: 0.8496\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3612 - accuracy: 0.8519\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3705 - accuracy: 0.8496\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3837 - accuracy: 0.8418\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3829 - accuracy: 0.8316\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3725 - accuracy: 0.8474\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3675 - accuracy: 0.8507\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3839 - accuracy: 0.8384\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3757 - accuracy: 0.8552\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3845 - accuracy: 0.8418\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3745 - accuracy: 0.8451\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3809 - accuracy: 0.8361\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3666 - accuracy: 0.8507\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3559 - accuracy: 0.8586\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3754 - accuracy: 0.8361\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3588 - accuracy: 0.8552\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3665 - accuracy: 0.8440\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3567 - accuracy: 0.8563\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3743 - accuracy: 0.8462\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3794 - accuracy: 0.8418\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3888 - accuracy: 0.8496\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3566 - accuracy: 0.8608\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3753 - accuracy: 0.8462\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3615 - accuracy: 0.8496\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 268us/step - loss: 0.3734 - accuracy: 0.8440\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3841 - accuracy: 0.8451\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3754 - accuracy: 0.8440\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3726 - accuracy: 0.8563\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3670 - accuracy: 0.8485\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3909 - accuracy: 0.8373\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3727 - accuracy: 0.8496\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3572 - accuracy: 0.8541\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3704 - accuracy: 0.8552\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3690 - accuracy: 0.8429\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3647 - accuracy: 0.8552\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3705 - accuracy: 0.8395\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3688 - accuracy: 0.8451\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3697 - accuracy: 0.8530\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3654 - accuracy: 0.8507\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3574 - accuracy: 0.8631\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3679 - accuracy: 0.8507\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3855 - accuracy: 0.8451\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.3551 - accuracy: 0.8575\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 270us/step - loss: 0.3614 - accuracy: 0.8530\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3699 - accuracy: 0.8305\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3888 - accuracy: 0.8395\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3648 - accuracy: 0.8552\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3695 - accuracy: 0.8451\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3759 - accuracy: 0.8361\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3748 - accuracy: 0.8485\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3749 - accuracy: 0.8406\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3728 - accuracy: 0.8485\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3786 - accuracy: 0.8440\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3642 - accuracy: 0.8530\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3750 - accuracy: 0.8451\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3572 - accuracy: 0.8575\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3747 - accuracy: 0.8507\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3711 - accuracy: 0.8474\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3595 - accuracy: 0.8507\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3757 - accuracy: 0.8440\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3762 - accuracy: 0.8429\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3745 - accuracy: 0.8530\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3573 - accuracy: 0.8608\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3938 - accuracy: 0.8373\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3536 - accuracy: 0.8575\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3821 - accuracy: 0.8496\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3662 - accuracy: 0.8608\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3705 - accuracy: 0.8462\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3693 - accuracy: 0.8474\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3633 - accuracy: 0.8541\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3722 - accuracy: 0.8451\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3637 - accuracy: 0.8474\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3713 - accuracy: 0.8552\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3604 - accuracy: 0.8496\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3753 - accuracy: 0.8395\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3600 - accuracy: 0.8575\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3658 - accuracy: 0.8687\n",
      "Epoch 392/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 239us/step - loss: 0.3815 - accuracy: 0.8530\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3654 - accuracy: 0.8451\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3797 - accuracy: 0.8440\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3863 - accuracy: 0.8384\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.3773 - accuracy: 0.8451\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3731 - accuracy: 0.8418\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3821 - accuracy: 0.8395\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3662 - accuracy: 0.8530\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3606 - accuracy: 0.8642\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 50, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 0.7859 - accuracy: 0.4607\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.7007 - accuracy: 0.5506\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.6539 - accuracy: 0.6292\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.6539 - accuracy: 0.6685\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.6009 - accuracy: 0.6742\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5931 - accuracy: 0.6854\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.6240 - accuracy: 0.7079\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.6100 - accuracy: 0.6573\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.5774 - accuracy: 0.6854\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.6153 - accuracy: 0.7191\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.6013 - accuracy: 0.6798\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5809 - accuracy: 0.7022\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5514 - accuracy: 0.7247\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.5711 - accuracy: 0.7303\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.5804 - accuracy: 0.7360\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.5778 - accuracy: 0.7191\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5413 - accuracy: 0.7191\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.5762 - accuracy: 0.6910\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5577 - accuracy: 0.6966\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5345 - accuracy: 0.7640\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5726 - accuracy: 0.7191\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5614 - accuracy: 0.7135\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.5824 - accuracy: 0.7303\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.83 - 0s 285us/step - loss: 0.4988 - accuracy: 0.8090\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.5907 - accuracy: 0.7079\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5326 - accuracy: 0.7416\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4693 - accuracy: 0.7921\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4906 - accuracy: 0.7472\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.5393 - accuracy: 0.7360\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.5076 - accuracy: 0.7528\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4938 - accuracy: 0.7528\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.4892 - accuracy: 0.7865\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4990 - accuracy: 0.7640\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5378 - accuracy: 0.7416\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5136 - accuracy: 0.7640\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5145 - accuracy: 0.7921\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4478 - accuracy: 0.7921\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5493 - accuracy: 0.7416\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5400 - accuracy: 0.7697\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5109 - accuracy: 0.7753\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4911 - accuracy: 0.7921\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5051 - accuracy: 0.7753\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5172 - accuracy: 0.7640\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5369 - accuracy: 0.7360\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4995 - accuracy: 0.7921\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.4459 - accuracy: 0.8146\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.5286 - accuracy: 0.7584\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.4610 - accuracy: 0.7865\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4582 - accuracy: 0.7697\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.4893 - accuracy: 0.7753\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4958 - accuracy: 0.7753\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4739 - accuracy: 0.7753\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5257 - accuracy: 0.7584\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.5183 - accuracy: 0.7640\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4938 - accuracy: 0.7584\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.4759 - accuracy: 0.7528\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4549 - accuracy: 0.7809\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4659 - accuracy: 0.7921\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4485 - accuracy: 0.7978\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4629 - accuracy: 0.7921\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4653 - accuracy: 0.7865\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4685 - accuracy: 0.7584\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4762 - accuracy: 0.7697\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5026 - accuracy: 0.7697\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5316 - accuracy: 0.7865\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4839 - accuracy: 0.7921\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4664 - accuracy: 0.7921\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4848 - accuracy: 0.7865\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4679 - accuracy: 0.7978\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.5110 - accuracy: 0.7640\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4474 - accuracy: 0.8202\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.5005 - accuracy: 0.7472\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.4692 - accuracy: 0.8034\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4484 - accuracy: 0.7697\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4359 - accuracy: 0.8090\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5235 - accuracy: 0.7528\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.4834 - accuracy: 0.7865\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.4905 - accuracy: 0.7865\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4826 - accuracy: 0.8315\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5015 - accuracy: 0.7753\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4725 - accuracy: 0.7809\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4851 - accuracy: 0.8090\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4682 - accuracy: 0.7921\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4474 - accuracy: 0.8090\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4645 - accuracy: 0.7640\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4533 - accuracy: 0.8034\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4474 - accuracy: 0.7640\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4571 - accuracy: 0.8090\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4496 - accuracy: 0.8483\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4294 - accuracy: 0.7584\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4615 - accuracy: 0.8202\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4207 - accuracy: 0.8315\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5010 - accuracy: 0.7921\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4471 - accuracy: 0.8034\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4408 - accuracy: 0.8427\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4718 - accuracy: 0.8146\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4384 - accuracy: 0.8202\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4203 - accuracy: 0.8315\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4300 - accuracy: 0.8146\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4298 - accuracy: 0.8258\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4827 - accuracy: 0.8202\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4524 - accuracy: 0.7809\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.4208 - accuracy: 0.8258\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4332 - accuracy: 0.8483\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4117 - accuracy: 0.8090\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4296 - accuracy: 0.8258\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4133 - accuracy: 0.8090\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.5030 - accuracy: 0.7865\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4450 - accuracy: 0.7978\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4100 - accuracy: 0.8315\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4445 - accuracy: 0.8258\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 343us/step - loss: 0.4114 - accuracy: 0.8202\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4593 - accuracy: 0.7865\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4308 - accuracy: 0.8202\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4503 - accuracy: 0.7978\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4378 - accuracy: 0.8202\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.3927 - accuracy: 0.8539\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4413 - accuracy: 0.8258\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3946 - accuracy: 0.8483\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4370 - accuracy: 0.8315\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4114 - accuracy: 0.8315\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.3840 - accuracy: 0.8483\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4222 - accuracy: 0.8202\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4081 - accuracy: 0.8539\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4034 - accuracy: 0.8034\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4737 - accuracy: 0.7697\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3838 - accuracy: 0.8202\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4367 - accuracy: 0.7809\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4244 - accuracy: 0.8483\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3863 - accuracy: 0.8258\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4663 - accuracy: 0.8315\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3712 - accuracy: 0.8483\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4234 - accuracy: 0.8427\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.4693 - accuracy: 0.8034\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4144 - accuracy: 0.8371\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3734 - accuracy: 0.8652\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4301 - accuracy: 0.8090\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3822 - accuracy: 0.8315\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3885 - accuracy: 0.8483\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3700 - accuracy: 0.8427\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4290 - accuracy: 0.8202\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4038 - accuracy: 0.8483\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4316 - accuracy: 0.8090\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4056 - accuracy: 0.8596\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.3811 - accuracy: 0.8427\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4084 - accuracy: 0.8202\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.4025 - accuracy: 0.8371\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.4243 - accuracy: 0.8483\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.3882 - accuracy: 0.8483\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.4199 - accuracy: 0.8371\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4106 - accuracy: 0.8315\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4016 - accuracy: 0.8315\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.3529 - accuracy: 0.8652\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4304 - accuracy: 0.8315\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3577 - accuracy: 0.8652\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.3569 - accuracy: 0.8315\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 312us/step - loss: 0.3553 - accuracy: 0.8483\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.3636 - accuracy: 0.8427\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.4221 - accuracy: 0.8034\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.3920 - accuracy: 0.8483\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.4082 - accuracy: 0.8371\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3780 - accuracy: 0.8539\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4138 - accuracy: 0.8202\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3694 - accuracy: 0.8315\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3940 - accuracy: 0.8652\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4001 - accuracy: 0.8539\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4191 - accuracy: 0.8202\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.4571 - accuracy: 0.8315\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.4098 - accuracy: 0.8034\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4065 - accuracy: 0.8258\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3783 - accuracy: 0.8315\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3439 - accuracy: 0.8539\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4097 - accuracy: 0.8146\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3884 - accuracy: 0.8708\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.3651 - accuracy: 0.8315\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4595 - accuracy: 0.8146\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4105 - accuracy: 0.8652\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3516 - accuracy: 0.8708\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4058 - accuracy: 0.8371\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3708 - accuracy: 0.8258\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4046 - accuracy: 0.8371\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3688 - accuracy: 0.8483\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3354 - accuracy: 0.8708\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3908 - accuracy: 0.8427\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3588 - accuracy: 0.8483\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3718 - accuracy: 0.8539\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3590 - accuracy: 0.8371\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4078 - accuracy: 0.8258\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4302 - accuracy: 0.8202\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3634 - accuracy: 0.8652\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4069 - accuracy: 0.8258\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3799 - accuracy: 0.8483\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.3602 - accuracy: 0.8427\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3901 - accuracy: 0.8483\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3388 - accuracy: 0.8764\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3668 - accuracy: 0.8483\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3817 - accuracy: 0.8652\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4027 - accuracy: 0.8315\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3391 - accuracy: 0.8708\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3508 - accuracy: 0.8820\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.3575 - accuracy: 0.8315\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3300 - accuracy: 0.8764\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.3877 - accuracy: 0.8483\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.3905 - accuracy: 0.8258\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3836 - accuracy: 0.8427\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.3607 - accuracy: 0.8764\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3610 - accuracy: 0.8371\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3749 - accuracy: 0.8708\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3863 - accuracy: 0.8202\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3360 - accuracy: 0.8596\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4121 - accuracy: 0.8090\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3440 - accuracy: 0.8483\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3486 - accuracy: 0.8371\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3606 - accuracy: 0.8764\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3778 - accuracy: 0.8483\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3581 - accuracy: 0.8708\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3712 - accuracy: 0.8315\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3327 - accuracy: 0.8708\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.3882 - accuracy: 0.8483\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4440 - accuracy: 0.8483\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3425 - accuracy: 0.8708\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3248 - accuracy: 0.8708\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3829 - accuracy: 0.8371\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4504 - accuracy: 0.7921\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3606 - accuracy: 0.8202\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4075 - accuracy: 0.8539\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3988 - accuracy: 0.8427\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3366 - accuracy: 0.8708\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3574 - accuracy: 0.8427\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3427 - accuracy: 0.9045\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3496 - accuracy: 0.8539\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3493 - accuracy: 0.8652\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3400 - accuracy: 0.8652\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3553 - accuracy: 0.8820\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.3443 - accuracy: 0.8708\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3400 - accuracy: 0.8427\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3705 - accuracy: 0.8596\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3302 - accuracy: 0.8596\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3138 - accuracy: 0.8371\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3081 - accuracy: 0.8876\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3449 - accuracy: 0.8258\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3744 - accuracy: 0.8483\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4112 - accuracy: 0.8539\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3274 - accuracy: 0.8652\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 404us/step - loss: 0.3680 - accuracy: 0.8146\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3761 - accuracy: 0.8596\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3149 - accuracy: 0.8708\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.2978 - accuracy: 0.8989\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3613 - accuracy: 0.8427\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3934 - accuracy: 0.8708\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3371 - accuracy: 0.8483\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3178 - accuracy: 0.8989\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3284 - accuracy: 0.8371\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3389 - accuracy: 0.8596\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3970 - accuracy: 0.8483\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.3324 - accuracy: 0.8596\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3446 - accuracy: 0.8596\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3260 - accuracy: 0.8596\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.2958 - accuracy: 0.8596\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3370 - accuracy: 0.8483\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.3134 - accuracy: 0.8764\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3866 - accuracy: 0.8315\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3247 - accuracy: 0.8933\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3312 - accuracy: 0.8652\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.2992 - accuracy: 0.8764\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.3889 - accuracy: 0.8258\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.3589 - accuracy: 0.8427\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.3899 - accuracy: 0.8539\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3642 - accuracy: 0.8652\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.2995 - accuracy: 0.8764\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3123 - accuracy: 0.8708\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3578 - accuracy: 0.8539\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3264 - accuracy: 0.8708\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3666 - accuracy: 0.8483\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.2803 - accuracy: 0.8876\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.3549 - accuracy: 0.8820\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.3526 - accuracy: 0.8708\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3538 - accuracy: 0.8371\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.3249 - accuracy: 0.8539\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3193 - accuracy: 0.8764\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3550 - accuracy: 0.8764\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3164 - accuracy: 0.8596\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3277 - accuracy: 0.8876\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3651 - accuracy: 0.8708\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3141 - accuracy: 0.8933\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3580 - accuracy: 0.8539\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3818 - accuracy: 0.8764\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3273 - accuracy: 0.8876\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3171 - accuracy: 0.8539\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3368 - accuracy: 0.8483\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3663 - accuracy: 0.8652\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3386 - accuracy: 0.8596\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3625 - accuracy: 0.8427\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3742 - accuracy: 0.8652\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3593 - accuracy: 0.8371\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3298 - accuracy: 0.8652\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3274 - accuracy: 0.8708\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3161 - accuracy: 0.8483\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3717 - accuracy: 0.8596\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3754 - accuracy: 0.8483\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3917 - accuracy: 0.8146\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3538 - accuracy: 0.8596\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3580 - accuracy: 0.8764\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3346 - accuracy: 0.8764\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3290 - accuracy: 0.8708\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3211 - accuracy: 0.8483\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3493 - accuracy: 0.8764\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3317 - accuracy: 0.8876\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3328 - accuracy: 0.8483\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3409 - accuracy: 0.8764\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3120 - accuracy: 0.8708\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3389 - accuracy: 0.8427\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 294us/step - loss: 0.4157 - accuracy: 0.8258\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3955 - accuracy: 0.8090\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3191 - accuracy: 0.8820\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3321 - accuracy: 0.8876\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3616 - accuracy: 0.8652\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.2959 - accuracy: 0.8652\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3225 - accuracy: 0.8596\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3514 - accuracy: 0.8708\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3660 - accuracy: 0.8820\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3220 - accuracy: 0.8708\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3739 - accuracy: 0.8315\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3468 - accuracy: 0.8596\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3403 - accuracy: 0.8764\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.2558 - accuracy: 0.8933\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3489 - accuracy: 0.8596\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.2950 - accuracy: 0.8652\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3172 - accuracy: 0.8764\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3229 - accuracy: 0.8764\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3115 - accuracy: 0.8933\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4435 - accuracy: 0.8315\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3146 - accuracy: 0.8708\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3312 - accuracy: 0.8596\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3124 - accuracy: 0.8652\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.2936 - accuracy: 0.8820\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3172 - accuracy: 0.8652\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3251 - accuracy: 0.8483\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3149 - accuracy: 0.8708\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3306 - accuracy: 0.8876\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3048 - accuracy: 0.8933\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3444 - accuracy: 0.8820\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3098 - accuracy: 0.8933\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3641 - accuracy: 0.8708\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3629 - accuracy: 0.8427\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.3212 - accuracy: 0.8652\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.2906 - accuracy: 0.8652\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.2839 - accuracy: 0.8933\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.3312 - accuracy: 0.8708\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.3327 - accuracy: 0.8820\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.2820 - accuracy: 0.8933\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.3120 - accuracy: 0.8820\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3326 - accuracy: 0.8876\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3189 - accuracy: 0.8820\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.2958 - accuracy: 0.8933\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.2765 - accuracy: 0.8989\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.3093 - accuracy: 0.8820\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.3728 - accuracy: 0.8427\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.3374 - accuracy: 0.8708\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3430 - accuracy: 0.8708\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.2882 - accuracy: 0.8820\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.2751 - accuracy: 0.8989\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.2811 - accuracy: 0.8876\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.3400 - accuracy: 0.8708\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.3990 - accuracy: 0.8427\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.3127 - accuracy: 0.8933\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 387us/step - loss: 0.3292 - accuracy: 0.8764\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.2911 - accuracy: 0.8876\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.3324 - accuracy: 0.8652\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 414us/step - loss: 0.2800 - accuracy: 0.8876\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 370us/step - loss: 0.3111 - accuracy: 0.8596\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.2921 - accuracy: 0.8876\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3338 - accuracy: 0.8652\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 456us/step - loss: 0.2604 - accuracy: 0.8989\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3407 - accuracy: 0.8708\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 385us/step - loss: 0.3209 - accuracy: 0.8820\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.2719 - accuracy: 0.8820\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.3633 - accuracy: 0.8596\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.3102 - accuracy: 0.8820\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.3332 - accuracy: 0.8764\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3130 - accuracy: 0.8820\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.2857 - accuracy: 0.8764\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3219 - accuracy: 0.8933\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.2863 - accuracy: 0.8933\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3435 - accuracy: 0.8483\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3329 - accuracy: 0.8596\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.2732 - accuracy: 0.8820\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.3502 - accuracy: 0.8483\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.2894 - accuracy: 0.8652\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.2861 - accuracy: 0.8820\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3473 - accuracy: 0.8820\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.2744 - accuracy: 0.8933\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.2902 - accuracy: 0.8820\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.2952 - accuracy: 0.8876\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.2946 - accuracy: 0.8933\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3030 - accuracy: 0.8764\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.2939 - accuracy: 0.8876\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3309 - accuracy: 0.8708\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.2873 - accuracy: 0.8989\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3127 - accuracy: 0.8652\n",
      "713/713 [==============================] - 1s 977us/step\n",
      "Epoch 1/400\n",
      "480/891 [===============>..............] - ETA: 0s - loss: 0.5554 - accuracy: 0.7896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 352us/step - loss: 0.5048 - accuracy: 0.8002\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4595 - accuracy: 0.7969\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4719 - accuracy: 0.8002\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4352 - accuracy: 0.8182\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4609 - accuracy: 0.8215\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4509 - accuracy: 0.8058\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4265 - accuracy: 0.8114\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4354 - accuracy: 0.8182\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4243 - accuracy: 0.8126\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4334 - accuracy: 0.8227\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4241 - accuracy: 0.8204\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4247 - accuracy: 0.8227\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4123 - accuracy: 0.8361\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4238 - accuracy: 0.8361\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4260 - accuracy: 0.8081\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4308 - accuracy: 0.8148\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4302 - accuracy: 0.8204\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4369 - accuracy: 0.8126\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4379 - accuracy: 0.8047\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4217 - accuracy: 0.8092\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4070 - accuracy: 0.8249\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4218 - accuracy: 0.8227\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4299 - accuracy: 0.8204\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4086 - accuracy: 0.8316\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4195 - accuracy: 0.8272\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4208 - accuracy: 0.8328\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4077 - accuracy: 0.8316\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4157 - accuracy: 0.8361\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4145 - accuracy: 0.8395\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.3945 - accuracy: 0.8406\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4072 - accuracy: 0.8406\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4273 - accuracy: 0.8238\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4047 - accuracy: 0.8305\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4001 - accuracy: 0.8384\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4050 - accuracy: 0.8294\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4196 - accuracy: 0.8305\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4109 - accuracy: 0.8406\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4247 - accuracy: 0.8272\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3987 - accuracy: 0.8272\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4220 - accuracy: 0.8283\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4078 - accuracy: 0.8339\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.3982 - accuracy: 0.8350\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4155 - accuracy: 0.8249\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4072 - accuracy: 0.8361\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4192 - accuracy: 0.8339\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4220 - accuracy: 0.8272\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.4124 - accuracy: 0.8283\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4037 - accuracy: 0.8395\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4052 - accuracy: 0.8148\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4056 - accuracy: 0.8361\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4186 - accuracy: 0.8272\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 286us/step - loss: 0.3800 - accuracy: 0.8586\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4137 - accuracy: 0.8395\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4060 - accuracy: 0.8339\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4070 - accuracy: 0.8316\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4104 - accuracy: 0.8249\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4078 - accuracy: 0.8361\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4191 - accuracy: 0.8204\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4143 - accuracy: 0.8384\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4061 - accuracy: 0.8249\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.4073 - accuracy: 0.8316\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3774 - accuracy: 0.8530\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4192 - accuracy: 0.8260\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3970 - accuracy: 0.8294\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.3948 - accuracy: 0.8384\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4004 - accuracy: 0.8339\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.3847 - accuracy: 0.8418\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4015 - accuracy: 0.8361\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4106 - accuracy: 0.8182\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3914 - accuracy: 0.8440\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.3881 - accuracy: 0.8429\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4196 - accuracy: 0.8361\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3958 - accuracy: 0.8406\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.3996 - accuracy: 0.8395\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3916 - accuracy: 0.8395\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 412us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4167 - accuracy: 0.8249\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3995 - accuracy: 0.8373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3893 - accuracy: 0.8395\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3961 - accuracy: 0.8361\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4053 - accuracy: 0.8361\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4056 - accuracy: 0.8361\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.4074 - accuracy: 0.8373\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.3885 - accuracy: 0.8350\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.3821 - accuracy: 0.8384\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4189 - accuracy: 0.8350\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3872 - accuracy: 0.8507\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4002 - accuracy: 0.8328\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3927 - accuracy: 0.8384\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3844 - accuracy: 0.8496\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3894 - accuracy: 0.8418\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4069 - accuracy: 0.8361\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3788 - accuracy: 0.8440\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3990 - accuracy: 0.8328\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4081 - accuracy: 0.8305\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3993 - accuracy: 0.8384\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3910 - accuracy: 0.8462\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.3996 - accuracy: 0.8350\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 367us/step - loss: 0.3811 - accuracy: 0.8418\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4036 - accuracy: 0.8418\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3884 - accuracy: 0.8406\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.3991 - accuracy: 0.8384\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 401us/step - loss: 0.3955 - accuracy: 0.8260\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3831 - accuracy: 0.8395\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.4031 - accuracy: 0.8373\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4079 - accuracy: 0.8418\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3922 - accuracy: 0.8283\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3907 - accuracy: 0.8384\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4001 - accuracy: 0.8339\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4049 - accuracy: 0.8339\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3884 - accuracy: 0.8496\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3869 - accuracy: 0.8440\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3977 - accuracy: 0.8361\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4098 - accuracy: 0.8328\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3995 - accuracy: 0.8440\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3938 - accuracy: 0.8462\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3951 - accuracy: 0.8496\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3962 - accuracy: 0.8373\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3886 - accuracy: 0.8350\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4135 - accuracy: 0.8305\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4013 - accuracy: 0.8316\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4034 - accuracy: 0.8350\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3992 - accuracy: 0.8462\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3885 - accuracy: 0.8384\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3758 - accuracy: 0.8440\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3825 - accuracy: 0.8530\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3901 - accuracy: 0.8384\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3898 - accuracy: 0.8474\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.4018 - accuracy: 0.8373\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3839 - accuracy: 0.8328\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3959 - accuracy: 0.8429\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3857 - accuracy: 0.8406\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3931 - accuracy: 0.8462\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4020 - accuracy: 0.8384\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3988 - accuracy: 0.8429\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4024 - accuracy: 0.8406\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3769 - accuracy: 0.8575\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3770 - accuracy: 0.8462\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3900 - accuracy: 0.8541\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.4061 - accuracy: 0.8294\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3855 - accuracy: 0.8440\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4090 - accuracy: 0.8283\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4012 - accuracy: 0.8384\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3896 - accuracy: 0.8474\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3843 - accuracy: 0.8350\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3865 - accuracy: 0.8440\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3861 - accuracy: 0.8462\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4082 - accuracy: 0.8339\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3936 - accuracy: 0.8395\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3811 - accuracy: 0.8496\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3735 - accuracy: 0.8507\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.4013 - accuracy: 0.8305\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3863 - accuracy: 0.8418\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3826 - accuracy: 0.8451\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4041 - accuracy: 0.8361\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3848 - accuracy: 0.8350\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3901 - accuracy: 0.8305\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4103 - accuracy: 0.8328\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4001 - accuracy: 0.8429\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4033 - accuracy: 0.8305\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3887 - accuracy: 0.8440\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3858 - accuracy: 0.8373\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3845 - accuracy: 0.8418\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3812 - accuracy: 0.8418\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4021 - accuracy: 0.8451\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3820 - accuracy: 0.8496\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3804 - accuracy: 0.8339\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3906 - accuracy: 0.8395\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3933 - accuracy: 0.8418\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3921 - accuracy: 0.8373\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3677 - accuracy: 0.8451\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3743 - accuracy: 0.8451\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3750 - accuracy: 0.8462\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 380us/step - loss: 0.3915 - accuracy: 0.8429\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3942 - accuracy: 0.8485\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3986 - accuracy: 0.8272\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3959 - accuracy: 0.8373\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3905 - accuracy: 0.8519\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3941 - accuracy: 0.8339\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3764 - accuracy: 0.8429\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3913 - accuracy: 0.8418\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3842 - accuracy: 0.8384\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3794 - accuracy: 0.8440\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3967 - accuracy: 0.8384\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3831 - accuracy: 0.8395\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3743 - accuracy: 0.8575\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3880 - accuracy: 0.8339\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3887 - accuracy: 0.8440\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3847 - accuracy: 0.8440\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3868 - accuracy: 0.8462\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3868 - accuracy: 0.8316\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3764 - accuracy: 0.8406\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3884 - accuracy: 0.8418\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3733 - accuracy: 0.8541\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3880 - accuracy: 0.8361\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3904 - accuracy: 0.8418\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3902 - accuracy: 0.8316\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3702 - accuracy: 0.8429\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3954 - accuracy: 0.8283\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3705 - accuracy: 0.8395\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3865 - accuracy: 0.8418\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3820 - accuracy: 0.8552\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3839 - accuracy: 0.8361\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3840 - accuracy: 0.8305\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3793 - accuracy: 0.8474\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3974 - accuracy: 0.8361\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3821 - accuracy: 0.8361\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3748 - accuracy: 0.8541\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3937 - accuracy: 0.8373\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.3761 - accuracy: 0.8485\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3925 - accuracy: 0.8429\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3987 - accuracy: 0.8260\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3826 - accuracy: 0.8451\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3795 - accuracy: 0.8474\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3820 - accuracy: 0.8462\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3790 - accuracy: 0.8485\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3795 - accuracy: 0.8316\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3787 - accuracy: 0.8474\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3985 - accuracy: 0.8361\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3868 - accuracy: 0.8418\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3828 - accuracy: 0.8474\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3884 - accuracy: 0.8406\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3870 - accuracy: 0.8429\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3680 - accuracy: 0.8530\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3797 - accuracy: 0.8406\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3875 - accuracy: 0.8451\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3776 - accuracy: 0.8440\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3716 - accuracy: 0.8462\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3784 - accuracy: 0.8384\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3929 - accuracy: 0.8373\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3854 - accuracy: 0.8361\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3828 - accuracy: 0.8451\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3986 - accuracy: 0.8406\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3840 - accuracy: 0.8440\n",
      "Epoch 236/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 302us/step - loss: 0.3868 - accuracy: 0.8350\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3923 - accuracy: 0.8361\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4025 - accuracy: 0.8328\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3849 - accuracy: 0.8485\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3899 - accuracy: 0.8462\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3948 - accuracy: 0.8272\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3924 - accuracy: 0.8451\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3836 - accuracy: 0.8440\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3941 - accuracy: 0.8462\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3880 - accuracy: 0.8462\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3799 - accuracy: 0.8429\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3831 - accuracy: 0.8507\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3678 - accuracy: 0.8496\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.3848 - accuracy: 0.8507\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3765 - accuracy: 0.8530\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3838 - accuracy: 0.8418\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3880 - accuracy: 0.8418\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3845 - accuracy: 0.8373\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3772 - accuracy: 0.8519\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3916 - accuracy: 0.8440\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3796 - accuracy: 0.8496\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3829 - accuracy: 0.8373\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3767 - accuracy: 0.8395\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3751 - accuracy: 0.8373\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3687 - accuracy: 0.8361\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3909 - accuracy: 0.8373\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3818 - accuracy: 0.8496\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3723 - accuracy: 0.8541\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3817 - accuracy: 0.8406\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3802 - accuracy: 0.8462\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3739 - accuracy: 0.8485\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3970 - accuracy: 0.8294\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3863 - accuracy: 0.8530\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3870 - accuracy: 0.8507\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3828 - accuracy: 0.8541\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3874 - accuracy: 0.8440\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3957 - accuracy: 0.8418\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3913 - accuracy: 0.8507\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3728 - accuracy: 0.8586\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3713 - accuracy: 0.8429\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3771 - accuracy: 0.8418\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3840 - accuracy: 0.8406\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3746 - accuracy: 0.8440\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3814 - accuracy: 0.8541\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3749 - accuracy: 0.8440\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3747 - accuracy: 0.8429\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3816 - accuracy: 0.8339\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3790 - accuracy: 0.8440\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3826 - accuracy: 0.8462\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3926 - accuracy: 0.8350\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3857 - accuracy: 0.8429\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3937 - accuracy: 0.8406\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3689 - accuracy: 0.8530\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3821 - accuracy: 0.8485\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3760 - accuracy: 0.8541\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3698 - accuracy: 0.8552\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3757 - accuracy: 0.8563\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3732 - accuracy: 0.8519\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3782 - accuracy: 0.8530\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3681 - accuracy: 0.8462\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3897 - accuracy: 0.8418\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3946 - accuracy: 0.8418\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3738 - accuracy: 0.8552\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3642 - accuracy: 0.8552\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3719 - accuracy: 0.8541\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3608 - accuracy: 0.8563\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3930 - accuracy: 0.8350\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3759 - accuracy: 0.8418\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3861 - accuracy: 0.8519\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3879 - accuracy: 0.8339\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.3780 - accuracy: 0.8552\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4013 - accuracy: 0.8451\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3888 - accuracy: 0.8440\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3715 - accuracy: 0.8418\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3710 - accuracy: 0.8384\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 402us/step - loss: 0.3751 - accuracy: 0.8462\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3897 - accuracy: 0.8418\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3734 - accuracy: 0.8530\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3940 - accuracy: 0.8429\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3932 - accuracy: 0.8418\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3775 - accuracy: 0.8451\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3744 - accuracy: 0.8519\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3871 - accuracy: 0.8519\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3660 - accuracy: 0.8519\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4018 - accuracy: 0.8418\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3803 - accuracy: 0.8418\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3801 - accuracy: 0.8485\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3876 - accuracy: 0.8418\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3737 - accuracy: 0.8485\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3666 - accuracy: 0.8541\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3791 - accuracy: 0.8507\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3771 - accuracy: 0.8418\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 450us/step - loss: 0.3814 - accuracy: 0.8429\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 1s 580us/step - loss: 0.3754 - accuracy: 0.8474\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3626 - accuracy: 0.8620\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.3821 - accuracy: 0.8350\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3835 - accuracy: 0.8440\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3871 - accuracy: 0.8395\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 410us/step - loss: 0.3774 - accuracy: 0.8519\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3868 - accuracy: 0.8339\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.3852 - accuracy: 0.8418\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 412us/step - loss: 0.3838 - accuracy: 0.8541\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3777 - accuracy: 0.8474\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3939 - accuracy: 0.8395\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3883 - accuracy: 0.8350\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3789 - accuracy: 0.8373\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3823 - accuracy: 0.8384\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.3628 - accuracy: 0.8496\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.3782 - accuracy: 0.8496\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3775 - accuracy: 0.8519\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3677 - accuracy: 0.8485\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3744 - accuracy: 0.8462\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4064 - accuracy: 0.8373\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3876 - accuracy: 0.8519\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3875 - accuracy: 0.8395\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3745 - accuracy: 0.8507\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3729 - accuracy: 0.8474\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3729 - accuracy: 0.8384\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3719 - accuracy: 0.8496\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3729 - accuracy: 0.8530\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3768 - accuracy: 0.8507\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3690 - accuracy: 0.8519\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3935 - accuracy: 0.8350\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3740 - accuracy: 0.8395\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3771 - accuracy: 0.8440\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3592 - accuracy: 0.8530\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3603 - accuracy: 0.8485\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3610 - accuracy: 0.8496\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3696 - accuracy: 0.8507\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3783 - accuracy: 0.8361\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3897 - accuracy: 0.8418\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3680 - accuracy: 0.8530\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3778 - accuracy: 0.8429\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3622 - accuracy: 0.8485\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3798 - accuracy: 0.8440\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3808 - accuracy: 0.8507\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3705 - accuracy: 0.8530\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3719 - accuracy: 0.8608\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3801 - accuracy: 0.8440\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.3767 - accuracy: 0.8530\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.3831 - accuracy: 0.8451\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3844 - accuracy: 0.8418\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3786 - accuracy: 0.8530\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3696 - accuracy: 0.8552\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3806 - accuracy: 0.8485\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.3707 - accuracy: 0.8474\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.3730 - accuracy: 0.8496\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3657 - accuracy: 0.8530\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3753 - accuracy: 0.8440\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3847 - accuracy: 0.8384\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3600 - accuracy: 0.8462\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3702 - accuracy: 0.8485\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3662 - accuracy: 0.8485\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3771 - accuracy: 0.8395\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 380us/step - loss: 0.3807 - accuracy: 0.8373\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3629 - accuracy: 0.8541\n",
      "Epoch 392/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 310us/step - loss: 0.3805 - accuracy: 0.8507\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3653 - accuracy: 0.8530\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3695 - accuracy: 0.8541\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3705 - accuracy: 0.8507\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3786 - accuracy: 0.8474\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4023 - accuracy: 0.8406\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 408us/step - loss: 0.3721 - accuracy: 0.8406\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.3774 - accuracy: 0.8440\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3735 - accuracy: 0.8462\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 100, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.7436 - accuracy: 0.6124\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.6720 - accuracy: 0.6461\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.6369 - accuracy: 0.6742\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.6085 - accuracy: 0.7022\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.5438 - accuracy: 0.7472\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.5468 - accuracy: 0.7416\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.5428 - accuracy: 0.7135\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.5460 - accuracy: 0.7584\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5393 - accuracy: 0.7472\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4709 - accuracy: 0.7978\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.5365 - accuracy: 0.7697\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.5052 - accuracy: 0.7978\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.5216 - accuracy: 0.7416\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4837 - accuracy: 0.7753\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.5000 - accuracy: 0.8090\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.5159 - accuracy: 0.7640\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4899 - accuracy: 0.7978\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.5224 - accuracy: 0.7472\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4498 - accuracy: 0.8146\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4883 - accuracy: 0.7191\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4757 - accuracy: 0.7809\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.5128 - accuracy: 0.8202\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5105 - accuracy: 0.7753\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4458 - accuracy: 0.8427\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4639 - accuracy: 0.7584\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4595 - accuracy: 0.8090\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4474 - accuracy: 0.8146\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4075 - accuracy: 0.8202\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4428 - accuracy: 0.8202\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4894 - accuracy: 0.7809\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4375 - accuracy: 0.7809\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4453 - accuracy: 0.8146\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4889 - accuracy: 0.7640\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4512 - accuracy: 0.7978\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4746 - accuracy: 0.7978\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4150 - accuracy: 0.8146\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4176 - accuracy: 0.7978\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4587 - accuracy: 0.8034\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4514 - accuracy: 0.8034\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4390 - accuracy: 0.7978\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4082 - accuracy: 0.8090\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4218 - accuracy: 0.8202\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4172 - accuracy: 0.8371\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4303 - accuracy: 0.8146\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4768 - accuracy: 0.7978\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4289 - accuracy: 0.8090\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4318 - accuracy: 0.8202\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4432 - accuracy: 0.7921\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3778 - accuracy: 0.8371\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.4102 - accuracy: 0.8371\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4139 - accuracy: 0.8202\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3849 - accuracy: 0.8764\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4408 - accuracy: 0.8202\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4545 - accuracy: 0.7921\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3901 - accuracy: 0.8315\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4269 - accuracy: 0.8090\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4052 - accuracy: 0.8146\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3914 - accuracy: 0.8315\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 255us/step - loss: 0.4058 - accuracy: 0.8202\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4132 - accuracy: 0.8371\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4514 - accuracy: 0.7865\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4373 - accuracy: 0.7978\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4102 - accuracy: 0.8034\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3899 - accuracy: 0.8146\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3921 - accuracy: 0.8315\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4100 - accuracy: 0.8539\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4095 - accuracy: 0.8315\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3804 - accuracy: 0.8427\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3738 - accuracy: 0.8146\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3834 - accuracy: 0.8371\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3698 - accuracy: 0.8315\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3729 - accuracy: 0.8483\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4204 - accuracy: 0.8258\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4131 - accuracy: 0.8258\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3686 - accuracy: 0.8427\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3487 - accuracy: 0.8652\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3955 - accuracy: 0.8539\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4099 - accuracy: 0.8258\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3873 - accuracy: 0.8427\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3579 - accuracy: 0.8539\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3963 - accuracy: 0.8315\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3602 - accuracy: 0.8483\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4004 - accuracy: 0.8371\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3740 - accuracy: 0.8371\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3632 - accuracy: 0.8315\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3960 - accuracy: 0.8146\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3595 - accuracy: 0.8427\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3606 - accuracy: 0.8371\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3770 - accuracy: 0.8427\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3675 - accuracy: 0.8315\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3614 - accuracy: 0.8427\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3307 - accuracy: 0.8652\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3469 - accuracy: 0.8315\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3845 - accuracy: 0.8202\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3667 - accuracy: 0.8539\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3680 - accuracy: 0.8596\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4251 - accuracy: 0.8034\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3579 - accuracy: 0.8258\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3906 - accuracy: 0.8371\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3587 - accuracy: 0.8539\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3811 - accuracy: 0.8483\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3351 - accuracy: 0.8315\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4054 - accuracy: 0.8146\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3808 - accuracy: 0.8371\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3933 - accuracy: 0.8820\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3973 - accuracy: 0.8315\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3338 - accuracy: 0.8483\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3693 - accuracy: 0.8483\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3604 - accuracy: 0.8483\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3936 - accuracy: 0.8427\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3539 - accuracy: 0.8708\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3455 - accuracy: 0.8539\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3282 - accuracy: 0.8708\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3892 - accuracy: 0.8258\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.3559 - accuracy: 0.8315\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3698 - accuracy: 0.8483\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3191 - accuracy: 0.8820\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3599 - accuracy: 0.8483\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3407 - accuracy: 0.8539\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3746 - accuracy: 0.8258\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3632 - accuracy: 0.8371\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3499 - accuracy: 0.8427\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3665 - accuracy: 0.8371\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3687 - accuracy: 0.8427\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3594 - accuracy: 0.8315\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3440 - accuracy: 0.8708\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3356 - accuracy: 0.8483\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3307 - accuracy: 0.8652\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3613 - accuracy: 0.8708\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3769 - accuracy: 0.8483\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3572 - accuracy: 0.8258\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3179 - accuracy: 0.8596\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3325 - accuracy: 0.8596\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3486 - accuracy: 0.8539\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3109 - accuracy: 0.8652\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3503 - accuracy: 0.8652\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3583 - accuracy: 0.8483\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3352 - accuracy: 0.8539\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3480 - accuracy: 0.8371\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3383 - accuracy: 0.8539\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3545 - accuracy: 0.8315\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3757 - accuracy: 0.8258\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3648 - accuracy: 0.8596\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3397 - accuracy: 0.8596\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3384 - accuracy: 0.8652\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3226 - accuracy: 0.8764\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.2967 - accuracy: 0.8820\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3578 - accuracy: 0.8315\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3123 - accuracy: 0.8933\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3655 - accuracy: 0.8652\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3355 - accuracy: 0.8371\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3520 - accuracy: 0.8371\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3581 - accuracy: 0.8539\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3242 - accuracy: 0.8933\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.2990 - accuracy: 0.8820\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3241 - accuracy: 0.8539\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 223us/step - loss: 0.3483 - accuracy: 0.8539\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3565 - accuracy: 0.8315\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3286 - accuracy: 0.8652\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3573 - accuracy: 0.8427\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3267 - accuracy: 0.8483\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3307 - accuracy: 0.8427\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.2979 - accuracy: 0.8596\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3239 - accuracy: 0.8315\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3253 - accuracy: 0.8764\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2977 - accuracy: 0.8708\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3339 - accuracy: 0.8596\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3555 - accuracy: 0.8483\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3246 - accuracy: 0.8708\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2840 - accuracy: 0.8764\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4100 - accuracy: 0.8090\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3038 - accuracy: 0.8539\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3021 - accuracy: 0.8483\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3455 - accuracy: 0.8427\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3580 - accuracy: 0.8427\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3651 - accuracy: 0.8596\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3189 - accuracy: 0.8820\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3483 - accuracy: 0.8652\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3172 - accuracy: 0.8652\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3493 - accuracy: 0.8652\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3730 - accuracy: 0.8596\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2730 - accuracy: 0.8764\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2931 - accuracy: 0.8764\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3548 - accuracy: 0.8371\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2974 - accuracy: 0.8764\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2949 - accuracy: 0.8708\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.2814 - accuracy: 0.8876\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4217 - accuracy: 0.8539\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3358 - accuracy: 0.8427\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3141 - accuracy: 0.8876\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2919 - accuracy: 0.8764\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3224 - accuracy: 0.8539\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3426 - accuracy: 0.8820\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3284 - accuracy: 0.8652\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2951 - accuracy: 0.9045\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3073 - accuracy: 0.8539\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3065 - accuracy: 0.8933\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3045 - accuracy: 0.8876\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2746 - accuracy: 0.9101\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3052 - accuracy: 0.8708\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3021 - accuracy: 0.8764\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3583 - accuracy: 0.8596\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3180 - accuracy: 0.8652\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3022 - accuracy: 0.8820\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3208 - accuracy: 0.8708\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3160 - accuracy: 0.8596\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.3159 - accuracy: 0.8652\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.3188 - accuracy: 0.8708\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3306 - accuracy: 0.8315\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3417 - accuracy: 0.8652\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2684 - accuracy: 0.8876\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2775 - accuracy: 0.8933\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2962 - accuracy: 0.8764\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2558 - accuracy: 0.8989\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3194 - accuracy: 0.8539\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3310 - accuracy: 0.8427\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3367 - accuracy: 0.8539\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3070 - accuracy: 0.8764\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3308 - accuracy: 0.8483\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3546 - accuracy: 0.8652\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2769 - accuracy: 0.8876\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3020 - accuracy: 0.8708\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3181 - accuracy: 0.8708\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3221 - accuracy: 0.8652\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3184 - accuracy: 0.8315\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2985 - accuracy: 0.8876\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2810 - accuracy: 0.8876\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3210 - accuracy: 0.8652\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3173 - accuracy: 0.8652\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3289 - accuracy: 0.8539\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2802 - accuracy: 0.8483\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3056 - accuracy: 0.8652\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3417 - accuracy: 0.8820\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2847 - accuracy: 0.8989\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.3030 - accuracy: 0.9101\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.2793 - accuracy: 0.8933\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3489 - accuracy: 0.8652\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.2894 - accuracy: 0.8876\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2664 - accuracy: 0.9045\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2761 - accuracy: 0.9101\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2997 - accuracy: 0.8820\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3237 - accuracy: 0.8708\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2702 - accuracy: 0.9045\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.2637 - accuracy: 0.9213\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3389 - accuracy: 0.8596\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2974 - accuracy: 0.8764\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2902 - accuracy: 0.8820\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2994 - accuracy: 0.8764\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2263 - accuracy: 0.9045\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3003 - accuracy: 0.8596\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3301 - accuracy: 0.8708\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3258 - accuracy: 0.8989\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3189 - accuracy: 0.8315\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2685 - accuracy: 0.8820\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2944 - accuracy: 0.8989\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2466 - accuracy: 0.8989\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3254 - accuracy: 0.8764\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3028 - accuracy: 0.8596\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.2935 - accuracy: 0.8652\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3267 - accuracy: 0.8483\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2873 - accuracy: 0.8876\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3478 - accuracy: 0.8427\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3020 - accuracy: 0.8876\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2724 - accuracy: 0.9101\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2786 - accuracy: 0.8708\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3173 - accuracy: 0.8539\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3004 - accuracy: 0.8820\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2930 - accuracy: 0.8989\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2952 - accuracy: 0.8820\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2908 - accuracy: 0.8764\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3173 - accuracy: 0.8933\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2966 - accuracy: 0.9101\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2880 - accuracy: 0.8876\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2884 - accuracy: 0.8764\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2619 - accuracy: 0.9045\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3061 - accuracy: 0.8539\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3535 - accuracy: 0.8483\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3046 - accuracy: 0.8596\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3239 - accuracy: 0.8652\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3102 - accuracy: 0.8652\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2775 - accuracy: 0.8820\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3045 - accuracy: 0.8539\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.2597 - accuracy: 0.8764\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2963 - accuracy: 0.8764\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3130 - accuracy: 0.8764\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.2539 - accuracy: 0.9101\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3007 - accuracy: 0.9045\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2969 - accuracy: 0.8989\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2862 - accuracy: 0.8820\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2954 - accuracy: 0.9101\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2846 - accuracy: 0.9101\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3022 - accuracy: 0.8933\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3051 - accuracy: 0.8820\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3180 - accuracy: 0.8764\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2631 - accuracy: 0.8876\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2554 - accuracy: 0.9157\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2672 - accuracy: 0.8764\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2650 - accuracy: 0.8876\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2813 - accuracy: 0.8820\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.2829 - accuracy: 0.8933\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2466 - accuracy: 0.9101\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2532 - accuracy: 0.9101\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2891 - accuracy: 0.8652\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2446 - accuracy: 0.8933\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2951 - accuracy: 0.8933\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3598 - accuracy: 0.8427\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2744 - accuracy: 0.8989\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2722 - accuracy: 0.8820\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3190 - accuracy: 0.8652\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2798 - accuracy: 0.8876\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2652 - accuracy: 0.8989\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2692 - accuracy: 0.8820\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 231us/step - loss: 0.2881 - accuracy: 0.8652\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2868 - accuracy: 0.8933\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3153 - accuracy: 0.8539\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2455 - accuracy: 0.8933\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2755 - accuracy: 0.9045\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2424 - accuracy: 0.8933\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2567 - accuracy: 0.9045\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2535 - accuracy: 0.9157\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.2887 - accuracy: 0.8652\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2569 - accuracy: 0.8989\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2695 - accuracy: 0.8820\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2913 - accuracy: 0.8989\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2482 - accuracy: 0.8876\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2566 - accuracy: 0.8876\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2817 - accuracy: 0.8933\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.2866 - accuracy: 0.8876\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2766 - accuracy: 0.8708\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2986 - accuracy: 0.8652\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2585 - accuracy: 0.8933\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2680 - accuracy: 0.9101\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2965 - accuracy: 0.8820\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2612 - accuracy: 0.8989\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2273 - accuracy: 0.9157\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2744 - accuracy: 0.9045\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.2855 - accuracy: 0.8989\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2946 - accuracy: 0.9045\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2645 - accuracy: 0.8989\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2668 - accuracy: 0.8764\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2621 - accuracy: 0.9101\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2784 - accuracy: 0.8820\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3426 - accuracy: 0.8427\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.2997 - accuracy: 0.8764\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2469 - accuracy: 0.8989\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2332 - accuracy: 0.9157\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2646 - accuracy: 0.8933\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3061 - accuracy: 0.8989\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2683 - accuracy: 0.9045\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3098 - accuracy: 0.8876\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2391 - accuracy: 0.9213\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2485 - accuracy: 0.9045\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2932 - accuracy: 0.8652\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2645 - accuracy: 0.9213\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2247 - accuracy: 0.9101\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2248 - accuracy: 0.9270\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2489 - accuracy: 0.9157\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2680 - accuracy: 0.8876\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.2688 - accuracy: 0.8876\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2226 - accuracy: 0.9045\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2667 - accuracy: 0.9101\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2645 - accuracy: 0.8933\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2895 - accuracy: 0.8989\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.2830 - accuracy: 0.8820\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2328 - accuracy: 0.9101\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2339 - accuracy: 0.9101\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2979 - accuracy: 0.8933\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2983 - accuracy: 0.8820\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2843 - accuracy: 0.8820\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2769 - accuracy: 0.8876\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2901 - accuracy: 0.8764\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.2407 - accuracy: 0.8933\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.2129 - accuracy: 0.9270\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3303 - accuracy: 0.8764\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2628 - accuracy: 0.8820\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2525 - accuracy: 0.9045\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.3099 - accuracy: 0.8989\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.1951 - accuracy: 0.9213\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2759 - accuracy: 0.9045\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2718 - accuracy: 0.8876\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.2293 - accuracy: 0.9157\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2718 - accuracy: 0.8820\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2664 - accuracy: 0.9101\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2645 - accuracy: 0.8764\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2436 - accuracy: 0.8989\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2702 - accuracy: 0.8933\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.2305 - accuracy: 0.9213\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2733 - accuracy: 0.8876\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2563 - accuracy: 0.9045\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.2731 - accuracy: 0.9045\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.2934 - accuracy: 0.8933\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.2797 - accuracy: 0.8876\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.2553 - accuracy: 0.9213\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.2307 - accuracy: 0.9157\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2504 - accuracy: 0.9101\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.2361 - accuracy: 0.9101\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.2619 - accuracy: 0.8708\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.2710 - accuracy: 0.9101\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.2649 - accuracy: 0.8708\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.2709 - accuracy: 0.8933\n",
      "713/713 [==============================] - 1s 736us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.5414 - accuracy: 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4760 - accuracy: 0.8025\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4523 - accuracy: 0.8092\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4480 - accuracy: 0.8114\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4361 - accuracy: 0.8227\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4488 - accuracy: 0.8204\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4410 - accuracy: 0.8204\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4118 - accuracy: 0.8361\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4267 - accuracy: 0.8137\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4260 - accuracy: 0.8260\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4060 - accuracy: 0.8328\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4190 - accuracy: 0.8361\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4253 - accuracy: 0.8215\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4284 - accuracy: 0.8193\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4054 - accuracy: 0.8260\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4024 - accuracy: 0.8294\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4180 - accuracy: 0.8283\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4177 - accuracy: 0.8350\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4256 - accuracy: 0.8283\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4130 - accuracy: 0.8215\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4164 - accuracy: 0.8114\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4168 - accuracy: 0.8114\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3982 - accuracy: 0.8395\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4017 - accuracy: 0.8328\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4007 - accuracy: 0.8350\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3949 - accuracy: 0.8373\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4000 - accuracy: 0.8462\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4031 - accuracy: 0.8384\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4033 - accuracy: 0.8339\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4156 - accuracy: 0.8283\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4159 - accuracy: 0.8294\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4022 - accuracy: 0.8406\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3964 - accuracy: 0.8384\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4110 - accuracy: 0.8316\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4035 - accuracy: 0.8339\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4059 - accuracy: 0.8328\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4001 - accuracy: 0.8339\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4086 - accuracy: 0.8272\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4076 - accuracy: 0.8193\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4152 - accuracy: 0.8114\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4003 - accuracy: 0.8294\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4229 - accuracy: 0.8260\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4070 - accuracy: 0.8249\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3910 - accuracy: 0.8395\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3819 - accuracy: 0.8496\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4130 - accuracy: 0.8305\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3881 - accuracy: 0.8418\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3831 - accuracy: 0.8418\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3902 - accuracy: 0.8462\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3890 - accuracy: 0.8485\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3895 - accuracy: 0.8339\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4017 - accuracy: 0.8451\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3913 - accuracy: 0.8361\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3976 - accuracy: 0.8485\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3968 - accuracy: 0.8384\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3924 - accuracy: 0.8361\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3993 - accuracy: 0.8384\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3916 - accuracy: 0.8429\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3970 - accuracy: 0.8238\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3814 - accuracy: 0.8384\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4008 - accuracy: 0.8350\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3987 - accuracy: 0.8440\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3995 - accuracy: 0.8238\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3852 - accuracy: 0.8429\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3809 - accuracy: 0.8462\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3951 - accuracy: 0.8316\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3883 - accuracy: 0.8283\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3842 - accuracy: 0.8496\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3867 - accuracy: 0.8474\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3891 - accuracy: 0.8406\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3979 - accuracy: 0.8373\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3783 - accuracy: 0.8519\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3947 - accuracy: 0.8328\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3930 - accuracy: 0.8406\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4021 - accuracy: 0.8339\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3799 - accuracy: 0.8451\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3943 - accuracy: 0.8373\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4000 - accuracy: 0.8429\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3780 - accuracy: 0.8328\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3986 - accuracy: 0.8339\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3769 - accuracy: 0.8462\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3878 - accuracy: 0.8395\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3759 - accuracy: 0.8418\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4061 - accuracy: 0.8451\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3997 - accuracy: 0.8350\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3797 - accuracy: 0.8395\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3835 - accuracy: 0.8496\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3662 - accuracy: 0.8541\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3809 - accuracy: 0.8406\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3874 - accuracy: 0.8418\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3842 - accuracy: 0.8384\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3825 - accuracy: 0.8541\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3771 - accuracy: 0.8440\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3824 - accuracy: 0.8440\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3968 - accuracy: 0.8328\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3984 - accuracy: 0.8384\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3910 - accuracy: 0.8418\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3879 - accuracy: 0.8384\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3857 - accuracy: 0.8373\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4001 - accuracy: 0.8350\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3758 - accuracy: 0.8496\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4050 - accuracy: 0.8260\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3982 - accuracy: 0.8406\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3858 - accuracy: 0.8395\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3901 - accuracy: 0.8316\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3707 - accuracy: 0.8451\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3802 - accuracy: 0.8429\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3861 - accuracy: 0.8373\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3799 - accuracy: 0.8440\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3715 - accuracy: 0.8462\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3911 - accuracy: 0.8451\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3857 - accuracy: 0.8462\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3987 - accuracy: 0.8429\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3861 - accuracy: 0.8440\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3860 - accuracy: 0.8440\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3915 - accuracy: 0.8272\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3743 - accuracy: 0.8474\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3875 - accuracy: 0.8474\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3686 - accuracy: 0.8563\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3914 - accuracy: 0.8451\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3760 - accuracy: 0.8530\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3880 - accuracy: 0.8384\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3824 - accuracy: 0.8462\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3847 - accuracy: 0.8373\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3902 - accuracy: 0.8294\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3863 - accuracy: 0.8462\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3844 - accuracy: 0.8541\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3777 - accuracy: 0.8563\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3893 - accuracy: 0.8474\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3761 - accuracy: 0.8395\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3765 - accuracy: 0.8552\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3758 - accuracy: 0.8530\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3921 - accuracy: 0.8316\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3896 - accuracy: 0.8485\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3750 - accuracy: 0.8541\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3817 - accuracy: 0.8406\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3675 - accuracy: 0.8485\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3810 - accuracy: 0.8485\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3872 - accuracy: 0.8474\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3860 - accuracy: 0.8395\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3730 - accuracy: 0.8361\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3626 - accuracy: 0.8485\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3815 - accuracy: 0.8429\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3703 - accuracy: 0.8519\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3790 - accuracy: 0.8552\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3788 - accuracy: 0.8541\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3666 - accuracy: 0.8541\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3778 - accuracy: 0.8429\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3924 - accuracy: 0.8429\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3769 - accuracy: 0.8485\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3764 - accuracy: 0.8440\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3785 - accuracy: 0.8575\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3799 - accuracy: 0.8474\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3794 - accuracy: 0.8406\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3789 - accuracy: 0.8339\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3854 - accuracy: 0.8328\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3851 - accuracy: 0.8474\n",
      "Epoch 158/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 234us/step - loss: 0.3625 - accuracy: 0.8530\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3617 - accuracy: 0.8530\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3897 - accuracy: 0.8373\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3856 - accuracy: 0.8339\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3658 - accuracy: 0.8406\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3780 - accuracy: 0.8429\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3785 - accuracy: 0.8440\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3708 - accuracy: 0.8429\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3801 - accuracy: 0.8328\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3787 - accuracy: 0.8451\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3617 - accuracy: 0.8519\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3704 - accuracy: 0.8474\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3881 - accuracy: 0.8406\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3836 - accuracy: 0.8429\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3764 - accuracy: 0.8485\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3734 - accuracy: 0.8485\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3786 - accuracy: 0.8339\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3678 - accuracy: 0.8406\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3740 - accuracy: 0.8406\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3736 - accuracy: 0.8474\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3646 - accuracy: 0.8507\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3754 - accuracy: 0.8418\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3722 - accuracy: 0.8485\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3708 - accuracy: 0.8474\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3678 - accuracy: 0.8418\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3713 - accuracy: 0.8496\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3693 - accuracy: 0.8530\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3773 - accuracy: 0.8485\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3717 - accuracy: 0.8485\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3722 - accuracy: 0.8384\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3766 - accuracy: 0.8451\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3675 - accuracy: 0.8530\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3752 - accuracy: 0.8530\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3798 - accuracy: 0.8451\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3650 - accuracy: 0.8530\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3643 - accuracy: 0.8451\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3733 - accuracy: 0.8563\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3781 - accuracy: 0.8384\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.3639 - accuracy: 0.8541\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3707 - accuracy: 0.8552\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3623 - accuracy: 0.8395\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3715 - accuracy: 0.8462\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3646 - accuracy: 0.8541\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3711 - accuracy: 0.8541\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3888 - accuracy: 0.8316\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3672 - accuracy: 0.8485\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3721 - accuracy: 0.8395\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3674 - accuracy: 0.8563\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3802 - accuracy: 0.8451\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3691 - accuracy: 0.8474\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3742 - accuracy: 0.8440\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3756 - accuracy: 0.8440\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3669 - accuracy: 0.8530\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3472 - accuracy: 0.8620\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3748 - accuracy: 0.8406\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3818 - accuracy: 0.8384\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3754 - accuracy: 0.8328\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 409us/step - loss: 0.3818 - accuracy: 0.8328\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3631 - accuracy: 0.8474\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3602 - accuracy: 0.8575\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3716 - accuracy: 0.8496\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.3684 - accuracy: 0.8530\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.3607 - accuracy: 0.8552\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 268us/step - loss: 0.3845 - accuracy: 0.8418\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.3726 - accuracy: 0.8496\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.3627 - accuracy: 0.8496\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3747 - accuracy: 0.8429\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3657 - accuracy: 0.8541\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.3655 - accuracy: 0.8429\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3554 - accuracy: 0.8563\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3479 - accuracy: 0.8642\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3811 - accuracy: 0.8429\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3554 - accuracy: 0.8496\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3658 - accuracy: 0.8530\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3731 - accuracy: 0.8575\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3634 - accuracy: 0.8519\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3586 - accuracy: 0.8440\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3785 - accuracy: 0.8429\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3829 - accuracy: 0.8418\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3834 - accuracy: 0.8339\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3589 - accuracy: 0.8530\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3661 - accuracy: 0.8530\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3957 - accuracy: 0.8361\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3691 - accuracy: 0.8485\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3588 - accuracy: 0.8620\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3544 - accuracy: 0.8563\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3576 - accuracy: 0.8552\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3707 - accuracy: 0.8541\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3734 - accuracy: 0.8552\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3586 - accuracy: 0.8507\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3574 - accuracy: 0.8575\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3692 - accuracy: 0.8485\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3650 - accuracy: 0.8563\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3570 - accuracy: 0.8530\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3782 - accuracy: 0.8395\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3684 - accuracy: 0.8462\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3706 - accuracy: 0.8620\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3614 - accuracy: 0.8541\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3618 - accuracy: 0.8541\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3826 - accuracy: 0.8339\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3729 - accuracy: 0.8462\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3683 - accuracy: 0.8485\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3566 - accuracy: 0.8631\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3827 - accuracy: 0.8328\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3775 - accuracy: 0.8440\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3840 - accuracy: 0.8373\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3660 - accuracy: 0.8519\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3759 - accuracy: 0.8474\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3534 - accuracy: 0.8541\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3623 - accuracy: 0.8496\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3627 - accuracy: 0.8440\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3653 - accuracy: 0.8530\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3793 - accuracy: 0.8519\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3643 - accuracy: 0.8563\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3603 - accuracy: 0.8608\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3596 - accuracy: 0.8451\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3667 - accuracy: 0.8563\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3618 - accuracy: 0.8496\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3718 - accuracy: 0.8519\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3732 - accuracy: 0.8485\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3618 - accuracy: 0.8530\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3770 - accuracy: 0.8429\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3555 - accuracy: 0.8563\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3767 - accuracy: 0.8485\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3677 - accuracy: 0.8530\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3498 - accuracy: 0.8507\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3690 - accuracy: 0.8406\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3761 - accuracy: 0.8451\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3505 - accuracy: 0.8676\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3664 - accuracy: 0.8519\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3705 - accuracy: 0.8406\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3658 - accuracy: 0.8485\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3693 - accuracy: 0.8429\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3709 - accuracy: 0.8496\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3555 - accuracy: 0.8496\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3580 - accuracy: 0.8597\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3783 - accuracy: 0.8395\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3553 - accuracy: 0.8507\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3617 - accuracy: 0.8530\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3510 - accuracy: 0.8519\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3660 - accuracy: 0.8451\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3670 - accuracy: 0.8474\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3676 - accuracy: 0.8474\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3756 - accuracy: 0.8418\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3699 - accuracy: 0.8563\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3648 - accuracy: 0.8485\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3627 - accuracy: 0.8563\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3716 - accuracy: 0.8474\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3784 - accuracy: 0.8429\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3685 - accuracy: 0.8620\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3652 - accuracy: 0.8451\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3581 - accuracy: 0.8631\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3752 - accuracy: 0.8418\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3616 - accuracy: 0.8507\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3686 - accuracy: 0.8597\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3530 - accuracy: 0.8597\n",
      "Epoch 314/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 239us/step - loss: 0.3771 - accuracy: 0.8350\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3576 - accuracy: 0.8496\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3582 - accuracy: 0.8642\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3717 - accuracy: 0.8429\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3697 - accuracy: 0.8406\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3778 - accuracy: 0.8530\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3718 - accuracy: 0.8429\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3592 - accuracy: 0.8530\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3714 - accuracy: 0.8474\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3641 - accuracy: 0.8563\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3571 - accuracy: 0.8507\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3670 - accuracy: 0.8462\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3555 - accuracy: 0.8496\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3432 - accuracy: 0.8653\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3689 - accuracy: 0.8519\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3655 - accuracy: 0.8485\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3689 - accuracy: 0.8597\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3605 - accuracy: 0.8496\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3565 - accuracy: 0.8541\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3474 - accuracy: 0.8664\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3583 - accuracy: 0.8519\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3691 - accuracy: 0.8552\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3740 - accuracy: 0.8440\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3448 - accuracy: 0.8777\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3618 - accuracy: 0.8530\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3632 - accuracy: 0.8519\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3632 - accuracy: 0.8597\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3650 - accuracy: 0.8507\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3563 - accuracy: 0.8608\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3517 - accuracy: 0.8519\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3417 - accuracy: 0.8552\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3391 - accuracy: 0.8687\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3628 - accuracy: 0.8541\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3579 - accuracy: 0.8563\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3536 - accuracy: 0.8485\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3533 - accuracy: 0.8597\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3629 - accuracy: 0.8507\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3704 - accuracy: 0.8462\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3636 - accuracy: 0.8474\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3751 - accuracy: 0.8507\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3567 - accuracy: 0.8575\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3685 - accuracy: 0.8406\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3582 - accuracy: 0.8519\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3649 - accuracy: 0.8541\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3494 - accuracy: 0.8563\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3537 - accuracy: 0.8586\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3831 - accuracy: 0.8406\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3805 - accuracy: 0.8373\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3670 - accuracy: 0.8496\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3612 - accuracy: 0.8552\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3662 - accuracy: 0.8519\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3451 - accuracy: 0.8586\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3498 - accuracy: 0.8631\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3576 - accuracy: 0.8474\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.3519 - accuracy: 0.8519\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.3744 - accuracy: 0.8519\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3740 - accuracy: 0.8507\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3497 - accuracy: 0.8620\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3782 - accuracy: 0.8440\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3533 - accuracy: 0.8451\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3750 - accuracy: 0.8519\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3639 - accuracy: 0.8507\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3661 - accuracy: 0.8474\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3808 - accuracy: 0.8519\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3616 - accuracy: 0.8485\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3481 - accuracy: 0.8631\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3560 - accuracy: 0.8541\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3732 - accuracy: 0.8552\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3709 - accuracy: 0.8474\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3634 - accuracy: 0.8552\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3535 - accuracy: 0.8530\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3691 - accuracy: 0.8586\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3485 - accuracy: 0.8586\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3538 - accuracy: 0.8496\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3607 - accuracy: 0.8440\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3362 - accuracy: 0.8631\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3648 - accuracy: 0.8530\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3538 - accuracy: 0.8608\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3610 - accuracy: 0.8631\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3538 - accuracy: 0.8552\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3488 - accuracy: 0.8462\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3799 - accuracy: 0.8384\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3638 - accuracy: 0.8575\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3481 - accuracy: 0.8519\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3714 - accuracy: 0.8429\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3460 - accuracy: 0.8575\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3630 - accuracy: 0.8462\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "relu, 100, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 0.7016 - accuracy: 0.5955\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.6429 - accuracy: 0.6910\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.6164 - accuracy: 0.6798\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.5723 - accuracy: 0.7079\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.5709 - accuracy: 0.7303\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.5006 - accuracy: 0.7697\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.5327 - accuracy: 0.7978\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.5168 - accuracy: 0.7247\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5156 - accuracy: 0.7697\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.5514 - accuracy: 0.7416\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.5880 - accuracy: 0.7303\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.5339 - accuracy: 0.7135\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.4856 - accuracy: 0.7584\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.5389 - accuracy: 0.7247\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.4931 - accuracy: 0.7640\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.5143 - accuracy: 0.7303\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.5273 - accuracy: 0.7416\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.5116 - accuracy: 0.7753\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.5032 - accuracy: 0.7528\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4905 - accuracy: 0.7921\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4525 - accuracy: 0.7921\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4656 - accuracy: 0.7865\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4412 - accuracy: 0.7865\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4763 - accuracy: 0.7640\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4872 - accuracy: 0.7809\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4996 - accuracy: 0.7809\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4715 - accuracy: 0.8146\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4490 - accuracy: 0.7921\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.4710 - accuracy: 0.8090\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4292 - accuracy: 0.8090\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4487 - accuracy: 0.7809\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4338 - accuracy: 0.8202\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4663 - accuracy: 0.8202\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3941 - accuracy: 0.8315\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4145 - accuracy: 0.7978\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4851 - accuracy: 0.7865\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4766 - accuracy: 0.8146\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4030 - accuracy: 0.8258\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4667 - accuracy: 0.7753\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4172 - accuracy: 0.8090\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4202 - accuracy: 0.8034\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4385 - accuracy: 0.8090\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3969 - accuracy: 0.8596\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4850 - accuracy: 0.7697\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4448 - accuracy: 0.8146\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4233 - accuracy: 0.8090\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4481 - accuracy: 0.8090\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4448 - accuracy: 0.7921\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4066 - accuracy: 0.8202\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4281 - accuracy: 0.8146\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3836 - accuracy: 0.8258\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4514 - accuracy: 0.7865\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4449 - accuracy: 0.8034\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4391 - accuracy: 0.8202\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.4014 - accuracy: 0.8483\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3976 - accuracy: 0.8371\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4969 - accuracy: 0.7978\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4020 - accuracy: 0.8427\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3529 - accuracy: 0.8539\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4504 - accuracy: 0.8258\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4303 - accuracy: 0.7978\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4213 - accuracy: 0.8090\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3948 - accuracy: 0.8090\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4705 - accuracy: 0.7809\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4461 - accuracy: 0.8315\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3954 - accuracy: 0.8371\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 339us/step - loss: 0.4287 - accuracy: 0.8371\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4149 - accuracy: 0.8034\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.4208 - accuracy: 0.8034\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4333 - accuracy: 0.8258\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.3915 - accuracy: 0.8258\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4000 - accuracy: 0.7978\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.3728 - accuracy: 0.8315\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4245 - accuracy: 0.8315\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4436 - accuracy: 0.8202\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.4515 - accuracy: 0.8371\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.3804 - accuracy: 0.8371\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3775 - accuracy: 0.8539\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3833 - accuracy: 0.8652\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3611 - accuracy: 0.8596\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3516 - accuracy: 0.8708\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4066 - accuracy: 0.8371\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3482 - accuracy: 0.8596\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3675 - accuracy: 0.8427\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3598 - accuracy: 0.8427\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4496 - accuracy: 0.7865\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3628 - accuracy: 0.8708\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3776 - accuracy: 0.8427\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4361 - accuracy: 0.8146\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.3954 - accuracy: 0.8202\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3976 - accuracy: 0.8090\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3576 - accuracy: 0.8539\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3524 - accuracy: 0.8652\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.4007 - accuracy: 0.8202\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3891 - accuracy: 0.8539\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3812 - accuracy: 0.8427\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4007 - accuracy: 0.8371\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.3875 - accuracy: 0.8483\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.3678 - accuracy: 0.8371\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3661 - accuracy: 0.8483\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3936 - accuracy: 0.8596\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3708 - accuracy: 0.8258\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.3631 - accuracy: 0.8146\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.3512 - accuracy: 0.8539\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.3577 - accuracy: 0.8596\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3889 - accuracy: 0.8315\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.3449 - accuracy: 0.8371\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3352 - accuracy: 0.8708\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.3486 - accuracy: 0.8708\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.3528 - accuracy: 0.8539\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3700 - accuracy: 0.8034\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.3238 - accuracy: 0.8483\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4590 - accuracy: 0.8146\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.3840 - accuracy: 0.8258\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3338 - accuracy: 0.8652\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.3772 - accuracy: 0.8146\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3934 - accuracy: 0.8202\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3443 - accuracy: 0.8427\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3363 - accuracy: 0.8539\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3565 - accuracy: 0.8708\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.3756 - accuracy: 0.8146\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3377 - accuracy: 0.8596\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.3084 - accuracy: 0.8708\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3363 - accuracy: 0.8371\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.3547 - accuracy: 0.8596\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3418 - accuracy: 0.8764\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.3585 - accuracy: 0.8539\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3197 - accuracy: 0.8596\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.4028 - accuracy: 0.8427\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.3675 - accuracy: 0.8652\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3793 - accuracy: 0.8427\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.3632 - accuracy: 0.8427\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3416 - accuracy: 0.8371\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3454 - accuracy: 0.8539\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.3605 - accuracy: 0.8258\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3438 - accuracy: 0.8539\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3579 - accuracy: 0.8483\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3673 - accuracy: 0.8652\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3384 - accuracy: 0.8483\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4285 - accuracy: 0.8258\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.3322 - accuracy: 0.8596\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3681 - accuracy: 0.8596\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.3177 - accuracy: 0.8652\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3964 - accuracy: 0.8202\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3715 - accuracy: 0.8258\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3447 - accuracy: 0.8315\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3751 - accuracy: 0.8539\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.3265 - accuracy: 0.8764\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3675 - accuracy: 0.8371\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3121 - accuracy: 0.8764\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3704 - accuracy: 0.8315\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3027 - accuracy: 0.8820\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3255 - accuracy: 0.8652\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3834 - accuracy: 0.8596\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3738 - accuracy: 0.8315\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3401 - accuracy: 0.8483\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 337us/step - loss: 0.3371 - accuracy: 0.8652\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3671 - accuracy: 0.8539\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3877 - accuracy: 0.8315\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3749 - accuracy: 0.8258\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.3607 - accuracy: 0.8258\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 366us/step - loss: 0.3619 - accuracy: 0.8539\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.2982 - accuracy: 0.8708\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3556 - accuracy: 0.8539\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3486 - accuracy: 0.8596\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3394 - accuracy: 0.8483\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3144 - accuracy: 0.8539\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3332 - accuracy: 0.8764\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3153 - accuracy: 0.8820\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3076 - accuracy: 0.8652\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.3277 - accuracy: 0.8539\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.3150 - accuracy: 0.8596\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.3269 - accuracy: 0.8596\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.3211 - accuracy: 0.8708\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3226 - accuracy: 0.8652\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.3346 - accuracy: 0.8764\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.2829 - accuracy: 0.8708\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.3473 - accuracy: 0.8483\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3049 - accuracy: 0.8764\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.3616 - accuracy: 0.8315\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3294 - accuracy: 0.8820\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3424 - accuracy: 0.8596\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2962 - accuracy: 0.8652\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 394us/step - loss: 0.3331 - accuracy: 0.8764\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 387us/step - loss: 0.2691 - accuracy: 0.8876\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 385us/step - loss: 0.3376 - accuracy: 0.8708\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.3301 - accuracy: 0.8764\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 380us/step - loss: 0.3254 - accuracy: 0.8483\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2909 - accuracy: 0.8820\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.3053 - accuracy: 0.8820\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.3458 - accuracy: 0.8652\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.3638 - accuracy: 0.8258\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.3173 - accuracy: 0.8764\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.3503 - accuracy: 0.8371\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3586 - accuracy: 0.8483\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.3151 - accuracy: 0.8427\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3058 - accuracy: 0.8989\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3194 - accuracy: 0.8539\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.2935 - accuracy: 0.8708\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.2963 - accuracy: 0.8652\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.3257 - accuracy: 0.8652\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.2853 - accuracy: 0.8876\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3200 - accuracy: 0.8371\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.3207 - accuracy: 0.8820\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.3626 - accuracy: 0.8596\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3443 - accuracy: 0.8596\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.3316 - accuracy: 0.8876\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3595 - accuracy: 0.8539\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3185 - accuracy: 0.8764\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.2991 - accuracy: 0.8539\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3082 - accuracy: 0.8596\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.2973 - accuracy: 0.8820\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3310 - accuracy: 0.8427\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.3517 - accuracy: 0.8539\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3504 - accuracy: 0.8483\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.2804 - accuracy: 0.8764\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.3140 - accuracy: 0.8764\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.2982 - accuracy: 0.8652\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.3387 - accuracy: 0.8764\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3209 - accuracy: 0.8483\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3737 - accuracy: 0.8202\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.3039 - accuracy: 0.8820\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 587us/step - loss: 0.3325 - accuracy: 0.8652\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 446us/step - loss: 0.3197 - accuracy: 0.8708\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 409us/step - loss: 0.3080 - accuracy: 0.8820\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.2910 - accuracy: 0.8876\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3307 - accuracy: 0.8596\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3447 - accuracy: 0.8596\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3050 - accuracy: 0.8539\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3411 - accuracy: 0.8989\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3311 - accuracy: 0.8708\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3519 - accuracy: 0.8539\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.3101 - accuracy: 0.8596\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3123 - accuracy: 0.8539\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3154 - accuracy: 0.8596\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3297 - accuracy: 0.8876\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3751 - accuracy: 0.8652\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.3064 - accuracy: 0.8933\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.2960 - accuracy: 0.8708\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.2917 - accuracy: 0.8876\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3016 - accuracy: 0.8708\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.3193 - accuracy: 0.8539\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.3062 - accuracy: 0.8483\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3442 - accuracy: 0.8315\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3261 - accuracy: 0.8708\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3617 - accuracy: 0.8596\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3407 - accuracy: 0.8427\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2919 - accuracy: 0.8708\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 504us/step - loss: 0.2810 - accuracy: 0.9045\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 395us/step - loss: 0.3031 - accuracy: 0.8820\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.2909 - accuracy: 0.8427\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.2970 - accuracy: 0.8483\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 360us/step - loss: 0.2597 - accuracy: 0.8652\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3066 - accuracy: 0.8876\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3596 - accuracy: 0.8596\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2879 - accuracy: 0.9045\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.2981 - accuracy: 0.8596\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3081 - accuracy: 0.8708\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.2628 - accuracy: 0.8876\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 339us/step - loss: 0.3435 - accuracy: 0.8764\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3004 - accuracy: 0.8820\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.2876 - accuracy: 0.8820\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.2977 - accuracy: 0.8820\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 373us/step - loss: 0.2957 - accuracy: 0.8876\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.2542 - accuracy: 0.8989\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.3213 - accuracy: 0.8652\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.2908 - accuracy: 0.9045\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3167 - accuracy: 0.8820\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3003 - accuracy: 0.8708\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2666 - accuracy: 0.8820\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.2764 - accuracy: 0.8764\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2681 - accuracy: 0.8820\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.2661 - accuracy: 0.8764\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2994 - accuracy: 0.8652\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.3021 - accuracy: 0.8820\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.2379 - accuracy: 0.8933\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3005 - accuracy: 0.8596\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3106 - accuracy: 0.8764\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3109 - accuracy: 0.8483\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.3036 - accuracy: 0.8708\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.2936 - accuracy: 0.8820\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2739 - accuracy: 0.9045\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3174 - accuracy: 0.8596\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.3244 - accuracy: 0.8427\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.3577 - accuracy: 0.8820\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.2500 - accuracy: 0.8876\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.3867 - accuracy: 0.8371\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.2958 - accuracy: 0.8876\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.3687 - accuracy: 0.8427\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.2809 - accuracy: 0.8764\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.2898 - accuracy: 0.8652\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.2502 - accuracy: 0.9101\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.2676 - accuracy: 0.8989\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.2976 - accuracy: 0.8764\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.2677 - accuracy: 0.9045\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2361 - accuracy: 0.8989\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3401 - accuracy: 0.8539\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2923 - accuracy: 0.8820\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2709 - accuracy: 0.8989\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2615 - accuracy: 0.8933\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.3402 - accuracy: 0.8539\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.2694 - accuracy: 0.8596\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3630 - accuracy: 0.8483\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3537 - accuracy: 0.8539\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.2449 - accuracy: 0.9157\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.2844 - accuracy: 0.8708\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.2668 - accuracy: 0.8933\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.2711 - accuracy: 0.8989\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.2850 - accuracy: 0.9045\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.2581 - accuracy: 0.9101\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3342 - accuracy: 0.8371\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.2783 - accuracy: 0.9101\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 320us/step - loss: 0.2634 - accuracy: 0.9101\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.3162 - accuracy: 0.8764\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.2989 - accuracy: 0.8652\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3152 - accuracy: 0.8483\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.2595 - accuracy: 0.9157\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3049 - accuracy: 0.8427\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2622 - accuracy: 0.9157\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2933 - accuracy: 0.8596\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.2894 - accuracy: 0.8764\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2897 - accuracy: 0.8820\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.3083 - accuracy: 0.8539\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.2806 - accuracy: 0.8820\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 356us/step - loss: 0.2624 - accuracy: 0.8933\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.2660 - accuracy: 0.9045\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.3361 - accuracy: 0.8989\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 472us/step - loss: 0.2745 - accuracy: 0.8820\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 392us/step - loss: 0.3296 - accuracy: 0.8764\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 388us/step - loss: 0.2335 - accuracy: 0.8989\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2869 - accuracy: 0.8764\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2930 - accuracy: 0.8989\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3299 - accuracy: 0.8708\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 373us/step - loss: 0.2377 - accuracy: 0.9101\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 433us/step - loss: 0.2880 - accuracy: 0.8989\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 437us/step - loss: 0.3318 - accuracy: 0.8539\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 397us/step - loss: 0.3216 - accuracy: 0.8483\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2783 - accuracy: 0.8820\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 339us/step - loss: 0.3053 - accuracy: 0.8820\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2790 - accuracy: 0.8820\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.2893 - accuracy: 0.8708\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.2763 - accuracy: 0.8876\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.2479 - accuracy: 0.9045\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.2872 - accuracy: 0.8933\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3152 - accuracy: 0.8596\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3506 - accuracy: 0.8820\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.3464 - accuracy: 0.8652\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.2490 - accuracy: 0.9045\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.2921 - accuracy: 0.9045\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.3273 - accuracy: 0.8820\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.2867 - accuracy: 0.8989\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 423us/step - loss: 0.2317 - accuracy: 0.9101\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.2972 - accuracy: 0.8933\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3174 - accuracy: 0.8820\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.3005 - accuracy: 0.8708\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 370us/step - loss: 0.2885 - accuracy: 0.8876\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2628 - accuracy: 0.8933\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2804 - accuracy: 0.8876\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.2759 - accuracy: 0.8933\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.2747 - accuracy: 0.8989\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.2648 - accuracy: 0.8989\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.3042 - accuracy: 0.8820\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.2785 - accuracy: 0.8989\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.2236 - accuracy: 0.9213\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3010 - accuracy: 0.8933\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.2733 - accuracy: 0.8652\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.2711 - accuracy: 0.8876\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.2953 - accuracy: 0.8876\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.2496 - accuracy: 0.8989\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.2918 - accuracy: 0.8876\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3042 - accuracy: 0.8764\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.2971 - accuracy: 0.8989\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.2776 - accuracy: 0.8876\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3252 - accuracy: 0.8708\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.2608 - accuracy: 0.8876\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3290 - accuracy: 0.8708\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3241 - accuracy: 0.8483\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.3107 - accuracy: 0.8933\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2988 - accuracy: 0.8933\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.2322 - accuracy: 0.9045\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.2449 - accuracy: 0.9045\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.3329 - accuracy: 0.8876\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3166 - accuracy: 0.8764\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2883 - accuracy: 0.8933\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3335 - accuracy: 0.8427\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.2655 - accuracy: 0.9045\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.2739 - accuracy: 0.8933\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 362us/step - loss: 0.2753 - accuracy: 0.8764\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.2965 - accuracy: 0.8989\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.2716 - accuracy: 0.8933\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.2635 - accuracy: 0.8708\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.2957 - accuracy: 0.8708\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.2964 - accuracy: 0.8483\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.2762 - accuracy: 0.9157\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.3372 - accuracy: 0.8539\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 364us/step - loss: 0.2639 - accuracy: 0.8989\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.2953 - accuracy: 0.8820\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.2992 - accuracy: 0.8820\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 339us/step - loss: 0.3109 - accuracy: 0.8876\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.2708 - accuracy: 0.9045\n",
      "713/713 [==============================] - 1s 930us/step\n",
      "Epoch 1/400\n",
      "570/891 [==================>...........] - ETA: 0s - loss: 0.5395 - accuracy: 0.8140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 312us/step - loss: 0.5215 - accuracy: 0.8036\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.4517 - accuracy: 0.8204\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.4414 - accuracy: 0.8114\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4176 - accuracy: 0.8260\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4266 - accuracy: 0.8249\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.4275 - accuracy: 0.8159\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4143 - accuracy: 0.8305\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4213 - accuracy: 0.8171\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4433 - accuracy: 0.8159\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4215 - accuracy: 0.8114\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4302 - accuracy: 0.8159\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4321 - accuracy: 0.8238\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4169 - accuracy: 0.8103\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4212 - accuracy: 0.8171\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4137 - accuracy: 0.8204\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4142 - accuracy: 0.8182\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4083 - accuracy: 0.8328\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4149 - accuracy: 0.8260\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4016 - accuracy: 0.8418\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4139 - accuracy: 0.8361\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3937 - accuracy: 0.8316\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4031 - accuracy: 0.8294\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4126 - accuracy: 0.8328\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4164 - accuracy: 0.8249\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3968 - accuracy: 0.8305\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4087 - accuracy: 0.8328\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4207 - accuracy: 0.8204\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3816 - accuracy: 0.8339\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4010 - accuracy: 0.8373\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3871 - accuracy: 0.8316\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.4184 - accuracy: 0.8215\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.4142 - accuracy: 0.8238\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4137 - accuracy: 0.8328\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3893 - accuracy: 0.8418\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4125 - accuracy: 0.8339\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.4170 - accuracy: 0.8316\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3882 - accuracy: 0.8440\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4150 - accuracy: 0.8283\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4045 - accuracy: 0.8294\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3806 - accuracy: 0.8339\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.3962 - accuracy: 0.8373\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4032 - accuracy: 0.8328\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4090 - accuracy: 0.8238\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4040 - accuracy: 0.8361\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4029 - accuracy: 0.8215\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4029 - accuracy: 0.8350\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4026 - accuracy: 0.8384\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4056 - accuracy: 0.8316\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4005 - accuracy: 0.8294\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3986 - accuracy: 0.8361\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3928 - accuracy: 0.8440\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4205 - accuracy: 0.8260\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3946 - accuracy: 0.8384\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 433us/step - loss: 0.3947 - accuracy: 0.8316\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3975 - accuracy: 0.8328\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 379us/step - loss: 0.4005 - accuracy: 0.8350\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3958 - accuracy: 0.8440\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4050 - accuracy: 0.8395\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3980 - accuracy: 0.8305\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 410us/step - loss: 0.4060 - accuracy: 0.8373\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 387us/step - loss: 0.4007 - accuracy: 0.8272\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 371us/step - loss: 0.4050 - accuracy: 0.8204\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 432us/step - loss: 0.3918 - accuracy: 0.8462\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.4086 - accuracy: 0.8294\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 397us/step - loss: 0.4070 - accuracy: 0.8305\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 387us/step - loss: 0.4009 - accuracy: 0.8260\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 389us/step - loss: 0.4011 - accuracy: 0.8316\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 398us/step - loss: 0.3950 - accuracy: 0.8339\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.3892 - accuracy: 0.8440\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 413us/step - loss: 0.3930 - accuracy: 0.8418\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 403us/step - loss: 0.3908 - accuracy: 0.8418\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 408us/step - loss: 0.4038 - accuracy: 0.8429\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 414us/step - loss: 0.3857 - accuracy: 0.8361\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.3918 - accuracy: 0.8373\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4068 - accuracy: 0.8485\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4030 - accuracy: 0.8316\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.4012 - accuracy: 0.8238\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.3882 - accuracy: 0.8474\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.3993 - accuracy: 0.8294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3862 - accuracy: 0.8395\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3944 - accuracy: 0.8339\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3792 - accuracy: 0.8485\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.3957 - accuracy: 0.8305\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 385us/step - loss: 0.3969 - accuracy: 0.8361\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.3905 - accuracy: 0.8406\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 420us/step - loss: 0.4041 - accuracy: 0.8361\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 392us/step - loss: 0.3868 - accuracy: 0.8316\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.3915 - accuracy: 0.8496\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.3978 - accuracy: 0.8350\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3872 - accuracy: 0.8429\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4124 - accuracy: 0.8328\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.3905 - accuracy: 0.8316\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 367us/step - loss: 0.3859 - accuracy: 0.8440\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.4006 - accuracy: 0.8373\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 384us/step - loss: 0.3764 - accuracy: 0.8474\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 382us/step - loss: 0.3799 - accuracy: 0.8462\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3828 - accuracy: 0.8384\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3799 - accuracy: 0.8462\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 411us/step - loss: 0.3790 - accuracy: 0.8496\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 371us/step - loss: 0.3848 - accuracy: 0.8418\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 483us/step - loss: 0.3803 - accuracy: 0.8361\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 428us/step - loss: 0.4106 - accuracy: 0.8215\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 462us/step - loss: 0.3767 - accuracy: 0.8440\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 385us/step - loss: 0.3808 - accuracy: 0.8418\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.3885 - accuracy: 0.8440\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3879 - accuracy: 0.8406\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 371us/step - loss: 0.3899 - accuracy: 0.8429\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.3995 - accuracy: 0.8339\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 383us/step - loss: 0.3892 - accuracy: 0.8305\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3856 - accuracy: 0.8485\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3887 - accuracy: 0.8406\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.3995 - accuracy: 0.8373\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3821 - accuracy: 0.8485\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3902 - accuracy: 0.8440\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.3969 - accuracy: 0.8384\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3934 - accuracy: 0.8418\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 374us/step - loss: 0.3766 - accuracy: 0.8496\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3906 - accuracy: 0.8395\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3838 - accuracy: 0.8350\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3819 - accuracy: 0.8384\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.3851 - accuracy: 0.8496\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3722 - accuracy: 0.8440\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.3764 - accuracy: 0.8440\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.3882 - accuracy: 0.8384\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.3819 - accuracy: 0.8373\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.3716 - accuracy: 0.8485\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3926 - accuracy: 0.8350\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 386us/step - loss: 0.3835 - accuracy: 0.8440\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3911 - accuracy: 0.8395\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3735 - accuracy: 0.8552\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3914 - accuracy: 0.8384\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3752 - accuracy: 0.8507\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3976 - accuracy: 0.8316\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3839 - accuracy: 0.8406\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.3955 - accuracy: 0.8350\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 390us/step - loss: 0.3717 - accuracy: 0.8507\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3817 - accuracy: 0.8418\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.3860 - accuracy: 0.8384\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 380us/step - loss: 0.3830 - accuracy: 0.8283\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3872 - accuracy: 0.8418\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3777 - accuracy: 0.8485\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3699 - accuracy: 0.8462\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3883 - accuracy: 0.8395\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3954 - accuracy: 0.8485\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.3635 - accuracy: 0.8485\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3706 - accuracy: 0.8418\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 407us/step - loss: 0.3860 - accuracy: 0.8249\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.3905 - accuracy: 0.8350\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.3826 - accuracy: 0.8361\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3856 - accuracy: 0.8283\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3834 - accuracy: 0.8406\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3666 - accuracy: 0.8563\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3809 - accuracy: 0.8339\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3764 - accuracy: 0.8474\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3862 - accuracy: 0.8373\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3769 - accuracy: 0.8440\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3860 - accuracy: 0.8395\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3895 - accuracy: 0.8294\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3940 - accuracy: 0.8249\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3778 - accuracy: 0.8395\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3784 - accuracy: 0.8395\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3771 - accuracy: 0.8272\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.3832 - accuracy: 0.8440\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4040 - accuracy: 0.8350\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.3870 - accuracy: 0.8305\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3844 - accuracy: 0.8395\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3715 - accuracy: 0.8496\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 423us/step - loss: 0.3861 - accuracy: 0.8373\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3810 - accuracy: 0.8440\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.3732 - accuracy: 0.8541\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3822 - accuracy: 0.8451\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3751 - accuracy: 0.8418\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3958 - accuracy: 0.8260\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3847 - accuracy: 0.8429\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 501us/step - loss: 0.3857 - accuracy: 0.8406\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3772 - accuracy: 0.8429\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 441us/step - loss: 0.3806 - accuracy: 0.8418\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.3841 - accuracy: 0.8440\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3868 - accuracy: 0.8406\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3848 - accuracy: 0.8406\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3724 - accuracy: 0.8373\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3788 - accuracy: 0.8507\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3837 - accuracy: 0.8395\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3834 - accuracy: 0.8418\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3585 - accuracy: 0.8474\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3772 - accuracy: 0.8406\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3577 - accuracy: 0.8530\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3838 - accuracy: 0.8339\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 349us/step - loss: 0.3955 - accuracy: 0.8373\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3765 - accuracy: 0.8429\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3614 - accuracy: 0.8586\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3805 - accuracy: 0.8395\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3790 - accuracy: 0.8451\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3703 - accuracy: 0.8507\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3824 - accuracy: 0.8395\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3717 - accuracy: 0.8485\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3794 - accuracy: 0.8462\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3821 - accuracy: 0.8384\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3825 - accuracy: 0.8519\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3830 - accuracy: 0.8316\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3809 - accuracy: 0.8462\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3850 - accuracy: 0.8384\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3835 - accuracy: 0.8485\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3831 - accuracy: 0.8406\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3867 - accuracy: 0.8485\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3774 - accuracy: 0.8530\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3869 - accuracy: 0.8339\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3811 - accuracy: 0.8429\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3787 - accuracy: 0.8418\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3878 - accuracy: 0.8384\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3765 - accuracy: 0.8305\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3790 - accuracy: 0.8474\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3871 - accuracy: 0.8462\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3663 - accuracy: 0.8519\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3844 - accuracy: 0.8361\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3853 - accuracy: 0.8350\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3650 - accuracy: 0.8496\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3881 - accuracy: 0.8305\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3721 - accuracy: 0.8530\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3644 - accuracy: 0.8462\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3743 - accuracy: 0.8406\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3956 - accuracy: 0.8373\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3587 - accuracy: 0.8451\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3605 - accuracy: 0.8519\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3774 - accuracy: 0.8474\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3858 - accuracy: 0.8373\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3699 - accuracy: 0.8384\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3742 - accuracy: 0.8530\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3795 - accuracy: 0.8541\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3720 - accuracy: 0.8451\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3806 - accuracy: 0.8496\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3806 - accuracy: 0.8429\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3803 - accuracy: 0.8474\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3832 - accuracy: 0.8328\n",
      "Epoch 236/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 321us/step - loss: 0.3706 - accuracy: 0.8451\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3802 - accuracy: 0.8451\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3792 - accuracy: 0.8451\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3579 - accuracy: 0.8451\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3724 - accuracy: 0.8519\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3835 - accuracy: 0.8328\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3745 - accuracy: 0.8451\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3729 - accuracy: 0.8373\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3615 - accuracy: 0.8418\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3603 - accuracy: 0.8507\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3818 - accuracy: 0.8418\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3817 - accuracy: 0.8384\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3586 - accuracy: 0.8496\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3865 - accuracy: 0.8451\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.3755 - accuracy: 0.8418\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3829 - accuracy: 0.8496\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 400us/step - loss: 0.3688 - accuracy: 0.8519\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.3658 - accuracy: 0.8541\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 390us/step - loss: 0.3841 - accuracy: 0.8451\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3724 - accuracy: 0.8519\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3744 - accuracy: 0.8474\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3733 - accuracy: 0.8485\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3757 - accuracy: 0.8395\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3800 - accuracy: 0.8440\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3676 - accuracy: 0.8429\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3719 - accuracy: 0.8496\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3779 - accuracy: 0.8316\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3659 - accuracy: 0.8429\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3836 - accuracy: 0.8451\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3566 - accuracy: 0.8530\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3641 - accuracy: 0.8541\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3583 - accuracy: 0.8462\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3686 - accuracy: 0.8530\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3737 - accuracy: 0.8462\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3840 - accuracy: 0.8451\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3945 - accuracy: 0.8373\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.3746 - accuracy: 0.8530\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3731 - accuracy: 0.8418\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3722 - accuracy: 0.8406\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3615 - accuracy: 0.8519\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3816 - accuracy: 0.8395\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3645 - accuracy: 0.8361\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3581 - accuracy: 0.8485\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3826 - accuracy: 0.8451\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3674 - accuracy: 0.8373\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3821 - accuracy: 0.8395\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3666 - accuracy: 0.8507\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3684 - accuracy: 0.8406\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3774 - accuracy: 0.8530\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3856 - accuracy: 0.8395\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3655 - accuracy: 0.8384\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3704 - accuracy: 0.8474\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3690 - accuracy: 0.8507\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3652 - accuracy: 0.8485\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3769 - accuracy: 0.8474\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3746 - accuracy: 0.8440\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3610 - accuracy: 0.8552\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3621 - accuracy: 0.8384\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3704 - accuracy: 0.8485\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3671 - accuracy: 0.8507\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3684 - accuracy: 0.8384\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3696 - accuracy: 0.8496\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3594 - accuracy: 0.8530\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3790 - accuracy: 0.8418\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3688 - accuracy: 0.8418\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3727 - accuracy: 0.8507\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3635 - accuracy: 0.8575\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3724 - accuracy: 0.8418\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3653 - accuracy: 0.8496\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3761 - accuracy: 0.8507\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3684 - accuracy: 0.8418\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3655 - accuracy: 0.8462\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3660 - accuracy: 0.8507\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3917 - accuracy: 0.8451\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3712 - accuracy: 0.8608\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3660 - accuracy: 0.8552\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3762 - accuracy: 0.8507\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3777 - accuracy: 0.8519\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3741 - accuracy: 0.8373\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3667 - accuracy: 0.8530\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.3770 - accuracy: 0.8530\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3622 - accuracy: 0.8451\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3747 - accuracy: 0.8395\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3552 - accuracy: 0.8530\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3707 - accuracy: 0.8462\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3710 - accuracy: 0.8552\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3670 - accuracy: 0.8507\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3734 - accuracy: 0.8474\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.3702 - accuracy: 0.8485\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3717 - accuracy: 0.8474\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3765 - accuracy: 0.8496\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3684 - accuracy: 0.8384\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3663 - accuracy: 0.8462\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3661 - accuracy: 0.8462\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3632 - accuracy: 0.8563\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3841 - accuracy: 0.8440\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3734 - accuracy: 0.8462\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3754 - accuracy: 0.8474\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3801 - accuracy: 0.8440\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3795 - accuracy: 0.8429\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3778 - accuracy: 0.8395\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3656 - accuracy: 0.8373\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3694 - accuracy: 0.8406\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3751 - accuracy: 0.8384\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3609 - accuracy: 0.8384\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3581 - accuracy: 0.8462\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3823 - accuracy: 0.8316\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3735 - accuracy: 0.8552\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3591 - accuracy: 0.8608\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3663 - accuracy: 0.8485\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3649 - accuracy: 0.8586\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3744 - accuracy: 0.8350\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3731 - accuracy: 0.8418\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3740 - accuracy: 0.8552\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3718 - accuracy: 0.8552\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3670 - accuracy: 0.8530\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3707 - accuracy: 0.8418\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.3783 - accuracy: 0.8429\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3594 - accuracy: 0.8474\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3761 - accuracy: 0.8519\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3805 - accuracy: 0.8507\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3786 - accuracy: 0.8373\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3655 - accuracy: 0.8530\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3719 - accuracy: 0.8530\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3735 - accuracy: 0.8462\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3542 - accuracy: 0.8597\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3760 - accuracy: 0.8474\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3503 - accuracy: 0.8530\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.3752 - accuracy: 0.8451\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 403us/step - loss: 0.3751 - accuracy: 0.8530\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.3676 - accuracy: 0.8496\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.3668 - accuracy: 0.8530\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.3694 - accuracy: 0.8440\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3672 - accuracy: 0.8552\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3670 - accuracy: 0.8451\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 397us/step - loss: 0.3672 - accuracy: 0.8496\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 389us/step - loss: 0.3760 - accuracy: 0.8474\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 382us/step - loss: 0.3501 - accuracy: 0.8732\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 387us/step - loss: 0.3868 - accuracy: 0.8373\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3657 - accuracy: 0.8541\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3724 - accuracy: 0.8451\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3762 - accuracy: 0.8350\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3624 - accuracy: 0.8384\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3678 - accuracy: 0.8541\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3755 - accuracy: 0.8451\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3640 - accuracy: 0.8474\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.3680 - accuracy: 0.8575\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3619 - accuracy: 0.8642\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3720 - accuracy: 0.8474\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3715 - accuracy: 0.8474\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3578 - accuracy: 0.8552\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3631 - accuracy: 0.8541\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3543 - accuracy: 0.8575\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.3726 - accuracy: 0.8541\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3671 - accuracy: 0.8507\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3624 - accuracy: 0.8451\n",
      "Epoch 392/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 321us/step - loss: 0.3602 - accuracy: 0.8496\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3622 - accuracy: 0.8519\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3814 - accuracy: 0.8339\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3735 - accuracy: 0.8474\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3660 - accuracy: 0.8519\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3639 - accuracy: 0.8462\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3674 - accuracy: 0.8597\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3571 - accuracy: 0.8496\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3618 - accuracy: 0.8519\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 25, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6924 - accuracy: 0.5449\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.6636 - accuracy: 0.6461\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.6929 - accuracy: 0.6292\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.6632 - accuracy: 0.6292\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.6462 - accuracy: 0.6573\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.6406 - accuracy: 0.6461\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.6504 - accuracy: 0.6517\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.6454 - accuracy: 0.6517\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.6328 - accuracy: 0.6573\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.6227 - accuracy: 0.6573\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.6311 - accuracy: 0.6517\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.6105 - accuracy: 0.6742\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.6070 - accuracy: 0.6629\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.6132 - accuracy: 0.6517\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.5806 - accuracy: 0.6798\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.6182 - accuracy: 0.6685\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.6160 - accuracy: 0.6517\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.5802 - accuracy: 0.6966\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.5981 - accuracy: 0.6742\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.5947 - accuracy: 0.6685\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.5778 - accuracy: 0.7079\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.5757 - accuracy: 0.6910\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.6081 - accuracy: 0.6404\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.5772 - accuracy: 0.6966\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.5982 - accuracy: 0.7135\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.5909 - accuracy: 0.7079\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.5639 - accuracy: 0.6854\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.5574 - accuracy: 0.6854\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.5674 - accuracy: 0.7360\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.5692 - accuracy: 0.6798\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5611 - accuracy: 0.6910\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.5481 - accuracy: 0.7416\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.5855 - accuracy: 0.7191\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.5590 - accuracy: 0.7303\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.5846 - accuracy: 0.6966\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.5345 - accuracy: 0.7809\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.5525 - accuracy: 0.6910\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.5539 - accuracy: 0.7303\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.5121 - accuracy: 0.7584\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.5579 - accuracy: 0.6854\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5168 - accuracy: 0.7528\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.5163 - accuracy: 0.7472\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.5209 - accuracy: 0.7640\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.5122 - accuracy: 0.7584\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.5065 - accuracy: 0.7697\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4965 - accuracy: 0.7753\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.5015 - accuracy: 0.7528\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.5375 - accuracy: 0.7753\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.5082 - accuracy: 0.7640\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.5405 - accuracy: 0.7191\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.6032 - accuracy: 0.6798\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4683 - accuracy: 0.8090\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.5371 - accuracy: 0.7472\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5178 - accuracy: 0.7584\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5551 - accuracy: 0.7191\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.5177 - accuracy: 0.7753\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4909 - accuracy: 0.7865\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.5285 - accuracy: 0.7416\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5548 - accuracy: 0.7247\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.5314 - accuracy: 0.7584\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.5010 - accuracy: 0.8034\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4664 - accuracy: 0.7978\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.5174 - accuracy: 0.7697\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.5227 - accuracy: 0.7809\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.5281 - accuracy: 0.7640\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.5137 - accuracy: 0.7472\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.5018 - accuracy: 0.7697\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4763 - accuracy: 0.7921\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4880 - accuracy: 0.7921\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4585 - accuracy: 0.7809\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.5024 - accuracy: 0.7753\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 659us/step - loss: 0.4533 - accuracy: 0.7921\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.5210 - accuracy: 0.7360\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.5079 - accuracy: 0.7303\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.5015 - accuracy: 0.7978\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4756 - accuracy: 0.7921\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.5099 - accuracy: 0.7697\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.5356 - accuracy: 0.7584\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.4478 - accuracy: 0.7697\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4772 - accuracy: 0.7809\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4950 - accuracy: 0.7697\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.5014 - accuracy: 0.7921\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4991 - accuracy: 0.7640\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 177us/step - loss: 0.4843 - accuracy: 0.7697\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4980 - accuracy: 0.7978\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4627 - accuracy: 0.7978\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4824 - accuracy: 0.7697\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4615 - accuracy: 0.7865\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4880 - accuracy: 0.7753\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4545 - accuracy: 0.8146\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5151 - accuracy: 0.7697\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4479 - accuracy: 0.8034\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 181us/step - loss: 0.4672 - accuracy: 0.8315\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4697 - accuracy: 0.7978\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4711 - accuracy: 0.8090\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4335 - accuracy: 0.8315\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.4964 - accuracy: 0.8090\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4680 - accuracy: 0.7697\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4894 - accuracy: 0.7753\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4976 - accuracy: 0.7865\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4818 - accuracy: 0.7865\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.4787 - accuracy: 0.7809\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4445 - accuracy: 0.8258\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4388 - accuracy: 0.8146\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4830 - accuracy: 0.7640\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4638 - accuracy: 0.8146\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4421 - accuracy: 0.8371\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4550 - accuracy: 0.8146\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4471 - accuracy: 0.8202\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4524 - accuracy: 0.7978\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4608 - accuracy: 0.7978\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4516 - accuracy: 0.7978\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4690 - accuracy: 0.7865\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4871 - accuracy: 0.7809\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4875 - accuracy: 0.7865\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.5029 - accuracy: 0.7865\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4496 - accuracy: 0.8090\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4503 - accuracy: 0.7978\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.4736 - accuracy: 0.7753\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4729 - accuracy: 0.7753\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 172us/step - loss: 0.4717 - accuracy: 0.8090\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.4665 - accuracy: 0.8034\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4756 - accuracy: 0.7865\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4448 - accuracy: 0.8090\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4383 - accuracy: 0.8090\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.4622 - accuracy: 0.8034\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4489 - accuracy: 0.8146\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4483 - accuracy: 0.8315\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 171us/step - loss: 0.4343 - accuracy: 0.8090\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4432 - accuracy: 0.8034\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4592 - accuracy: 0.7978\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4191 - accuracy: 0.8202\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4438 - accuracy: 0.8315\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4729 - accuracy: 0.8034\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.5029 - accuracy: 0.7753\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4838 - accuracy: 0.8202\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4159 - accuracy: 0.8202\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4644 - accuracy: 0.7978\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4740 - accuracy: 0.7753\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4450 - accuracy: 0.7921\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.4656 - accuracy: 0.8090\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4482 - accuracy: 0.7978\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4835 - accuracy: 0.7697\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4170 - accuracy: 0.8427\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4733 - accuracy: 0.8090\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4394 - accuracy: 0.7865\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4341 - accuracy: 0.8258\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.4586 - accuracy: 0.8202\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4367 - accuracy: 0.8090\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4963 - accuracy: 0.7865\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4902 - accuracy: 0.7809\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4376 - accuracy: 0.8596\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4338 - accuracy: 0.8090\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4785 - accuracy: 0.7753\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.4138 - accuracy: 0.8371\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.4387 - accuracy: 0.8202\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 150us/step - loss: 0.4141 - accuracy: 0.8202\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4383 - accuracy: 0.8202\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 163us/step - loss: 0.4697 - accuracy: 0.7865\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.4312 - accuracy: 0.8371\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4930 - accuracy: 0.7978\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4570 - accuracy: 0.7753\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4523 - accuracy: 0.7978\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4666 - accuracy: 0.7753\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4572 - accuracy: 0.8090\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4504 - accuracy: 0.8146\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4391 - accuracy: 0.8202\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4436 - accuracy: 0.8258\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.3867 - accuracy: 0.8483\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4565 - accuracy: 0.7865\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4530 - accuracy: 0.8034\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4829 - accuracy: 0.7978\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4176 - accuracy: 0.8427\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4444 - accuracy: 0.7809\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4592 - accuracy: 0.8090\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4994 - accuracy: 0.7865\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.4218 - accuracy: 0.8315\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.4542 - accuracy: 0.8146\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4090 - accuracy: 0.8202\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 167us/step - loss: 0.4538 - accuracy: 0.8090\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 165us/step - loss: 0.4526 - accuracy: 0.7921\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4601 - accuracy: 0.8146\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4656 - accuracy: 0.7978\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4332 - accuracy: 0.8258\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4281 - accuracy: 0.7809\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4282 - accuracy: 0.8258\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4342 - accuracy: 0.7865\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4303 - accuracy: 0.8258\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4273 - accuracy: 0.8146\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4750 - accuracy: 0.7921\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 182us/step - loss: 0.4292 - accuracy: 0.8146\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7697\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4360 - accuracy: 0.8202\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.3889 - accuracy: 0.8708\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4132 - accuracy: 0.8146\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4474 - accuracy: 0.8034\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4102 - accuracy: 0.8596\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4058 - accuracy: 0.8315\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4215 - accuracy: 0.8371\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4363 - accuracy: 0.8202\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4600 - accuracy: 0.7978\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4386 - accuracy: 0.8146\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.4455 - accuracy: 0.8202\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4002 - accuracy: 0.8652\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 173us/step - loss: 0.4027 - accuracy: 0.8539\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4099 - accuracy: 0.8371\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.4412 - accuracy: 0.8146\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4465 - accuracy: 0.8146\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4415 - accuracy: 0.8371\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4633 - accuracy: 0.7697\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4161 - accuracy: 0.8427\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 179us/step - loss: 0.4333 - accuracy: 0.8258\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4110 - accuracy: 0.8315\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 170us/step - loss: 0.4170 - accuracy: 0.8090\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4100 - accuracy: 0.8708\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4513 - accuracy: 0.8146\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.4646 - accuracy: 0.8034\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4261 - accuracy: 0.8146\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4502 - accuracy: 0.8146\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4093 - accuracy: 0.8427\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4591 - accuracy: 0.8202\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4041 - accuracy: 0.8315\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4243 - accuracy: 0.8371\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4290 - accuracy: 0.8202\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4319 - accuracy: 0.8202\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4502 - accuracy: 0.7865\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4408 - accuracy: 0.8315\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4236 - accuracy: 0.8146\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 168us/step - loss: 0.4618 - accuracy: 0.7978\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4322 - accuracy: 0.8090\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4205 - accuracy: 0.8315\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4355 - accuracy: 0.8090\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4571 - accuracy: 0.7697\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.3846 - accuracy: 0.8652\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4296 - accuracy: 0.8090\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4247 - accuracy: 0.8596\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.3908 - accuracy: 0.8764\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4566 - accuracy: 0.8090\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 166us/step - loss: 0.4592 - accuracy: 0.8090\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4118 - accuracy: 0.8596\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.3897 - accuracy: 0.8315\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4045 - accuracy: 0.8315\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4556 - accuracy: 0.8371\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4558 - accuracy: 0.8090\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4314 - accuracy: 0.8146\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4407 - accuracy: 0.8371\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4038 - accuracy: 0.8315\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4270 - accuracy: 0.8090\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4194 - accuracy: 0.8539\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4548 - accuracy: 0.7921\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4712 - accuracy: 0.7921\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3806 - accuracy: 0.8427\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4415 - accuracy: 0.8427\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4183 - accuracy: 0.8371\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4430 - accuracy: 0.8090\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4263 - accuracy: 0.8258\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4401 - accuracy: 0.7978\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4295 - accuracy: 0.8146\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.3904 - accuracy: 0.8315\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 164us/step - loss: 0.4131 - accuracy: 0.7978\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4429 - accuracy: 0.7978\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4142 - accuracy: 0.8258\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4320 - accuracy: 0.8202\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.4173 - accuracy: 0.8258\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.3991 - accuracy: 0.8371\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4452 - accuracy: 0.8202\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4053 - accuracy: 0.8315\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4468 - accuracy: 0.8090\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4623 - accuracy: 0.8090\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4107 - accuracy: 0.8258\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4462 - accuracy: 0.8146\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.4352 - accuracy: 0.8315\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.4136 - accuracy: 0.8202\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4000 - accuracy: 0.8371\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4086 - accuracy: 0.8371\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4417 - accuracy: 0.8315\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4050 - accuracy: 0.8146\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3900 - accuracy: 0.8596\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.3642 - accuracy: 0.8820\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4428 - accuracy: 0.8258\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4609 - accuracy: 0.8090\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 176us/step - loss: 0.4201 - accuracy: 0.8315\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 178us/step - loss: 0.4223 - accuracy: 0.8315\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4029 - accuracy: 0.8090\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.4230 - accuracy: 0.8371\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4290 - accuracy: 0.7921\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4214 - accuracy: 0.8371\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.3864 - accuracy: 0.8315\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4159 - accuracy: 0.8315\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4442 - accuracy: 0.7865\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4472 - accuracy: 0.8146\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.3742 - accuracy: 0.8652\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4162 - accuracy: 0.8258\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4148 - accuracy: 0.8202\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.3994 - accuracy: 0.8315\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4117 - accuracy: 0.8427\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.4271 - accuracy: 0.8258\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 185us/step - loss: 0.4469 - accuracy: 0.8258\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4035 - accuracy: 0.8371\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4369 - accuracy: 0.8034\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.4483 - accuracy: 0.8202\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4144 - accuracy: 0.8315\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4267 - accuracy: 0.8146\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4409 - accuracy: 0.8090\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 161us/step - loss: 0.4188 - accuracy: 0.8427\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 175us/step - loss: 0.4263 - accuracy: 0.8258\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.3869 - accuracy: 0.8539\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 157us/step - loss: 0.3811 - accuracy: 0.8315\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4095 - accuracy: 0.8652\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4351 - accuracy: 0.7978\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4094 - accuracy: 0.8315\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.3908 - accuracy: 0.8483\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 143us/step - loss: 0.3913 - accuracy: 0.8371\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4293 - accuracy: 0.8371\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4357 - accuracy: 0.8034\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4115 - accuracy: 0.8371\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4322 - accuracy: 0.8258\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4429 - accuracy: 0.8034\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4136 - accuracy: 0.8483\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.4719 - accuracy: 0.7865\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4156 - accuracy: 0.8427\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4143 - accuracy: 0.8427\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.3795 - accuracy: 0.8427\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3912 - accuracy: 0.8427\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 152us/step - loss: 0.4208 - accuracy: 0.8539\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4312 - accuracy: 0.8427\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4233 - accuracy: 0.8202\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4114 - accuracy: 0.8483\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4110 - accuracy: 0.8315\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.4164 - accuracy: 0.8202\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4315 - accuracy: 0.8371\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4655 - accuracy: 0.8090\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4597 - accuracy: 0.8090\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4100 - accuracy: 0.8258\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4118 - accuracy: 0.8315\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3955 - accuracy: 0.8371\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 153us/step - loss: 0.4222 - accuracy: 0.7978\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4492 - accuracy: 0.8090\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.4097 - accuracy: 0.8483\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.3765 - accuracy: 0.8315\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4061 - accuracy: 0.8146\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.3995 - accuracy: 0.8483\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4285 - accuracy: 0.8202\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4292 - accuracy: 0.8202\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4197 - accuracy: 0.8146\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4059 - accuracy: 0.8315\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 156us/step - loss: 0.4281 - accuracy: 0.8427\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 160us/step - loss: 0.4287 - accuracy: 0.8202\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.4414 - accuracy: 0.8034\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4564 - accuracy: 0.7978\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4027 - accuracy: 0.8371\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 162us/step - loss: 0.4410 - accuracy: 0.8146\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4096 - accuracy: 0.8483\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4472 - accuracy: 0.8090\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4010 - accuracy: 0.8315\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.3934 - accuracy: 0.8652\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 155us/step - loss: 0.4426 - accuracy: 0.8258\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4041 - accuracy: 0.8427\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 142us/step - loss: 0.4079 - accuracy: 0.7978\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3966 - accuracy: 0.8371\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.4072 - accuracy: 0.8371\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 141us/step - loss: 0.4392 - accuracy: 0.8315\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 183us/step - loss: 0.4165 - accuracy: 0.8258\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 159us/step - loss: 0.3873 - accuracy: 0.8539\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4219 - accuracy: 0.8315\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4119 - accuracy: 0.8315\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.4154 - accuracy: 0.8258\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4016 - accuracy: 0.8315\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4169 - accuracy: 0.7921\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4039 - accuracy: 0.8596\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4009 - accuracy: 0.8596\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.4012 - accuracy: 0.8202\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.3920 - accuracy: 0.8596\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 146us/step - loss: 0.3783 - accuracy: 0.8258\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.3959 - accuracy: 0.8371\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4317 - accuracy: 0.7978\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4173 - accuracy: 0.8090\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 148us/step - loss: 0.3849 - accuracy: 0.8090\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.3930 - accuracy: 0.8371\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3554 - accuracy: 0.8596\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.3844 - accuracy: 0.8427\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.3879 - accuracy: 0.8539\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 158us/step - loss: 0.3598 - accuracy: 0.8708\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.3687 - accuracy: 0.8258\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4132 - accuracy: 0.8371\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 169us/step - loss: 0.4390 - accuracy: 0.8146\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 150us/step - loss: 0.4124 - accuracy: 0.8371\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4334 - accuracy: 0.7978\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 149us/step - loss: 0.4318 - accuracy: 0.8258\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 144us/step - loss: 0.4181 - accuracy: 0.8371\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 174us/step - loss: 0.4017 - accuracy: 0.8483\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 154us/step - loss: 0.4284 - accuracy: 0.8258\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.4037 - accuracy: 0.8258\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.3865 - accuracy: 0.8483\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4309 - accuracy: 0.8315\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 151us/step - loss: 0.4033 - accuracy: 0.8371\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 147us/step - loss: 0.4446 - accuracy: 0.7753\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 145us/step - loss: 0.3931 - accuracy: 0.8315\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 143us/step - loss: 0.4465 - accuracy: 0.8090\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 140us/step - loss: 0.4044 - accuracy: 0.8258\n",
      "713/713 [==============================] - 0s 611us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4774 - accuracy: 0.7890\n",
      "Epoch 2/400\n",
      "420/891 [=============>................] - ETA: 0s - loss: 0.4740 - accuracy: 0.7857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 141us/step - loss: 0.4683 - accuracy: 0.7924\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4443 - accuracy: 0.8204\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4541 - accuracy: 0.8025\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4457 - accuracy: 0.8047\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4361 - accuracy: 0.8204\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4246 - accuracy: 0.8159\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4321 - accuracy: 0.8238\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4180 - accuracy: 0.8373\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.4409 - accuracy: 0.8193\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4346 - accuracy: 0.8171\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4372 - accuracy: 0.8193\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4343 - accuracy: 0.8193\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4572 - accuracy: 0.7969\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4439 - accuracy: 0.8148\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4362 - accuracy: 0.8182\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4451 - accuracy: 0.8137\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4345 - accuracy: 0.8272\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4272 - accuracy: 0.8227\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 142us/step - loss: 0.4501 - accuracy: 0.8126\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4344 - accuracy: 0.8283\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4475 - accuracy: 0.8114\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4363 - accuracy: 0.8171\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.4328 - accuracy: 0.8283\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4449 - accuracy: 0.8159\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.4423 - accuracy: 0.8148\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4211 - accuracy: 0.8204\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4352 - accuracy: 0.8204\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4404 - accuracy: 0.8126\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4220 - accuracy: 0.8227\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4530 - accuracy: 0.8182\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4449 - accuracy: 0.8182\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4383 - accuracy: 0.8249\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4322 - accuracy: 0.8204\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4356 - accuracy: 0.8272\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4301 - accuracy: 0.8227\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4313 - accuracy: 0.8148\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.4312 - accuracy: 0.8238\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4404 - accuracy: 0.8294\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4027 - accuracy: 0.8395\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4298 - accuracy: 0.8227\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4380 - accuracy: 0.8182\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 142us/step - loss: 0.4200 - accuracy: 0.8406\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.4190 - accuracy: 0.8238\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4212 - accuracy: 0.8249\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.4191 - accuracy: 0.8204\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4356 - accuracy: 0.8182\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4373 - accuracy: 0.8272\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4528 - accuracy: 0.8070\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4368 - accuracy: 0.8137\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4354 - accuracy: 0.8126\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4294 - accuracy: 0.8272\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4380 - accuracy: 0.8114\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4249 - accuracy: 0.8238\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4217 - accuracy: 0.8373\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4294 - accuracy: 0.8215\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4332 - accuracy: 0.8193\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.4282 - accuracy: 0.8137\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4280 - accuracy: 0.8373\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4229 - accuracy: 0.8238\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4330 - accuracy: 0.8159\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4226 - accuracy: 0.8215\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4318 - accuracy: 0.8294\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 148us/step - loss: 0.4384 - accuracy: 0.8159\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4318 - accuracy: 0.8204\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.4322 - accuracy: 0.8193\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4261 - accuracy: 0.8305\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4269 - accuracy: 0.8227\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4132 - accuracy: 0.8260\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4109 - accuracy: 0.8429\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4151 - accuracy: 0.8294\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.4383 - accuracy: 0.8204\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4151 - accuracy: 0.8294\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4296 - accuracy: 0.8328\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4318 - accuracy: 0.8227\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4157 - accuracy: 0.8305\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4250 - accuracy: 0.8283\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4284 - accuracy: 0.8260\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4364 - accuracy: 0.8126\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4413 - accuracy: 0.8272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.4182 - accuracy: 0.8406\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4143 - accuracy: 0.8361\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.4383 - accuracy: 0.8204\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4216 - accuracy: 0.8294\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.4166 - accuracy: 0.8272\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.4218 - accuracy: 0.8215\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4171 - accuracy: 0.8215\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.4274 - accuracy: 0.8215\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.4365 - accuracy: 0.8204\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4123 - accuracy: 0.8361\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4104 - accuracy: 0.8294\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.4255 - accuracy: 0.8193\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4179 - accuracy: 0.8294\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.4155 - accuracy: 0.8182\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4140 - accuracy: 0.8249\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.4241 - accuracy: 0.8238\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.4285 - accuracy: 0.8182\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4190 - accuracy: 0.8373\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.4293 - accuracy: 0.8305\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.4279 - accuracy: 0.8193\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.4275 - accuracy: 0.8238\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4117 - accuracy: 0.8316\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.4139 - accuracy: 0.8350\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.4149 - accuracy: 0.8238\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4223 - accuracy: 0.8294\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4105 - accuracy: 0.8249\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.4198 - accuracy: 0.8316\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4113 - accuracy: 0.8361\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4157 - accuracy: 0.8294\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4380 - accuracy: 0.8193\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4255 - accuracy: 0.8204\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4075 - accuracy: 0.8316\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4208 - accuracy: 0.8227\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.4367 - accuracy: 0.8159\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4079 - accuracy: 0.8328\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4313 - accuracy: 0.8182\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4221 - accuracy: 0.8260\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4095 - accuracy: 0.8294\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4312 - accuracy: 0.8227\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4074 - accuracy: 0.8294\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.4122 - accuracy: 0.8305\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 143us/step - loss: 0.3935 - accuracy: 0.8496\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 147us/step - loss: 0.4310 - accuracy: 0.8159\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 146us/step - loss: 0.4182 - accuracy: 0.8260\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4027 - accuracy: 0.8328\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4336 - accuracy: 0.8215\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4189 - accuracy: 0.8159\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4004 - accuracy: 0.8328\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4062 - accuracy: 0.8361\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 145us/step - loss: 0.4475 - accuracy: 0.8171\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.4073 - accuracy: 0.8305\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 141us/step - loss: 0.4211 - accuracy: 0.8227\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 142us/step - loss: 0.4227 - accuracy: 0.8305\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 144us/step - loss: 0.4227 - accuracy: 0.8260\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4132 - accuracy: 0.8249\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4248 - accuracy: 0.8171\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4124 - accuracy: 0.8294\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4190 - accuracy: 0.8328\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4291 - accuracy: 0.8227\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4038 - accuracy: 0.8316\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4234 - accuracy: 0.8260\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4068 - accuracy: 0.8350\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3997 - accuracy: 0.8429\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 150us/step - loss: 0.4199 - accuracy: 0.8148\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4121 - accuracy: 0.8294\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4188 - accuracy: 0.8227\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4187 - accuracy: 0.8305\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4099 - accuracy: 0.8294\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4168 - accuracy: 0.8283\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3958 - accuracy: 0.8305\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4219 - accuracy: 0.8215\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4117 - accuracy: 0.8260\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4232 - accuracy: 0.8215\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4079 - accuracy: 0.8384\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4327 - accuracy: 0.8249\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4297 - accuracy: 0.8114\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4189 - accuracy: 0.8114\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4013 - accuracy: 0.8384\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3993 - accuracy: 0.8283\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4080 - accuracy: 0.8395\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4163 - accuracy: 0.8294\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4282 - accuracy: 0.8148\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4253 - accuracy: 0.8227\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4103 - accuracy: 0.8204\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4158 - accuracy: 0.8316\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4132 - accuracy: 0.8361\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.3947 - accuracy: 0.8373\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.4164 - accuracy: 0.8227\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.4020 - accuracy: 0.8283\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4076 - accuracy: 0.8294\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 163us/step - loss: 0.4240 - accuracy: 0.8249\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4251 - accuracy: 0.8103\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4061 - accuracy: 0.8283\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4043 - accuracy: 0.8305\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4073 - accuracy: 0.8328\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4168 - accuracy: 0.8406\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3983 - accuracy: 0.8429\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.4230 - accuracy: 0.8238\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4158 - accuracy: 0.8328\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.4141 - accuracy: 0.8238\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.4137 - accuracy: 0.8339\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.3973 - accuracy: 0.8429\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.4123 - accuracy: 0.8238\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.4082 - accuracy: 0.8406\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3987 - accuracy: 0.8474\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3873 - accuracy: 0.8328\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 158us/step - loss: 0.4020 - accuracy: 0.8328\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4142 - accuracy: 0.8249\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4007 - accuracy: 0.8429\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4019 - accuracy: 0.8350\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4093 - accuracy: 0.8384\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3939 - accuracy: 0.8418\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3988 - accuracy: 0.8373\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4147 - accuracy: 0.8328\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4063 - accuracy: 0.8159\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4173 - accuracy: 0.8238\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3954 - accuracy: 0.8406\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4058 - accuracy: 0.8305\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3995 - accuracy: 0.8373\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3926 - accuracy: 0.8406\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4007 - accuracy: 0.8350\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3968 - accuracy: 0.8316\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4189 - accuracy: 0.8238\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4024 - accuracy: 0.8350\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4090 - accuracy: 0.8316\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4034 - accuracy: 0.8350\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.3966 - accuracy: 0.8350\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4108 - accuracy: 0.8283\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 156us/step - loss: 0.4169 - accuracy: 0.8316\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.4005 - accuracy: 0.8406\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4026 - accuracy: 0.8305\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4018 - accuracy: 0.8238\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4051 - accuracy: 0.8429\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.4019 - accuracy: 0.8305\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4126 - accuracy: 0.8350\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 152us/step - loss: 0.3987 - accuracy: 0.8451\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3929 - accuracy: 0.8361\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.4064 - accuracy: 0.8339\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.4160 - accuracy: 0.8238\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4046 - accuracy: 0.8361\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.4041 - accuracy: 0.8328\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3995 - accuracy: 0.8541\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.3932 - accuracy: 0.8339\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4013 - accuracy: 0.8350\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.3972 - accuracy: 0.8316\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 164us/step - loss: 0.4144 - accuracy: 0.8260\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 159us/step - loss: 0.4078 - accuracy: 0.8350\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 157us/step - loss: 0.3882 - accuracy: 0.8474\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 160us/step - loss: 0.3961 - accuracy: 0.8440\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.4080 - accuracy: 0.8294\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.4055 - accuracy: 0.8272\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3916 - accuracy: 0.8451\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4036 - accuracy: 0.8305\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.4018 - accuracy: 0.8328\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4065 - accuracy: 0.8238\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.4128 - accuracy: 0.8193\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 166us/step - loss: 0.3971 - accuracy: 0.8339\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.4249 - accuracy: 0.8193\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4074 - accuracy: 0.8328\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3970 - accuracy: 0.8373\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4064 - accuracy: 0.8328\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 380us/step - loss: 0.4051 - accuracy: 0.8316\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4075 - accuracy: 0.8384\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4107 - accuracy: 0.8328\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4073 - accuracy: 0.8227\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3950 - accuracy: 0.8474\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4041 - accuracy: 0.8316\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3938 - accuracy: 0.8451\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4014 - accuracy: 0.8260\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.3930 - accuracy: 0.8451\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3853 - accuracy: 0.8474\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4154 - accuracy: 0.8249\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.4174 - accuracy: 0.8305\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4210 - accuracy: 0.8238\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.4018 - accuracy: 0.8440\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4051 - accuracy: 0.8294\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.4016 - accuracy: 0.8316\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4103 - accuracy: 0.8294\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4163 - accuracy: 0.8238\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 166us/step - loss: 0.4091 - accuracy: 0.8361\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3864 - accuracy: 0.8429\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3984 - accuracy: 0.8283\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.3792 - accuracy: 0.8474\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.3887 - accuracy: 0.8474\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4034 - accuracy: 0.8305\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.3942 - accuracy: 0.8328\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3926 - accuracy: 0.8462\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4046 - accuracy: 0.8361\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3892 - accuracy: 0.8361\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.3867 - accuracy: 0.8563\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4032 - accuracy: 0.8429\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.3988 - accuracy: 0.8395\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.3863 - accuracy: 0.8451\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4082 - accuracy: 0.8272\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4013 - accuracy: 0.8350\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4020 - accuracy: 0.8339\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4002 - accuracy: 0.8462\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4043 - accuracy: 0.8361\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.3987 - accuracy: 0.8406\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4030 - accuracy: 0.8440\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4047 - accuracy: 0.8339\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3865 - accuracy: 0.8361\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.4108 - accuracy: 0.8283\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4079 - accuracy: 0.8272\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.3919 - accuracy: 0.8451\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.3903 - accuracy: 0.8429\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4071 - accuracy: 0.8305\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 186us/step - loss: 0.4082 - accuracy: 0.8193\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.4029 - accuracy: 0.8305\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.4055 - accuracy: 0.8373\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.4029 - accuracy: 0.8350\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.3962 - accuracy: 0.8350\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.3846 - accuracy: 0.8384\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4129 - accuracy: 0.8328\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.3824 - accuracy: 0.8507\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4028 - accuracy: 0.8316\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3941 - accuracy: 0.8451\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4084 - accuracy: 0.8227\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 188us/step - loss: 0.4032 - accuracy: 0.8283\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 179us/step - loss: 0.3999 - accuracy: 0.8283\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4045 - accuracy: 0.8316\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4016 - accuracy: 0.8305\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 171us/step - loss: 0.3935 - accuracy: 0.8305\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4039 - accuracy: 0.8440\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.3899 - accuracy: 0.8361\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3915 - accuracy: 0.8429\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.3971 - accuracy: 0.8384\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3932 - accuracy: 0.8406\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3942 - accuracy: 0.8418\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3827 - accuracy: 0.8552\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.4148 - accuracy: 0.8227\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.3941 - accuracy: 0.8373\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4001 - accuracy: 0.8373\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.3858 - accuracy: 0.8373\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3982 - accuracy: 0.8361\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3988 - accuracy: 0.8328\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.4053 - accuracy: 0.8272\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4113 - accuracy: 0.8215\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 185us/step - loss: 0.4135 - accuracy: 0.8339\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3805 - accuracy: 0.8339\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3977 - accuracy: 0.8395\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3985 - accuracy: 0.8384\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.3917 - accuracy: 0.8361\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.4063 - accuracy: 0.8283\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 165us/step - loss: 0.3936 - accuracy: 0.8373\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3980 - accuracy: 0.8316\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.3913 - accuracy: 0.8418\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 170us/step - loss: 0.3980 - accuracy: 0.8328\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3820 - accuracy: 0.8418\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.4032 - accuracy: 0.8316\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.3888 - accuracy: 0.8395\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3973 - accuracy: 0.8395\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4021 - accuracy: 0.8418\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4019 - accuracy: 0.8316\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.3911 - accuracy: 0.8361\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3940 - accuracy: 0.8316\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 178us/step - loss: 0.3961 - accuracy: 0.8406\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 187us/step - loss: 0.4011 - accuracy: 0.8316\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.3926 - accuracy: 0.8440\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3863 - accuracy: 0.8474\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 181us/step - loss: 0.3855 - accuracy: 0.8474\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.3977 - accuracy: 0.8395\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 172us/step - loss: 0.4066 - accuracy: 0.8350\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4008 - accuracy: 0.8339\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3922 - accuracy: 0.8474\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3964 - accuracy: 0.8294\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 180us/step - loss: 0.4005 - accuracy: 0.8395\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3926 - accuracy: 0.8294\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 189us/step - loss: 0.3910 - accuracy: 0.8328\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4079 - accuracy: 0.8350\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.3859 - accuracy: 0.8451\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3994 - accuracy: 0.8339\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3880 - accuracy: 0.8418\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 184us/step - loss: 0.3981 - accuracy: 0.8384\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4075 - accuracy: 0.8350\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3959 - accuracy: 0.8373\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.3993 - accuracy: 0.8328\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4128 - accuracy: 0.8227\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3853 - accuracy: 0.8530\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4052 - accuracy: 0.8238\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3840 - accuracy: 0.8440\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3814 - accuracy: 0.8563\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4033 - accuracy: 0.8316\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3921 - accuracy: 0.8350\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4055 - accuracy: 0.8305\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3912 - accuracy: 0.8395\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3863 - accuracy: 0.8474\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3980 - accuracy: 0.8350\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.3919 - accuracy: 0.8361\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 175us/step - loss: 0.4061 - accuracy: 0.8339\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3978 - accuracy: 0.8283\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4031 - accuracy: 0.8283\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3994 - accuracy: 0.8373\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3917 - accuracy: 0.8339\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4140 - accuracy: 0.8227\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3918 - accuracy: 0.8361\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 176us/step - loss: 0.4005 - accuracy: 0.8249\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 174us/step - loss: 0.3898 - accuracy: 0.8361\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3742 - accuracy: 0.8451\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 177us/step - loss: 0.3997 - accuracy: 0.8395\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.3859 - accuracy: 0.8373\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3941 - accuracy: 0.8429\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.3800 - accuracy: 0.8406\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 183us/step - loss: 0.3850 - accuracy: 0.8339\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 182us/step - loss: 0.4068 - accuracy: 0.8305\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3945 - accuracy: 0.8373\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 169us/step - loss: 0.3948 - accuracy: 0.8361\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 167us/step - loss: 0.3809 - accuracy: 0.8429\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3920 - accuracy: 0.8429\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.3945 - accuracy: 0.8384\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3958 - accuracy: 0.8373\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3895 - accuracy: 0.8406\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 158us/step - loss: 0.3882 - accuracy: 0.8373\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3876 - accuracy: 0.8418\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 162us/step - loss: 0.3846 - accuracy: 0.8395\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3826 - accuracy: 0.8462\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 168us/step - loss: 0.4003 - accuracy: 0.8350\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3782 - accuracy: 0.8406\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 161us/step - loss: 0.3890 - accuracy: 0.8395\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 154us/step - loss: 0.4197 - accuracy: 0.8328\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 25, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 4s 22ms/step - loss: 0.8011 - accuracy: 0.3427\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.7267 - accuracy: 0.4607\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.6962 - accuracy: 0.5506\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.6912 - accuracy: 0.5393\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6730 - accuracy: 0.5955\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.6673 - accuracy: 0.6292\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.6615 - accuracy: 0.6067\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.6330 - accuracy: 0.6517\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.6411 - accuracy: 0.6798\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6519 - accuracy: 0.6404\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.6284 - accuracy: 0.6629\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.6264 - accuracy: 0.6573\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.6515 - accuracy: 0.6517\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.6327 - accuracy: 0.6517\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6311 - accuracy: 0.6798\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.6137 - accuracy: 0.6742\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.6328 - accuracy: 0.6517\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.6638 - accuracy: 0.6517\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.6367 - accuracy: 0.6461\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.6318 - accuracy: 0.6517\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.6368 - accuracy: 0.6461\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.6427 - accuracy: 0.6573\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.6586 - accuracy: 0.6180\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.6408 - accuracy: 0.6573\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.6321 - accuracy: 0.6742\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.6184 - accuracy: 0.6742\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.6118 - accuracy: 0.6854\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.6334 - accuracy: 0.6348\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.6381 - accuracy: 0.6573\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.6183 - accuracy: 0.6517\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.6051 - accuracy: 0.6685\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5929 - accuracy: 0.6798\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.6265 - accuracy: 0.6573\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.6104 - accuracy: 0.6966\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.6067 - accuracy: 0.6966\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.6166 - accuracy: 0.6517\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5920 - accuracy: 0.6854\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.6417 - accuracy: 0.6629\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5897 - accuracy: 0.6629\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5839 - accuracy: 0.6854\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.6132 - accuracy: 0.6573\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.6062 - accuracy: 0.6629\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.6011 - accuracy: 0.6629\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.5833 - accuracy: 0.6966\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5826 - accuracy: 0.6854\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.5951 - accuracy: 0.7079\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.6126 - accuracy: 0.7022\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.5828 - accuracy: 0.6798\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.5767 - accuracy: 0.6910\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5735 - accuracy: 0.7135\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.5716 - accuracy: 0.6966\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.6028 - accuracy: 0.6629\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.5987 - accuracy: 0.6573\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5573 - accuracy: 0.7191\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.6017 - accuracy: 0.6629\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 258us/step - loss: 0.5597 - accuracy: 0.6910\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.5279 - accuracy: 0.7584\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.5559 - accuracy: 0.7303\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.5609 - accuracy: 0.7416\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.5714 - accuracy: 0.7135\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.5493 - accuracy: 0.7416\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.5351 - accuracy: 0.7022\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5990 - accuracy: 0.6854\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.5938 - accuracy: 0.6966\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.5458 - accuracy: 0.7360\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.5435 - accuracy: 0.7191\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5397 - accuracy: 0.7584\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.5261 - accuracy: 0.7247\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.5403 - accuracy: 0.7416\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.5219 - accuracy: 0.7528\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.5735 - accuracy: 0.6966\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.5449 - accuracy: 0.7303\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.5390 - accuracy: 0.7416\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.5588 - accuracy: 0.7416\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.5224 - accuracy: 0.7697\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.5292 - accuracy: 0.7416\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5006 - accuracy: 0.7697\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.5442 - accuracy: 0.7135\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.5398 - accuracy: 0.7528\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5476 - accuracy: 0.7640\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.5379 - accuracy: 0.7416\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.5280 - accuracy: 0.7303\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5376 - accuracy: 0.7303\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4971 - accuracy: 0.7472\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.5390 - accuracy: 0.7472\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5114 - accuracy: 0.7584\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.5353 - accuracy: 0.7360\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5327 - accuracy: 0.7191\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.5133 - accuracy: 0.7753\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.5529 - accuracy: 0.6629\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.5459 - accuracy: 0.6910\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.5576 - accuracy: 0.7303\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5240 - accuracy: 0.7472\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4645 - accuracy: 0.8034\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5253 - accuracy: 0.8034\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.5187 - accuracy: 0.7697\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.5369 - accuracy: 0.7640\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4755 - accuracy: 0.8034\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.5415 - accuracy: 0.7697\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5079 - accuracy: 0.7584\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.5067 - accuracy: 0.7584\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5068 - accuracy: 0.7921\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4803 - accuracy: 0.7640\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5429 - accuracy: 0.7303\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4747 - accuracy: 0.7865\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5098 - accuracy: 0.7921\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.5265 - accuracy: 0.7247\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5058 - accuracy: 0.7809\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4941 - accuracy: 0.7753\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4691 - accuracy: 0.7921\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4790 - accuracy: 0.7809\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4992 - accuracy: 0.7697\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.5132 - accuracy: 0.7528\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.5124 - accuracy: 0.7697\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4871 - accuracy: 0.7978\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4845 - accuracy: 0.7640\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4967 - accuracy: 0.7753\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5236 - accuracy: 0.7472\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4661 - accuracy: 0.8258\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4747 - accuracy: 0.7921\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4899 - accuracy: 0.7584\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4887 - accuracy: 0.7865\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4686 - accuracy: 0.7865\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4432 - accuracy: 0.8146\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5117 - accuracy: 0.7303\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.5184 - accuracy: 0.7697\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5003 - accuracy: 0.7978\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.5351 - accuracy: 0.7697\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.5247 - accuracy: 0.7191\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.5563 - accuracy: 0.7191\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5232 - accuracy: 0.7528\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4462 - accuracy: 0.8090\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4941 - accuracy: 0.7809\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4956 - accuracy: 0.7753\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4455 - accuracy: 0.7753\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4398 - accuracy: 0.8146\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.5085 - accuracy: 0.7697\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.5186 - accuracy: 0.7809\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4760 - accuracy: 0.7697\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4448 - accuracy: 0.7865\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4876 - accuracy: 0.7809\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4704 - accuracy: 0.7865\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4747 - accuracy: 0.7809\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4983 - accuracy: 0.7697\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.5163 - accuracy: 0.7584\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4638 - accuracy: 0.7753\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.5078 - accuracy: 0.7753\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.5206 - accuracy: 0.7472\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5174 - accuracy: 0.7640\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4322 - accuracy: 0.8258\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4417 - accuracy: 0.8090\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4611 - accuracy: 0.7753\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4611 - accuracy: 0.7697\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4670 - accuracy: 0.7865\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4599 - accuracy: 0.8146\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.5018 - accuracy: 0.7528\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 231us/step - loss: 0.4918 - accuracy: 0.7809\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4625 - accuracy: 0.8202\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4884 - accuracy: 0.7753\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4839 - accuracy: 0.7921\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4730 - accuracy: 0.7865\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4768 - accuracy: 0.7640\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4769 - accuracy: 0.8034\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4622 - accuracy: 0.8034\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4432 - accuracy: 0.8034\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4657 - accuracy: 0.7865\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4567 - accuracy: 0.7753\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4225 - accuracy: 0.8258\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4557 - accuracy: 0.7528\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4850 - accuracy: 0.7809\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4689 - accuracy: 0.7865\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4290 - accuracy: 0.7978\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 184us/step - loss: 0.5102 - accuracy: 0.7865\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4718 - accuracy: 0.7921\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4623 - accuracy: 0.7865\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4974 - accuracy: 0.7809\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4588 - accuracy: 0.8034\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.5297 - accuracy: 0.7528\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5598 - accuracy: 0.7472\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4850 - accuracy: 0.7865\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4624 - accuracy: 0.7978\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4392 - accuracy: 0.7978\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4490 - accuracy: 0.8090\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4705 - accuracy: 0.8258\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4446 - accuracy: 0.8202\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4604 - accuracy: 0.8090\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4743 - accuracy: 0.7753\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4948 - accuracy: 0.7640\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4381 - accuracy: 0.8427\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4602 - accuracy: 0.8090\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4661 - accuracy: 0.7865\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4526 - accuracy: 0.7809\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4852 - accuracy: 0.7697\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4921 - accuracy: 0.7978\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4776 - accuracy: 0.7978\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4454 - accuracy: 0.8315\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4366 - accuracy: 0.7921\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.5061 - accuracy: 0.7809\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4616 - accuracy: 0.8090\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4495 - accuracy: 0.7809\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4672 - accuracy: 0.7584\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4616 - accuracy: 0.7753\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4726 - accuracy: 0.7865\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4522 - accuracy: 0.7809\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4507 - accuracy: 0.8090\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4404 - accuracy: 0.7978\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4244 - accuracy: 0.8090\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4056 - accuracy: 0.8427\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 188us/step - loss: 0.4445 - accuracy: 0.8090\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4680 - accuracy: 0.8034\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4259 - accuracy: 0.8202\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4766 - accuracy: 0.8034\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4626 - accuracy: 0.8202\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4651 - accuracy: 0.7921\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4670 - accuracy: 0.7978\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4460 - accuracy: 0.7921\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4473 - accuracy: 0.8034\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4505 - accuracy: 0.8034\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4116 - accuracy: 0.8202\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4592 - accuracy: 0.8258\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4338 - accuracy: 0.8202\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4304 - accuracy: 0.8258\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4563 - accuracy: 0.8146\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4336 - accuracy: 0.8090\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4070 - accuracy: 0.8258\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4680 - accuracy: 0.7753\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4040 - accuracy: 0.8371\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3994 - accuracy: 0.8427\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4291 - accuracy: 0.8315\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4444 - accuracy: 0.8090\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4686 - accuracy: 0.7809\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.5065 - accuracy: 0.7753\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4727 - accuracy: 0.8258\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4705 - accuracy: 0.7921\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4889 - accuracy: 0.7528\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4565 - accuracy: 0.8090\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4268 - accuracy: 0.8202\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4829 - accuracy: 0.7809\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4300 - accuracy: 0.8258\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4565 - accuracy: 0.8090\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4514 - accuracy: 0.7697\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4722 - accuracy: 0.7921\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 186us/step - loss: 0.4386 - accuracy: 0.8034\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.5086 - accuracy: 0.8090\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 189us/step - loss: 0.4505 - accuracy: 0.8034\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4215 - accuracy: 0.8427\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4618 - accuracy: 0.7809\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4590 - accuracy: 0.7753\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4509 - accuracy: 0.7865\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4396 - accuracy: 0.8202\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4245 - accuracy: 0.8315\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4815 - accuracy: 0.7865\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4517 - accuracy: 0.8090\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4511 - accuracy: 0.8090\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4435 - accuracy: 0.8258\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4299 - accuracy: 0.8146\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4283 - accuracy: 0.8090\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.5402 - accuracy: 0.7753\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4637 - accuracy: 0.7640\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4712 - accuracy: 0.7865\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4384 - accuracy: 0.7978\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4218 - accuracy: 0.8427\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4206 - accuracy: 0.8202\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4216 - accuracy: 0.8427\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 187us/step - loss: 0.4726 - accuracy: 0.7809\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4356 - accuracy: 0.7978\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4500 - accuracy: 0.8146\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4532 - accuracy: 0.8034\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 191us/step - loss: 0.4679 - accuracy: 0.7978\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4672 - accuracy: 0.7809\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 190us/step - loss: 0.4102 - accuracy: 0.8258\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4698 - accuracy: 0.7865\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5046 - accuracy: 0.7472\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.4165 - accuracy: 0.8258\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4026 - accuracy: 0.8258\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4877 - accuracy: 0.7584\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4726 - accuracy: 0.7697\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4816 - accuracy: 0.7921\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4575 - accuracy: 0.7921\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4699 - accuracy: 0.7865\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.5007 - accuracy: 0.7809\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4718 - accuracy: 0.8202\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4606 - accuracy: 0.8258\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4637 - accuracy: 0.7978\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4307 - accuracy: 0.8146\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4360 - accuracy: 0.7978\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4641 - accuracy: 0.7921\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4532 - accuracy: 0.7809\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4042 - accuracy: 0.8427\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4643 - accuracy: 0.7528\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4109 - accuracy: 0.8427\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4251 - accuracy: 0.7921\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4355 - accuracy: 0.7978\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4605 - accuracy: 0.8315\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4533 - accuracy: 0.7921\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4452 - accuracy: 0.8258\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4399 - accuracy: 0.7978\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4628 - accuracy: 0.7978\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4632 - accuracy: 0.7865\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4409 - accuracy: 0.8090\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4433 - accuracy: 0.8146\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4178 - accuracy: 0.8371\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.4511 - accuracy: 0.8146\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4075 - accuracy: 0.8315\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 198us/step - loss: 0.4121 - accuracy: 0.8371\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4462 - accuracy: 0.7809\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4607 - accuracy: 0.8146\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4685 - accuracy: 0.7865\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4619 - accuracy: 0.7978\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4555 - accuracy: 0.7978\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4439 - accuracy: 0.7978\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4165 - accuracy: 0.8258\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 204us/step - loss: 0.4167 - accuracy: 0.8202\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4141 - accuracy: 0.8258\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4943 - accuracy: 0.7753\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4444 - accuracy: 0.8202\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4282 - accuracy: 0.8371\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4479 - accuracy: 0.8034\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4295 - accuracy: 0.8202\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4442 - accuracy: 0.8034\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4536 - accuracy: 0.8146\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4711 - accuracy: 0.7978\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4362 - accuracy: 0.8090\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4100 - accuracy: 0.8371\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4364 - accuracy: 0.8258\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4559 - accuracy: 0.7978\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 356us/step - loss: 0.4339 - accuracy: 0.8202\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4187 - accuracy: 0.8202\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4283 - accuracy: 0.8258\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4196 - accuracy: 0.8371\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4574 - accuracy: 0.8202\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4205 - accuracy: 0.8202\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4403 - accuracy: 0.7921\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4416 - accuracy: 0.8090\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4401 - accuracy: 0.8146\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4082 - accuracy: 0.8090\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4070 - accuracy: 0.8146\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4535 - accuracy: 0.7921\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4409 - accuracy: 0.8034\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4241 - accuracy: 0.8427\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4245 - accuracy: 0.8146\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3998 - accuracy: 0.8315\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.4547 - accuracy: 0.7921\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4111 - accuracy: 0.8315\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4090 - accuracy: 0.8483\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4290 - accuracy: 0.8146\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4993 - accuracy: 0.7753\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 204us/step - loss: 0.4073 - accuracy: 0.8202\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4681 - accuracy: 0.7753\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4214 - accuracy: 0.8258\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4151 - accuracy: 0.8202\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4581 - accuracy: 0.8034\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4269 - accuracy: 0.8090\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4534 - accuracy: 0.8202\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4302 - accuracy: 0.8146\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4509 - accuracy: 0.8034\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4365 - accuracy: 0.7921\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4286 - accuracy: 0.7978\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4717 - accuracy: 0.7865\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4093 - accuracy: 0.8596\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4152 - accuracy: 0.8315\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4395 - accuracy: 0.8258\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4027 - accuracy: 0.8090\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 202us/step - loss: 0.4263 - accuracy: 0.8202\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4416 - accuracy: 0.8146\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4213 - accuracy: 0.8371\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4087 - accuracy: 0.8146\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.3809 - accuracy: 0.8652\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4365 - accuracy: 0.7753\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3981 - accuracy: 0.8315\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4263 - accuracy: 0.8258\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 201us/step - loss: 0.4188 - accuracy: 0.8258\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4612 - accuracy: 0.7865\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4604 - accuracy: 0.8090\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4471 - accuracy: 0.8146\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.3977 - accuracy: 0.8539\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4244 - accuracy: 0.8371\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4548 - accuracy: 0.7978\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 200us/step - loss: 0.4437 - accuracy: 0.8427\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4380 - accuracy: 0.8427\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 205us/step - loss: 0.4189 - accuracy: 0.8146\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4070 - accuracy: 0.8371\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4690 - accuracy: 0.7921\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4435 - accuracy: 0.7978\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4498 - accuracy: 0.7865\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4413 - accuracy: 0.8090\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 199us/step - loss: 0.4485 - accuracy: 0.7697\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4214 - accuracy: 0.8146\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 203us/step - loss: 0.4691 - accuracy: 0.8034\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3975 - accuracy: 0.8090\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.3849 - accuracy: 0.8427\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 196us/step - loss: 0.3945 - accuracy: 0.8258\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4025 - accuracy: 0.8483\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 193us/step - loss: 0.4455 - accuracy: 0.8146\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 192us/step - loss: 0.4579 - accuracy: 0.8146\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4326 - accuracy: 0.8202\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 197us/step - loss: 0.4108 - accuracy: 0.8427\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4552 - accuracy: 0.8202\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 195us/step - loss: 0.4724 - accuracy: 0.8146\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 194us/step - loss: 0.4423 - accuracy: 0.8146\n",
      "713/713 [==============================] - 1s 825us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4893 - accuracy: 0.7856\n",
      "Epoch 2/400\n",
      " 30/891 [>.............................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 205us/step - loss: 0.4849 - accuracy: 0.7924\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4696 - accuracy: 0.8070\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4877 - accuracy: 0.7980\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4561 - accuracy: 0.7946\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4720 - accuracy: 0.7957\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4622 - accuracy: 0.8182\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4707 - accuracy: 0.8036\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4803 - accuracy: 0.7957\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4539 - accuracy: 0.8047\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4639 - accuracy: 0.8081\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4616 - accuracy: 0.8047\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4676 - accuracy: 0.8013\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4491 - accuracy: 0.8070\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4563 - accuracy: 0.8114\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4384 - accuracy: 0.8283\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4653 - accuracy: 0.8070\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4612 - accuracy: 0.8114\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4600 - accuracy: 0.8036\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4492 - accuracy: 0.8193\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4529 - accuracy: 0.8159\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4532 - accuracy: 0.8047\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4478 - accuracy: 0.8148\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 191us/step - loss: 0.4662 - accuracy: 0.7980\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4501 - accuracy: 0.8013\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4537 - accuracy: 0.8058\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4494 - accuracy: 0.8249\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4328 - accuracy: 0.8182\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4543 - accuracy: 0.8047\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4456 - accuracy: 0.8025\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4509 - accuracy: 0.8137\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4384 - accuracy: 0.8204\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4497 - accuracy: 0.8182\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4590 - accuracy: 0.8092\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4537 - accuracy: 0.8126\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4457 - accuracy: 0.8126\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4506 - accuracy: 0.8070\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4677 - accuracy: 0.7957\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4484 - accuracy: 0.8114\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4570 - accuracy: 0.8171\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4459 - accuracy: 0.8092\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4547 - accuracy: 0.8114\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4462 - accuracy: 0.8103\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4538 - accuracy: 0.8081\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4602 - accuracy: 0.8159\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4556 - accuracy: 0.8103\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4547 - accuracy: 0.8182\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4322 - accuracy: 0.8204\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4654 - accuracy: 0.8036\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4524 - accuracy: 0.8159\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4498 - accuracy: 0.8103\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4473 - accuracy: 0.8249\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4434 - accuracy: 0.8070\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 260us/step - loss: 0.4489 - accuracy: 0.8182\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4554 - accuracy: 0.8137\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4521 - accuracy: 0.8036\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4384 - accuracy: 0.8114\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4483 - accuracy: 0.8193\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 192us/step - loss: 0.4577 - accuracy: 0.8092\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4406 - accuracy: 0.8092\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4420 - accuracy: 0.8260\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4604 - accuracy: 0.8137\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4341 - accuracy: 0.8294\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4534 - accuracy: 0.8070\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4546 - accuracy: 0.8137\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4625 - accuracy: 0.8148\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4442 - accuracy: 0.8092\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4404 - accuracy: 0.8260\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4496 - accuracy: 0.8103\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4378 - accuracy: 0.8126\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4553 - accuracy: 0.8058\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4407 - accuracy: 0.8249\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4468 - accuracy: 0.8193\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4427 - accuracy: 0.8171\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4356 - accuracy: 0.8238\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4334 - accuracy: 0.8204\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4345 - accuracy: 0.8272\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4471 - accuracy: 0.8171\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4484 - accuracy: 0.8249\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.4193 - accuracy: 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4336 - accuracy: 0.8215\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4441 - accuracy: 0.8171\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.4445 - accuracy: 0.8159\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.4475 - accuracy: 0.8171\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4469 - accuracy: 0.8227\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4333 - accuracy: 0.8260\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4473 - accuracy: 0.8249\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4310 - accuracy: 0.8182\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4447 - accuracy: 0.8238\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4507 - accuracy: 0.8238\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4672 - accuracy: 0.8036\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4489 - accuracy: 0.8182\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4513 - accuracy: 0.8182\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4144 - accuracy: 0.8373\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4407 - accuracy: 0.8238\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4506 - accuracy: 0.8081\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4427 - accuracy: 0.8114\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4316 - accuracy: 0.8305\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4299 - accuracy: 0.8283\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4371 - accuracy: 0.8204\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4317 - accuracy: 0.8215\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4336 - accuracy: 0.8283\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4477 - accuracy: 0.8249\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4225 - accuracy: 0.8328\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4402 - accuracy: 0.8103\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4238 - accuracy: 0.8193\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4260 - accuracy: 0.8215\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4318 - accuracy: 0.8249\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4347 - accuracy: 0.8249\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4097 - accuracy: 0.8406\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4503 - accuracy: 0.8159\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.4260 - accuracy: 0.8272\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4309 - accuracy: 0.8215\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4345 - accuracy: 0.8204\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4504 - accuracy: 0.8103\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4419 - accuracy: 0.8171\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4297 - accuracy: 0.8193\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4466 - accuracy: 0.8092\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4266 - accuracy: 0.8305\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4379 - accuracy: 0.8227\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4423 - accuracy: 0.8159\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4151 - accuracy: 0.8316\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4308 - accuracy: 0.8294\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4447 - accuracy: 0.8238\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4386 - accuracy: 0.8171\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4250 - accuracy: 0.8272\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4264 - accuracy: 0.8260\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4267 - accuracy: 0.8395\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4260 - accuracy: 0.8272\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4325 - accuracy: 0.8148\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4427 - accuracy: 0.8137\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4353 - accuracy: 0.8283\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4237 - accuracy: 0.8283\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4270 - accuracy: 0.8272\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4556 - accuracy: 0.8081\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4264 - accuracy: 0.8305\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4357 - accuracy: 0.8238\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4496 - accuracy: 0.8092\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4173 - accuracy: 0.8328\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4092 - accuracy: 0.8316\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4328 - accuracy: 0.8114\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4345 - accuracy: 0.8081\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4194 - accuracy: 0.8395\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 193us/step - loss: 0.4149 - accuracy: 0.8361\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.4264 - accuracy: 0.8328\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4300 - accuracy: 0.8148\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4090 - accuracy: 0.8406\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.4508 - accuracy: 0.8114\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4563 - accuracy: 0.7890\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4382 - accuracy: 0.8081\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4142 - accuracy: 0.8339\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4298 - accuracy: 0.8339\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4062 - accuracy: 0.8384\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4262 - accuracy: 0.8238\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4124 - accuracy: 0.8272\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4289 - accuracy: 0.8249\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4145 - accuracy: 0.8440\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4340 - accuracy: 0.8316\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4153 - accuracy: 0.8395\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4304 - accuracy: 0.8171\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4143 - accuracy: 0.8249\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4192 - accuracy: 0.8260\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4167 - accuracy: 0.8361\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4145 - accuracy: 0.8215\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4216 - accuracy: 0.8294\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4329 - accuracy: 0.8238\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4225 - accuracy: 0.8272\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4360 - accuracy: 0.8182\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4223 - accuracy: 0.8193\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4175 - accuracy: 0.8249\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4272 - accuracy: 0.8305\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4204 - accuracy: 0.8260\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4171 - accuracy: 0.8294\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4177 - accuracy: 0.8227\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4343 - accuracy: 0.8272\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4265 - accuracy: 0.8148\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4240 - accuracy: 0.8260\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4252 - accuracy: 0.8215\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4498 - accuracy: 0.8092\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4310 - accuracy: 0.8249\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4309 - accuracy: 0.8126\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4275 - accuracy: 0.8294\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4145 - accuracy: 0.8182\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4239 - accuracy: 0.8283\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4168 - accuracy: 0.8238\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4375 - accuracy: 0.8272\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4250 - accuracy: 0.8215\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4191 - accuracy: 0.8339\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4093 - accuracy: 0.8305\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4226 - accuracy: 0.8249\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4192 - accuracy: 0.8260\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4408 - accuracy: 0.8238\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4193 - accuracy: 0.8305\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4034 - accuracy: 0.8474\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4283 - accuracy: 0.8283\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4233 - accuracy: 0.8283\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4168 - accuracy: 0.8294\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4155 - accuracy: 0.8238\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4049 - accuracy: 0.8294\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4197 - accuracy: 0.8283\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4255 - accuracy: 0.8384\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4268 - accuracy: 0.8238\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4278 - accuracy: 0.8227\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4073 - accuracy: 0.8361\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4302 - accuracy: 0.8272\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4051 - accuracy: 0.8429\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4102 - accuracy: 0.8305\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4022 - accuracy: 0.8395\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4164 - accuracy: 0.8316\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4202 - accuracy: 0.8159\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4186 - accuracy: 0.8272\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4175 - accuracy: 0.8316\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4386 - accuracy: 0.8148\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4347 - accuracy: 0.8182\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4071 - accuracy: 0.8294\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4324 - accuracy: 0.8182\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4381 - accuracy: 0.8215\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4301 - accuracy: 0.8182\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4259 - accuracy: 0.8260\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4323 - accuracy: 0.8227\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4201 - accuracy: 0.8272\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4160 - accuracy: 0.8294\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4052 - accuracy: 0.8339\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 194us/step - loss: 0.4081 - accuracy: 0.8406\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4268 - accuracy: 0.8249\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4364 - accuracy: 0.8126\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4147 - accuracy: 0.8283\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4227 - accuracy: 0.8361\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4167 - accuracy: 0.8305\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4162 - accuracy: 0.8384\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3993 - accuracy: 0.8395\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3937 - accuracy: 0.8350\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4024 - accuracy: 0.8350\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4093 - accuracy: 0.8204\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4337 - accuracy: 0.8137\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4088 - accuracy: 0.8339\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 207us/step - loss: 0.4094 - accuracy: 0.8440\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4072 - accuracy: 0.8328\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4206 - accuracy: 0.8260\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4203 - accuracy: 0.8215\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3985 - accuracy: 0.8496\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4181 - accuracy: 0.8272\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4152 - accuracy: 0.8350\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4051 - accuracy: 0.8406\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4135 - accuracy: 0.8361\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4162 - accuracy: 0.8137\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4177 - accuracy: 0.8339\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4028 - accuracy: 0.8316\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4084 - accuracy: 0.8294\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4104 - accuracy: 0.8272\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4119 - accuracy: 0.8373\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4090 - accuracy: 0.8373\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.3970 - accuracy: 0.8328\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4237 - accuracy: 0.8283\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4189 - accuracy: 0.8294\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4185 - accuracy: 0.8148\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4050 - accuracy: 0.8384\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4129 - accuracy: 0.8249\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4253 - accuracy: 0.8238\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4117 - accuracy: 0.8316\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3992 - accuracy: 0.8474\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4334 - accuracy: 0.8294\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4294 - accuracy: 0.8193\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4029 - accuracy: 0.8339\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.3928 - accuracy: 0.8384\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4197 - accuracy: 0.8283\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4060 - accuracy: 0.8361\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4045 - accuracy: 0.8272\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4157 - accuracy: 0.8238\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4116 - accuracy: 0.8272\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4283 - accuracy: 0.8227\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4066 - accuracy: 0.8429\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4144 - accuracy: 0.8395\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4084 - accuracy: 0.8294\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4207 - accuracy: 0.8350\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.3929 - accuracy: 0.8451\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4214 - accuracy: 0.8294\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4201 - accuracy: 0.8249\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4169 - accuracy: 0.8305\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4180 - accuracy: 0.8316\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4269 - accuracy: 0.8137\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4054 - accuracy: 0.8339\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4110 - accuracy: 0.8305\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4106 - accuracy: 0.8373\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4136 - accuracy: 0.8316\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.3875 - accuracy: 0.8339\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4317 - accuracy: 0.8227\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4052 - accuracy: 0.8361\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4154 - accuracy: 0.8373\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4191 - accuracy: 0.8215\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4047 - accuracy: 0.8283\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4205 - accuracy: 0.8328\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3969 - accuracy: 0.8373\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4191 - accuracy: 0.8406\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4125 - accuracy: 0.8238\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4026 - accuracy: 0.8328\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 195us/step - loss: 0.4002 - accuracy: 0.8272\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4080 - accuracy: 0.8316\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4201 - accuracy: 0.8373\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4069 - accuracy: 0.8350\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4134 - accuracy: 0.8328\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3936 - accuracy: 0.8361\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4173 - accuracy: 0.8171\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4028 - accuracy: 0.8215\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4054 - accuracy: 0.8283\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4112 - accuracy: 0.8361\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4176 - accuracy: 0.8193\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.4219 - accuracy: 0.8114\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 196us/step - loss: 0.4035 - accuracy: 0.8373\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4107 - accuracy: 0.8361\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4287 - accuracy: 0.8137\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 205us/step - loss: 0.4277 - accuracy: 0.8182\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4266 - accuracy: 0.8204\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4064 - accuracy: 0.8350\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4130 - accuracy: 0.8294\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4017 - accuracy: 0.8350\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3980 - accuracy: 0.8418\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4218 - accuracy: 0.8283\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4071 - accuracy: 0.8260\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 197us/step - loss: 0.4065 - accuracy: 0.8339\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4106 - accuracy: 0.8272\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4155 - accuracy: 0.8328\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4001 - accuracy: 0.8384\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4218 - accuracy: 0.8249\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3969 - accuracy: 0.8406\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4107 - accuracy: 0.8305\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.3962 - accuracy: 0.8339\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4116 - accuracy: 0.8272\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3997 - accuracy: 0.8418\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3975 - accuracy: 0.8373\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4070 - accuracy: 0.8272\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4139 - accuracy: 0.8316\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4186 - accuracy: 0.8238\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4150 - accuracy: 0.8339\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 263us/step - loss: 0.4047 - accuracy: 0.8272\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4005 - accuracy: 0.8451\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3892 - accuracy: 0.8418\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3767 - accuracy: 0.8485\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4007 - accuracy: 0.8260\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4191 - accuracy: 0.8227\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4172 - accuracy: 0.8283\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3966 - accuracy: 0.8249\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4130 - accuracy: 0.8373\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3904 - accuracy: 0.8462\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4079 - accuracy: 0.8339\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.3940 - accuracy: 0.8429\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3999 - accuracy: 0.8384\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4082 - accuracy: 0.8294\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3971 - accuracy: 0.8496\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4089 - accuracy: 0.8272\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4145 - accuracy: 0.8283\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4079 - accuracy: 0.8316\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3976 - accuracy: 0.8339\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4242 - accuracy: 0.8204\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3953 - accuracy: 0.8328\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4245 - accuracy: 0.8193\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4086 - accuracy: 0.8294\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4089 - accuracy: 0.8316\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4034 - accuracy: 0.8384\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.3929 - accuracy: 0.8373\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4051 - accuracy: 0.8328\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.4051 - accuracy: 0.8339\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 200us/step - loss: 0.3983 - accuracy: 0.8373\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3889 - accuracy: 0.8395\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4196 - accuracy: 0.8249\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4003 - accuracy: 0.8316\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4119 - accuracy: 0.8361\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4025 - accuracy: 0.8328\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3940 - accuracy: 0.8418\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4092 - accuracy: 0.8283\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3948 - accuracy: 0.8316\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4003 - accuracy: 0.8339\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4011 - accuracy: 0.8316\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3813 - accuracy: 0.8474\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.3977 - accuracy: 0.8350\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3804 - accuracy: 0.8373\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4043 - accuracy: 0.8328\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3959 - accuracy: 0.8462\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4087 - accuracy: 0.8305\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3963 - accuracy: 0.8294\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4050 - accuracy: 0.8283\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3903 - accuracy: 0.8406\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4034 - accuracy: 0.8339\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4043 - accuracy: 0.8339\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.3945 - accuracy: 0.8294\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4133 - accuracy: 0.8260\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 198us/step - loss: 0.3858 - accuracy: 0.8418\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 204us/step - loss: 0.4001 - accuracy: 0.8395\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4001 - accuracy: 0.8260\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.3982 - accuracy: 0.8339\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4086 - accuracy: 0.8384\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 206us/step - loss: 0.3880 - accuracy: 0.8395\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 203us/step - loss: 0.4115 - accuracy: 0.8204\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 202us/step - loss: 0.4006 - accuracy: 0.8361\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3946 - accuracy: 0.8283\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4059 - accuracy: 0.8283\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3951 - accuracy: 0.8384\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 201us/step - loss: 0.4132 - accuracy: 0.8215\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 199us/step - loss: 0.4039 - accuracy: 0.8249\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 50, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 16ms/step - loss: 0.6717 - accuracy: 0.5449\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.6486 - accuracy: 0.6798\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.6598 - accuracy: 0.6292\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.6453 - accuracy: 0.6517\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.6348 - accuracy: 0.6517\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.6100 - accuracy: 0.6517\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.6270 - accuracy: 0.6685\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.6243 - accuracy: 0.6517\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.5964 - accuracy: 0.6798\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.6327 - accuracy: 0.6573\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.5865 - accuracy: 0.6573\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5960 - accuracy: 0.6798\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5934 - accuracy: 0.6685\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.5854 - accuracy: 0.6910\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.5692 - accuracy: 0.7135\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.5796 - accuracy: 0.7135\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.5668 - accuracy: 0.6798\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.5821 - accuracy: 0.6629\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.5610 - accuracy: 0.7022\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5442 - accuracy: 0.7528\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.5758 - accuracy: 0.7135\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5571 - accuracy: 0.7079\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5725 - accuracy: 0.7135\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.5542 - accuracy: 0.6910\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.5291 - accuracy: 0.7360\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5305 - accuracy: 0.7472\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5396 - accuracy: 0.7247\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5526 - accuracy: 0.7303\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5724 - accuracy: 0.7247\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5214 - accuracy: 0.7416\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5001 - accuracy: 0.7809\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.5338 - accuracy: 0.7360\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4888 - accuracy: 0.7865\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.5437 - accuracy: 0.7528\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5386 - accuracy: 0.7360\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5226 - accuracy: 0.7472\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.5041 - accuracy: 0.7978\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5037 - accuracy: 0.7809\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.5347 - accuracy: 0.7640\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.5283 - accuracy: 0.7360\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5067 - accuracy: 0.7697\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5319 - accuracy: 0.7472\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.5214 - accuracy: 0.7865\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4558 - accuracy: 0.7921\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.5144 - accuracy: 0.7640\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.5189 - accuracy: 0.7697\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4864 - accuracy: 0.7753\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4715 - accuracy: 0.7809\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.5117 - accuracy: 0.7640\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5060 - accuracy: 0.7809\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4918 - accuracy: 0.7528\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4913 - accuracy: 0.7697\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.5053 - accuracy: 0.7584\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4506 - accuracy: 0.7978\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.5056 - accuracy: 0.7528\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.5016 - accuracy: 0.7697\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4764 - accuracy: 0.7865\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.5378 - accuracy: 0.7584\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4825 - accuracy: 0.7921\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4847 - accuracy: 0.7865\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4944 - accuracy: 0.7640\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4744 - accuracy: 0.7528\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4839 - accuracy: 0.7865\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.5076 - accuracy: 0.7528\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4847 - accuracy: 0.7921\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4349 - accuracy: 0.8090\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4951 - accuracy: 0.7697\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4978 - accuracy: 0.7640\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4602 - accuracy: 0.8090\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4384 - accuracy: 0.7865\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4759 - accuracy: 0.8090\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4890 - accuracy: 0.7753\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4772 - accuracy: 0.7584\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4472 - accuracy: 0.7865\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4637 - accuracy: 0.7809\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4838 - accuracy: 0.7472\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4836 - accuracy: 0.7921\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.5049 - accuracy: 0.7584\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4803 - accuracy: 0.7865\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4565 - accuracy: 0.8034\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4957 - accuracy: 0.7697\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4690 - accuracy: 0.7697\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4654 - accuracy: 0.8202\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4048 - accuracy: 0.8315\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4603 - accuracy: 0.7921\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4314 - accuracy: 0.8371\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4556 - accuracy: 0.7978\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4351 - accuracy: 0.8034\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4641 - accuracy: 0.8034\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4204 - accuracy: 0.8202\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4697 - accuracy: 0.8090\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4811 - accuracy: 0.7978\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4430 - accuracy: 0.8258\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4903 - accuracy: 0.7865\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4456 - accuracy: 0.8090\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4371 - accuracy: 0.8146\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4925 - accuracy: 0.8090\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4265 - accuracy: 0.8202\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4507 - accuracy: 0.7978\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4746 - accuracy: 0.8090\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4812 - accuracy: 0.7809\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4530 - accuracy: 0.8258\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3986 - accuracy: 0.8315\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4509 - accuracy: 0.7978\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4694 - accuracy: 0.8090\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4489 - accuracy: 0.7978\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4563 - accuracy: 0.7921\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4338 - accuracy: 0.8090\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4508 - accuracy: 0.7978\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4501 - accuracy: 0.7978\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4638 - accuracy: 0.8146\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4496 - accuracy: 0.7809\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4451 - accuracy: 0.7978\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4610 - accuracy: 0.7921\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4261 - accuracy: 0.8146\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4246 - accuracy: 0.8427\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4672 - accuracy: 0.8034\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4618 - accuracy: 0.7978\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4295 - accuracy: 0.8202\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4110 - accuracy: 0.8034\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4307 - accuracy: 0.8202\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4726 - accuracy: 0.7978\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4245 - accuracy: 0.8202\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4199 - accuracy: 0.8090\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4657 - accuracy: 0.8034\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4367 - accuracy: 0.8090\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4964 - accuracy: 0.7865\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4150 - accuracy: 0.8371\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4496 - accuracy: 0.7921\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4496 - accuracy: 0.7865\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4309 - accuracy: 0.8034\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4525 - accuracy: 0.7809\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4306 - accuracy: 0.8315\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3977 - accuracy: 0.8258\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4216 - accuracy: 0.8258\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4438 - accuracy: 0.8090\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4299 - accuracy: 0.8146\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4615 - accuracy: 0.7921\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4494 - accuracy: 0.8146\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4138 - accuracy: 0.8427\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4659 - accuracy: 0.8371\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4382 - accuracy: 0.7978\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4436 - accuracy: 0.8034\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4644 - accuracy: 0.8202\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4447 - accuracy: 0.7921\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4735 - accuracy: 0.7978\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4314 - accuracy: 0.8371\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4318 - accuracy: 0.8202\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4028 - accuracy: 0.8146\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4186 - accuracy: 0.8315\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4275 - accuracy: 0.8427\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4148 - accuracy: 0.8371\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4598 - accuracy: 0.8090\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4321 - accuracy: 0.8146\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4394 - accuracy: 0.8427\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3973 - accuracy: 0.8315\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 210us/step - loss: 0.3997 - accuracy: 0.8258\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4654 - accuracy: 0.8034\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4415 - accuracy: 0.8539\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4353 - accuracy: 0.8371\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4156 - accuracy: 0.8371\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4672 - accuracy: 0.7978\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4135 - accuracy: 0.8258\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4632 - accuracy: 0.7978\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4067 - accuracy: 0.8483\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4316 - accuracy: 0.8258\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4166 - accuracy: 0.8258\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4343 - accuracy: 0.8090\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4173 - accuracy: 0.8483\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4179 - accuracy: 0.8202\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3981 - accuracy: 0.8258\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4341 - accuracy: 0.7921\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4496 - accuracy: 0.8090\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4516 - accuracy: 0.7978\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4060 - accuracy: 0.8202\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4565 - accuracy: 0.8146\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4154 - accuracy: 0.8258\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4058 - accuracy: 0.8483\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4334 - accuracy: 0.8202\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4514 - accuracy: 0.8090\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4822 - accuracy: 0.7921\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4321 - accuracy: 0.8146\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4394 - accuracy: 0.8315\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4326 - accuracy: 0.8315\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4476 - accuracy: 0.8090\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4215 - accuracy: 0.8090\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 206us/step - loss: 0.4010 - accuracy: 0.8146\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4471 - accuracy: 0.8315\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4068 - accuracy: 0.8539\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4235 - accuracy: 0.8090\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4155 - accuracy: 0.8090\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4489 - accuracy: 0.8146\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4610 - accuracy: 0.8146\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.3931 - accuracy: 0.8258\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4025 - accuracy: 0.8315\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4426 - accuracy: 0.7978\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.3905 - accuracy: 0.8371\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 209us/step - loss: 0.4667 - accuracy: 0.8090\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 207us/step - loss: 0.4388 - accuracy: 0.8146\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 210us/step - loss: 0.4204 - accuracy: 0.8202\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 208us/step - loss: 0.4283 - accuracy: 0.8427\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4352 - accuracy: 0.7865\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4340 - accuracy: 0.7921\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4063 - accuracy: 0.8315\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4060 - accuracy: 0.8371\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.4307 - accuracy: 0.8258\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4354 - accuracy: 0.7978\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4378 - accuracy: 0.8090\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3963 - accuracy: 0.8315\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4091 - accuracy: 0.8371\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.4267 - accuracy: 0.7978\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3924 - accuracy: 0.8427\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4193 - accuracy: 0.8202\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4335 - accuracy: 0.7978\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4064 - accuracy: 0.8483\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4078 - accuracy: 0.8483\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4277 - accuracy: 0.7865\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4031 - accuracy: 0.8202\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3617 - accuracy: 0.8596\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3618 - accuracy: 0.8483\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4287 - accuracy: 0.8202\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4125 - accuracy: 0.8483\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4278 - accuracy: 0.8315\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4386 - accuracy: 0.7921\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4103 - accuracy: 0.8315\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4563 - accuracy: 0.8090\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4047 - accuracy: 0.7809\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4246 - accuracy: 0.8202\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4116 - accuracy: 0.8483\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3993 - accuracy: 0.8483\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4102 - accuracy: 0.8427\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4010 - accuracy: 0.8202\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4140 - accuracy: 0.8315\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3905 - accuracy: 0.8596\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4369 - accuracy: 0.8202\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4311 - accuracy: 0.8315\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4133 - accuracy: 0.8202\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4001 - accuracy: 0.8258\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.3888 - accuracy: 0.8539\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4328 - accuracy: 0.8315\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4063 - accuracy: 0.8427\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4172 - accuracy: 0.8258\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3906 - accuracy: 0.8539\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3656 - accuracy: 0.8483\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4502 - accuracy: 0.8146\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3933 - accuracy: 0.8427\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3698 - accuracy: 0.8371\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3655 - accuracy: 0.8539\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3962 - accuracy: 0.8483\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4089 - accuracy: 0.8146\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3756 - accuracy: 0.8539\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3927 - accuracy: 0.8371\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3782 - accuracy: 0.8708\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4132 - accuracy: 0.8371\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4257 - accuracy: 0.8427\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4050 - accuracy: 0.8258\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3875 - accuracy: 0.8371\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4137 - accuracy: 0.8315\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4040 - accuracy: 0.8427\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4081 - accuracy: 0.8427\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4170 - accuracy: 0.8146\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3549 - accuracy: 0.8371\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4169 - accuracy: 0.8146\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3848 - accuracy: 0.8371\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3945 - accuracy: 0.8371\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4221 - accuracy: 0.8371\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4011 - accuracy: 0.8146\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4077 - accuracy: 0.8258\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4014 - accuracy: 0.8427\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3639 - accuracy: 0.8371\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4203 - accuracy: 0.8146\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4078 - accuracy: 0.8371\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4092 - accuracy: 0.8539\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.4535 - accuracy: 0.8034\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3995 - accuracy: 0.8371\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3890 - accuracy: 0.8483\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3867 - accuracy: 0.8146\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.4184 - accuracy: 0.8258\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4278 - accuracy: 0.8090\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3950 - accuracy: 0.8090\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4103 - accuracy: 0.8315\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3848 - accuracy: 0.8371\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3782 - accuracy: 0.8764\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4723 - accuracy: 0.7697\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4244 - accuracy: 0.8146\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4307 - accuracy: 0.8258\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3564 - accuracy: 0.8483\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3928 - accuracy: 0.8371\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3852 - accuracy: 0.8427\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3773 - accuracy: 0.8483\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4104 - accuracy: 0.8258\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.3489 - accuracy: 0.8708\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.4141 - accuracy: 0.8202\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4158 - accuracy: 0.8258\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.4263 - accuracy: 0.8146\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4035 - accuracy: 0.8202\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3446 - accuracy: 0.8539\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4017 - accuracy: 0.8427\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3793 - accuracy: 0.8315\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3902 - accuracy: 0.8371\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4866 - accuracy: 0.7753\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3892 - accuracy: 0.8652\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4094 - accuracy: 0.8202\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3720 - accuracy: 0.8708\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3869 - accuracy: 0.8258\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4127 - accuracy: 0.8090\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3719 - accuracy: 0.8371\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4019 - accuracy: 0.8315\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.4038 - accuracy: 0.8427\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3794 - accuracy: 0.8483\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4081 - accuracy: 0.8258\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3874 - accuracy: 0.8315\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 225us/step - loss: 0.4716 - accuracy: 0.7978\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3946 - accuracy: 0.8596\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3916 - accuracy: 0.8483\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4124 - accuracy: 0.8258\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4027 - accuracy: 0.8427\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3956 - accuracy: 0.8427\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3839 - accuracy: 0.8315\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3463 - accuracy: 0.8652\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.4123 - accuracy: 0.8202\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.4126 - accuracy: 0.8371\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3703 - accuracy: 0.8596\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3847 - accuracy: 0.8315\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4604 - accuracy: 0.7921\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3944 - accuracy: 0.8315\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3720 - accuracy: 0.8596\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3549 - accuracy: 0.8596\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 225us/step - loss: 0.3716 - accuracy: 0.8371\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4023 - accuracy: 0.8258\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4192 - accuracy: 0.8371\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4297 - accuracy: 0.8146\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3806 - accuracy: 0.8596\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3629 - accuracy: 0.8539\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3744 - accuracy: 0.8483\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4059 - accuracy: 0.8315\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3805 - accuracy: 0.8483\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3771 - accuracy: 0.8427\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4214 - accuracy: 0.8258\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3821 - accuracy: 0.8708\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3641 - accuracy: 0.8539\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3787 - accuracy: 0.8371\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 218us/step - loss: 0.3646 - accuracy: 0.8202\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3446 - accuracy: 0.8596\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3863 - accuracy: 0.8427\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.3927 - accuracy: 0.8315\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3828 - accuracy: 0.8315\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3395 - accuracy: 0.8315\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3505 - accuracy: 0.8483\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3856 - accuracy: 0.8483\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3667 - accuracy: 0.8371\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3919 - accuracy: 0.8315\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4071 - accuracy: 0.8258\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3289 - accuracy: 0.8764\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.3958 - accuracy: 0.8146\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.4473 - accuracy: 0.8146\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 223us/step - loss: 0.4249 - accuracy: 0.7809\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3764 - accuracy: 0.8315\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3924 - accuracy: 0.8483\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.3947 - accuracy: 0.8315\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3791 - accuracy: 0.8427\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 222us/step - loss: 0.3892 - accuracy: 0.8483\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 226us/step - loss: 0.3851 - accuracy: 0.8315\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3758 - accuracy: 0.8315\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3925 - accuracy: 0.8315\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 221us/step - loss: 0.3927 - accuracy: 0.8483\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.4058 - accuracy: 0.8315\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3606 - accuracy: 0.8764\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3621 - accuracy: 0.8652\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3789 - accuracy: 0.8371\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3970 - accuracy: 0.8764\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3473 - accuracy: 0.8708\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3756 - accuracy: 0.8708\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4008 - accuracy: 0.8202\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4156 - accuracy: 0.8315\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3894 - accuracy: 0.8371\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3935 - accuracy: 0.8539\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3748 - accuracy: 0.8596\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3644 - accuracy: 0.8596\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.3550 - accuracy: 0.8596\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4349 - accuracy: 0.7921\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.4147 - accuracy: 0.8483\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3628 - accuracy: 0.8483\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 216us/step - loss: 0.3518 - accuracy: 0.8483\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4067 - accuracy: 0.8371\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4305 - accuracy: 0.8202\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3793 - accuracy: 0.8258\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 215us/step - loss: 0.4018 - accuracy: 0.8258\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3691 - accuracy: 0.8483\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.3975 - accuracy: 0.8427\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3870 - accuracy: 0.8539\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 213us/step - loss: 0.4073 - accuracy: 0.8258\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 214us/step - loss: 0.3729 - accuracy: 0.8371\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 220us/step - loss: 0.3781 - accuracy: 0.8202\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3306 - accuracy: 0.8539\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.4035 - accuracy: 0.8427\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 212us/step - loss: 0.3447 - accuracy: 0.8708\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 219us/step - loss: 0.3545 - accuracy: 0.8708\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 217us/step - loss: 0.3772 - accuracy: 0.8539\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 211us/step - loss: 0.3729 - accuracy: 0.8427\n",
      "713/713 [==============================] - 0s 696us/step\n",
      "Epoch 1/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4738 - accuracy: 0.7924\n",
      "Epoch 2/400\n",
      " 30/891 [>.............................] - ETA: 0s - loss: 0.4629 - accuracy: 0.7333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 217us/step - loss: 0.4795 - accuracy: 0.7845\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4522 - accuracy: 0.8081\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 207us/step - loss: 0.4540 - accuracy: 0.8036\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4244 - accuracy: 0.8171\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4460 - accuracy: 0.7980\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 206us/step - loss: 0.4526 - accuracy: 0.8013\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4464 - accuracy: 0.8227\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4451 - accuracy: 0.8092\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4402 - accuracy: 0.8025\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4341 - accuracy: 0.8103\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4306 - accuracy: 0.8171\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4419 - accuracy: 0.8103\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4343 - accuracy: 0.8215\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4230 - accuracy: 0.8193\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4287 - accuracy: 0.8193\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4119 - accuracy: 0.8328\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4314 - accuracy: 0.8193\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4381 - accuracy: 0.8215\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4280 - accuracy: 0.8182\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4268 - accuracy: 0.8215\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4315 - accuracy: 0.8316\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4125 - accuracy: 0.8305\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4333 - accuracy: 0.8182\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4123 - accuracy: 0.8249\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.4372 - accuracy: 0.8070\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4007 - accuracy: 0.8339\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4486 - accuracy: 0.8159\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4294 - accuracy: 0.8137\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4282 - accuracy: 0.8227\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4369 - accuracy: 0.8193\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4236 - accuracy: 0.8182\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4307 - accuracy: 0.8171\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.4336 - accuracy: 0.8148\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4248 - accuracy: 0.8103\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4193 - accuracy: 0.8193\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4242 - accuracy: 0.8227\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4304 - accuracy: 0.8215\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4426 - accuracy: 0.8171\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4245 - accuracy: 0.8316\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4509 - accuracy: 0.8025\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4108 - accuracy: 0.8328\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4182 - accuracy: 0.8227\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4208 - accuracy: 0.8339\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4457 - accuracy: 0.8058\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4374 - accuracy: 0.8070\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4213 - accuracy: 0.8395\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4191 - accuracy: 0.8215\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4022 - accuracy: 0.8260\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4357 - accuracy: 0.8114\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4303 - accuracy: 0.8159\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4242 - accuracy: 0.8126\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4227 - accuracy: 0.8260\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4101 - accuracy: 0.8260\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4213 - accuracy: 0.8283\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4217 - accuracy: 0.8260\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4162 - accuracy: 0.8249\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4207 - accuracy: 0.8260\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4182 - accuracy: 0.8328\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4294 - accuracy: 0.8182\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4095 - accuracy: 0.8316\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4170 - accuracy: 0.8249\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4136 - accuracy: 0.8305\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4149 - accuracy: 0.8294\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4178 - accuracy: 0.8339\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4255 - accuracy: 0.8272\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4082 - accuracy: 0.8384\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4160 - accuracy: 0.8305\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4305 - accuracy: 0.8171\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4198 - accuracy: 0.8249\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4278 - accuracy: 0.8171\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4017 - accuracy: 0.8418\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4152 - accuracy: 0.8238\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4014 - accuracy: 0.8316\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4116 - accuracy: 0.8294\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4096 - accuracy: 0.8328\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4020 - accuracy: 0.8260\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4082 - accuracy: 0.8305\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4300 - accuracy: 0.8204\n",
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4085 - accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4169 - accuracy: 0.8373\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4236 - accuracy: 0.8249\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4239 - accuracy: 0.8294\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4080 - accuracy: 0.8373\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4070 - accuracy: 0.8361\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4323 - accuracy: 0.8215\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4029 - accuracy: 0.8384\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4107 - accuracy: 0.8316\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4055 - accuracy: 0.8361\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4104 - accuracy: 0.8395\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4258 - accuracy: 0.8294\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4052 - accuracy: 0.8294\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4121 - accuracy: 0.8395\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4165 - accuracy: 0.8238\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4226 - accuracy: 0.8361\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4063 - accuracy: 0.8305\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4244 - accuracy: 0.8260\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3995 - accuracy: 0.8384\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4097 - accuracy: 0.8283\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4126 - accuracy: 0.8283\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4087 - accuracy: 0.8350\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4154 - accuracy: 0.8272\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4127 - accuracy: 0.8272\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4138 - accuracy: 0.8215\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 209us/step - loss: 0.4102 - accuracy: 0.8305\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4128 - accuracy: 0.8283\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3894 - accuracy: 0.8406\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4051 - accuracy: 0.8215\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4176 - accuracy: 0.8215\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4020 - accuracy: 0.8350\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4253 - accuracy: 0.8238\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3950 - accuracy: 0.8373\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4244 - accuracy: 0.8159\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4161 - accuracy: 0.8182\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4064 - accuracy: 0.8204\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4159 - accuracy: 0.8238\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4139 - accuracy: 0.8249\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4243 - accuracy: 0.8305\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3992 - accuracy: 0.8339\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3882 - accuracy: 0.8373\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3994 - accuracy: 0.8485\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3869 - accuracy: 0.8462\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4024 - accuracy: 0.8339\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4075 - accuracy: 0.8215\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3997 - accuracy: 0.8373\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4269 - accuracy: 0.8249\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3816 - accuracy: 0.8440\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4104 - accuracy: 0.8193\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4077 - accuracy: 0.8272\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4012 - accuracy: 0.8451\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3982 - accuracy: 0.8283\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4145 - accuracy: 0.8238\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3950 - accuracy: 0.8429\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.4284 - accuracy: 0.8215\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4091 - accuracy: 0.8238\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4019 - accuracy: 0.8361\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4035 - accuracy: 0.8350\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4100 - accuracy: 0.8283\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4062 - accuracy: 0.8294\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4273 - accuracy: 0.8159\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4046 - accuracy: 0.8462\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4059 - accuracy: 0.8328\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4197 - accuracy: 0.8238\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4047 - accuracy: 0.8283\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4105 - accuracy: 0.8294\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3946 - accuracy: 0.8474\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4276 - accuracy: 0.8238\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4113 - accuracy: 0.8272\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4076 - accuracy: 0.8373\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4015 - accuracy: 0.8384\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 208us/step - loss: 0.4266 - accuracy: 0.8316\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4143 - accuracy: 0.8260\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4120 - accuracy: 0.8328\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4025 - accuracy: 0.8272\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4219 - accuracy: 0.8272\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3966 - accuracy: 0.8462\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3993 - accuracy: 0.8373\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3957 - accuracy: 0.8249\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3983 - accuracy: 0.8350\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4004 - accuracy: 0.8429\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.4125 - accuracy: 0.8204\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3941 - accuracy: 0.8361\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4111 - accuracy: 0.8249\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4006 - accuracy: 0.8373\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4198 - accuracy: 0.8193\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3988 - accuracy: 0.8373\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4096 - accuracy: 0.8283\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3978 - accuracy: 0.8283\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4124 - accuracy: 0.8272\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4013 - accuracy: 0.8339\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4061 - accuracy: 0.8260\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3987 - accuracy: 0.8294\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4054 - accuracy: 0.8395\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4031 - accuracy: 0.8418\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4041 - accuracy: 0.8339\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4116 - accuracy: 0.8272\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3972 - accuracy: 0.8384\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3992 - accuracy: 0.8373\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3990 - accuracy: 0.8328\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4007 - accuracy: 0.8339\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4158 - accuracy: 0.8204\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3929 - accuracy: 0.8418\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4014 - accuracy: 0.8294\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4018 - accuracy: 0.8305\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3971 - accuracy: 0.8260\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3971 - accuracy: 0.8350\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4218 - accuracy: 0.8204\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4077 - accuracy: 0.8418\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4076 - accuracy: 0.8283\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3979 - accuracy: 0.8361\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3935 - accuracy: 0.8384\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4061 - accuracy: 0.8384\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4059 - accuracy: 0.8395\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3721 - accuracy: 0.8552\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4084 - accuracy: 0.8339\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3989 - accuracy: 0.8373\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4239 - accuracy: 0.8193\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4127 - accuracy: 0.8283\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.4001 - accuracy: 0.8384\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4120 - accuracy: 0.8238\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3988 - accuracy: 0.8429\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4129 - accuracy: 0.8406\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4124 - accuracy: 0.8294\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.3976 - accuracy: 0.8328\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3910 - accuracy: 0.8418\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3907 - accuracy: 0.8361\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3898 - accuracy: 0.8373\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3959 - accuracy: 0.8406\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.3870 - accuracy: 0.8451\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 268us/step - loss: 0.4098 - accuracy: 0.8339\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3940 - accuracy: 0.8361\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3993 - accuracy: 0.8316\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3881 - accuracy: 0.8418\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4123 - accuracy: 0.8283\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3869 - accuracy: 0.8496\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4143 - accuracy: 0.8283\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4057 - accuracy: 0.8204\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4048 - accuracy: 0.8350\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3983 - accuracy: 0.8462\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4101 - accuracy: 0.8361\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3971 - accuracy: 0.8316\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4047 - accuracy: 0.8373\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3899 - accuracy: 0.8339\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3986 - accuracy: 0.8350\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3987 - accuracy: 0.8328\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3898 - accuracy: 0.8418\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3874 - accuracy: 0.8451\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3980 - accuracy: 0.8339\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4026 - accuracy: 0.8260\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4042 - accuracy: 0.8373\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3961 - accuracy: 0.8373\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3853 - accuracy: 0.8373\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3993 - accuracy: 0.8373\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3957 - accuracy: 0.8305\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3904 - accuracy: 0.8462\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 222us/step - loss: 0.3934 - accuracy: 0.8429\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3951 - accuracy: 0.8406\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3930 - accuracy: 0.8350\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4036 - accuracy: 0.8204\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3942 - accuracy: 0.8406\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3968 - accuracy: 0.8350\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3763 - accuracy: 0.8418\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4098 - accuracy: 0.8339\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3782 - accuracy: 0.8395\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3929 - accuracy: 0.8249\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3739 - accuracy: 0.8575\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4085 - accuracy: 0.8316\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3970 - accuracy: 0.8395\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3944 - accuracy: 0.8350\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4120 - accuracy: 0.8215\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4004 - accuracy: 0.8361\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4007 - accuracy: 0.8316\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4060 - accuracy: 0.8406\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3936 - accuracy: 0.8339\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4050 - accuracy: 0.8316\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.4032 - accuracy: 0.8272\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4138 - accuracy: 0.8272\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3864 - accuracy: 0.8361\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3887 - accuracy: 0.8373\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3872 - accuracy: 0.8384\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3871 - accuracy: 0.8361\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.3751 - accuracy: 0.8507\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3959 - accuracy: 0.8406\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3990 - accuracy: 0.8294\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4005 - accuracy: 0.8373\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3997 - accuracy: 0.8395\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3899 - accuracy: 0.8406\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4060 - accuracy: 0.8305\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3905 - accuracy: 0.8418\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3871 - accuracy: 0.8474\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3942 - accuracy: 0.8496\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3838 - accuracy: 0.8395\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3936 - accuracy: 0.8395\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3925 - accuracy: 0.8350\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3992 - accuracy: 0.8350\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3843 - accuracy: 0.8406\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4082 - accuracy: 0.8294\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3880 - accuracy: 0.8294\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3938 - accuracy: 0.8406\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4045 - accuracy: 0.8272\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4025 - accuracy: 0.8361\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 210us/step - loss: 0.4042 - accuracy: 0.8361\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4065 - accuracy: 0.8249\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3869 - accuracy: 0.8474\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4042 - accuracy: 0.8339\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3870 - accuracy: 0.8485\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3814 - accuracy: 0.8451\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3883 - accuracy: 0.8373\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4091 - accuracy: 0.8373\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3880 - accuracy: 0.8272\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 211us/step - loss: 0.3791 - accuracy: 0.8429\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4069 - accuracy: 0.8305\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.4050 - accuracy: 0.8272\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.4049 - accuracy: 0.8283\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.4195 - accuracy: 0.8249\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.4136 - accuracy: 0.8272\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3928 - accuracy: 0.8272\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3934 - accuracy: 0.8496\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3705 - accuracy: 0.8462\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3927 - accuracy: 0.8395\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3860 - accuracy: 0.8384\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3819 - accuracy: 0.8294\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3818 - accuracy: 0.8451\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3902 - accuracy: 0.8373\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.4019 - accuracy: 0.8328\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3828 - accuracy: 0.8418\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4063 - accuracy: 0.8227\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.4033 - accuracy: 0.8418\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3835 - accuracy: 0.8328\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4130 - accuracy: 0.8283\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3852 - accuracy: 0.8429\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3771 - accuracy: 0.8429\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3861 - accuracy: 0.8238\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3815 - accuracy: 0.8384\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3967 - accuracy: 0.8373\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3777 - accuracy: 0.8384\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3855 - accuracy: 0.8328\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3834 - accuracy: 0.8395\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3853 - accuracy: 0.8384\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3931 - accuracy: 0.8316\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4101 - accuracy: 0.8373\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3944 - accuracy: 0.8429\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3957 - accuracy: 0.8440\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3734 - accuracy: 0.8395\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 212us/step - loss: 0.3848 - accuracy: 0.8361\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3774 - accuracy: 0.8406\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3944 - accuracy: 0.8316\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 215us/step - loss: 0.3926 - accuracy: 0.8406\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 214us/step - loss: 0.3988 - accuracy: 0.8316\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3809 - accuracy: 0.8496\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 213us/step - loss: 0.3901 - accuracy: 0.8249\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3973 - accuracy: 0.8350\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3926 - accuracy: 0.8373\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.4159 - accuracy: 0.8137\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3919 - accuracy: 0.8361\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3973 - accuracy: 0.8406\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3858 - accuracy: 0.8429\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.4075 - accuracy: 0.8305\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3780 - accuracy: 0.8519\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3809 - accuracy: 0.8395\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.4075 - accuracy: 0.8249\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3793 - accuracy: 0.8429\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3895 - accuracy: 0.8328\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3907 - accuracy: 0.8339\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3892 - accuracy: 0.8395\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3850 - accuracy: 0.8316\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3971 - accuracy: 0.8406\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3913 - accuracy: 0.8440\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.4124 - accuracy: 0.8171\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3839 - accuracy: 0.8429\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3924 - accuracy: 0.8361\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3853 - accuracy: 0.8373\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3839 - accuracy: 0.8294\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3921 - accuracy: 0.8361\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3887 - accuracy: 0.8305\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3846 - accuracy: 0.8440\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3944 - accuracy: 0.8418\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3868 - accuracy: 0.8418\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3917 - accuracy: 0.8305\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3834 - accuracy: 0.8328\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3779 - accuracy: 0.8474\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3790 - accuracy: 0.8406\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3760 - accuracy: 0.8507\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3998 - accuracy: 0.8395\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3759 - accuracy: 0.8496\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3806 - accuracy: 0.8418\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3821 - accuracy: 0.8462\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3802 - accuracy: 0.8373\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3972 - accuracy: 0.8260\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3723 - accuracy: 0.8462\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3814 - accuracy: 0.8384\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 225us/step - loss: 0.3734 - accuracy: 0.8395\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 226us/step - loss: 0.3917 - accuracy: 0.8316\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 228us/step - loss: 0.3797 - accuracy: 0.8474\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3932 - accuracy: 0.8305\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3966 - accuracy: 0.8260\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3932 - accuracy: 0.8328\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 227us/step - loss: 0.3714 - accuracy: 0.8384\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3834 - accuracy: 0.8429\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 223us/step - loss: 0.3924 - accuracy: 0.8350\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3972 - accuracy: 0.8384\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3800 - accuracy: 0.8462\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3844 - accuracy: 0.8328\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3868 - accuracy: 0.8474\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3677 - accuracy: 0.8373\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3730 - accuracy: 0.8519\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 221us/step - loss: 0.3996 - accuracy: 0.8260\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 217us/step - loss: 0.3846 - accuracy: 0.8451\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3907 - accuracy: 0.8339\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3762 - accuracy: 0.8418\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 222us/step - loss: 0.3851 - accuracy: 0.8406\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 228us/step - loss: 0.3932 - accuracy: 0.8350\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.3658 - accuracy: 0.8530\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 218us/step - loss: 0.3784 - accuracy: 0.8496\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3893 - accuracy: 0.8328\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 220us/step - loss: 0.3794 - accuracy: 0.8395\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 219us/step - loss: 0.3949 - accuracy: 0.8305\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 224us/step - loss: 0.4075 - accuracy: 0.8328\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 216us/step - loss: 0.3821 - accuracy: 0.8485\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 50, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 4s 23ms/step - loss: 0.6533 - accuracy: 0.6180\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.6431 - accuracy: 0.6629\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.6726 - accuracy: 0.6517\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.6733 - accuracy: 0.6404\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.6511 - accuracy: 0.6404\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.6241 - accuracy: 0.6798\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.6243 - accuracy: 0.6629\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.6026 - accuracy: 0.6798\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.6271 - accuracy: 0.6573\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.6280 - accuracy: 0.6236\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.6468 - accuracy: 0.6685\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.6217 - accuracy: 0.6742\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.6156 - accuracy: 0.6629\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.6079 - accuracy: 0.6685\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5991 - accuracy: 0.6685\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.6094 - accuracy: 0.6742\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.5874 - accuracy: 0.6910\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5938 - accuracy: 0.6629\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.5975 - accuracy: 0.6742\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.5805 - accuracy: 0.6854\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.6229 - accuracy: 0.6573\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.6122 - accuracy: 0.6910\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5615 - accuracy: 0.7247\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5966 - accuracy: 0.6854\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5566 - accuracy: 0.7135\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.5285 - accuracy: 0.7022\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5479 - accuracy: 0.7303\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.5497 - accuracy: 0.7135\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5548 - accuracy: 0.7360\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5675 - accuracy: 0.7079\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5541 - accuracy: 0.7416\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.5520 - accuracy: 0.7584\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5540 - accuracy: 0.7472\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5547 - accuracy: 0.7303\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.5511 - accuracy: 0.7753\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.5280 - accuracy: 0.7303\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.5631 - accuracy: 0.7303\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5321 - accuracy: 0.7303\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5235 - accuracy: 0.7584\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5474 - accuracy: 0.7303\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5409 - accuracy: 0.7472\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.5198 - accuracy: 0.7416\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.5511 - accuracy: 0.7247\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.5118 - accuracy: 0.7079\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.5415 - accuracy: 0.7416\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5398 - accuracy: 0.7191\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.5254 - accuracy: 0.7416\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5066 - accuracy: 0.7528\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5109 - accuracy: 0.7753\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5088 - accuracy: 0.7809\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.5669 - accuracy: 0.7247\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5105 - accuracy: 0.7528\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5280 - accuracy: 0.7416\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.5179 - accuracy: 0.7753\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5087 - accuracy: 0.7978\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5016 - accuracy: 0.7753\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4860 - accuracy: 0.7753\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.5805 - accuracy: 0.7191\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5360 - accuracy: 0.7809\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4938 - accuracy: 0.7753\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5402 - accuracy: 0.7640\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4785 - accuracy: 0.7978\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4979 - accuracy: 0.7753\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.4447 - accuracy: 0.8202\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4702 - accuracy: 0.7921\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.5137 - accuracy: 0.7584\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4642 - accuracy: 0.7978\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5376 - accuracy: 0.7360\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.5051 - accuracy: 0.7809\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.4822 - accuracy: 0.7921\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4722 - accuracy: 0.8034\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5395 - accuracy: 0.7472\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4962 - accuracy: 0.7865\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.5110 - accuracy: 0.7528\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.4879 - accuracy: 0.7697\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5195 - accuracy: 0.7416\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4740 - accuracy: 0.7640\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5215 - accuracy: 0.7360\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5164 - accuracy: 0.7640\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.5306 - accuracy: 0.7528\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4722 - accuracy: 0.7865\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4315 - accuracy: 0.8315\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4979 - accuracy: 0.7640\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4816 - accuracy: 0.7697\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4503 - accuracy: 0.8090\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4867 - accuracy: 0.7921\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.4895 - accuracy: 0.7809\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4293 - accuracy: 0.8258\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.5078 - accuracy: 0.7697\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.5062 - accuracy: 0.7809\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4659 - accuracy: 0.8034\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4887 - accuracy: 0.8090\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4591 - accuracy: 0.8034\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5107 - accuracy: 0.7640\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5304 - accuracy: 0.7640\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4823 - accuracy: 0.8034\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4911 - accuracy: 0.8034\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.5303 - accuracy: 0.7584\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4606 - accuracy: 0.8034\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.5333 - accuracy: 0.7640\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.5047 - accuracy: 0.7528\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4896 - accuracy: 0.8034\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4871 - accuracy: 0.7753\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4765 - accuracy: 0.7978\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4576 - accuracy: 0.8034\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4950 - accuracy: 0.7809\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 271us/step - loss: 0.4943 - accuracy: 0.7584\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.4965 - accuracy: 0.7640\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4446 - accuracy: 0.8258\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4489 - accuracy: 0.8258\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4401 - accuracy: 0.8315\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4406 - accuracy: 0.8258\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4807 - accuracy: 0.7360\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4759 - accuracy: 0.8146\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4943 - accuracy: 0.7753\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4169 - accuracy: 0.8427\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.5176 - accuracy: 0.7640\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.4713 - accuracy: 0.7865\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4137 - accuracy: 0.8483\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4699 - accuracy: 0.8202\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4763 - accuracy: 0.8034\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.4670 - accuracy: 0.7697\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4674 - accuracy: 0.8034\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4943 - accuracy: 0.7865\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4823 - accuracy: 0.7753\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4663 - accuracy: 0.7697\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4610 - accuracy: 0.8315\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4623 - accuracy: 0.8034\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.4782 - accuracy: 0.7865\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4583 - accuracy: 0.7921\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4804 - accuracy: 0.7978\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.5421 - accuracy: 0.7753\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4843 - accuracy: 0.7865\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4548 - accuracy: 0.7921\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4938 - accuracy: 0.7697\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4753 - accuracy: 0.8258\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4611 - accuracy: 0.7921\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4586 - accuracy: 0.7978\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4649 - accuracy: 0.8090\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4826 - accuracy: 0.7921\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4308 - accuracy: 0.8090\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4620 - accuracy: 0.7978\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4360 - accuracy: 0.8427\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4427 - accuracy: 0.7865\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4797 - accuracy: 0.7978\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4238 - accuracy: 0.8202\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4321 - accuracy: 0.8315\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4388 - accuracy: 0.8258\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4529 - accuracy: 0.7978\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4684 - accuracy: 0.8034\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4601 - accuracy: 0.8034\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.3964 - accuracy: 0.8483\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4139 - accuracy: 0.8258\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4826 - accuracy: 0.8258\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4849 - accuracy: 0.8090\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4552 - accuracy: 0.8090\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 295us/step - loss: 0.4481 - accuracy: 0.7978\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4809 - accuracy: 0.7809\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4165 - accuracy: 0.8371\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4119 - accuracy: 0.8315\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4815 - accuracy: 0.8146\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4910 - accuracy: 0.7865\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4553 - accuracy: 0.7921\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4680 - accuracy: 0.8090\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4181 - accuracy: 0.8371\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4774 - accuracy: 0.7921\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.4216 - accuracy: 0.8202\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4523 - accuracy: 0.7921\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4292 - accuracy: 0.8258\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4178 - accuracy: 0.8202\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4523 - accuracy: 0.8146\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.5091 - accuracy: 0.7978\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4358 - accuracy: 0.8146\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4522 - accuracy: 0.8258\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4527 - accuracy: 0.7865\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4410 - accuracy: 0.8315\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4193 - accuracy: 0.8258\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4137 - accuracy: 0.8315\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4846 - accuracy: 0.8034\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.4226 - accuracy: 0.8258\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4859 - accuracy: 0.7978\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.5125 - accuracy: 0.7640\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4713 - accuracy: 0.8146\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4357 - accuracy: 0.8596\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4544 - accuracy: 0.7865\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 494us/step - loss: 0.4701 - accuracy: 0.7978\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4815 - accuracy: 0.7978\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.4312 - accuracy: 0.8146\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4389 - accuracy: 0.8034\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4631 - accuracy: 0.7809\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4355 - accuracy: 0.8146\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4206 - accuracy: 0.8371\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.4488 - accuracy: 0.8090\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.4429 - accuracy: 0.8034\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4732 - accuracy: 0.8258\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.3922 - accuracy: 0.8708\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4447 - accuracy: 0.8034\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4778 - accuracy: 0.7809\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4482 - accuracy: 0.8146\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4410 - accuracy: 0.8202\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4124 - accuracy: 0.8539\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4094 - accuracy: 0.8315\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4352 - accuracy: 0.8146\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4644 - accuracy: 0.8315\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4494 - accuracy: 0.8090\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4139 - accuracy: 0.8258\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4613 - accuracy: 0.8146\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4255 - accuracy: 0.8315\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4448 - accuracy: 0.8202\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4398 - accuracy: 0.8258\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4391 - accuracy: 0.8146\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4300 - accuracy: 0.8090\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4523 - accuracy: 0.8258\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4641 - accuracy: 0.7978\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4086 - accuracy: 0.8427\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4655 - accuracy: 0.8034\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4515 - accuracy: 0.8371\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4525 - accuracy: 0.8146\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4335 - accuracy: 0.8258\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4255 - accuracy: 0.8202\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4679 - accuracy: 0.7978\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4058 - accuracy: 0.8146\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4360 - accuracy: 0.8315\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4412 - accuracy: 0.8315\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4082 - accuracy: 0.8202\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4322 - accuracy: 0.8315\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4101 - accuracy: 0.8371\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4546 - accuracy: 0.7978\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4191 - accuracy: 0.8202\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4839 - accuracy: 0.7753\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4608 - accuracy: 0.8146\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4365 - accuracy: 0.8202\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4446 - accuracy: 0.8146\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3811 - accuracy: 0.8371\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4311 - accuracy: 0.8202\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4484 - accuracy: 0.8596\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4379 - accuracy: 0.8146\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4274 - accuracy: 0.7921\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4260 - accuracy: 0.8146\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4202 - accuracy: 0.8202\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4559 - accuracy: 0.7921\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4715 - accuracy: 0.8146\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4326 - accuracy: 0.8427\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4681 - accuracy: 0.7865\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4568 - accuracy: 0.8034\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4407 - accuracy: 0.8090\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4402 - accuracy: 0.7921\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4506 - accuracy: 0.8146\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4443 - accuracy: 0.8090\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3874 - accuracy: 0.8483\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4566 - accuracy: 0.8202\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4218 - accuracy: 0.8427\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4315 - accuracy: 0.8483\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4499 - accuracy: 0.8090\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4716 - accuracy: 0.7978\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4402 - accuracy: 0.7921\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4588 - accuracy: 0.8146\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4370 - accuracy: 0.8202\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4432 - accuracy: 0.8090\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4636 - accuracy: 0.8090\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4241 - accuracy: 0.8202\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4279 - accuracy: 0.8146\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4485 - accuracy: 0.8315\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3880 - accuracy: 0.8315\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3972 - accuracy: 0.8539\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4485 - accuracy: 0.8090\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4358 - accuracy: 0.8034\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4631 - accuracy: 0.7921\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4652 - accuracy: 0.7978\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4581 - accuracy: 0.8090\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4384 - accuracy: 0.8258\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4552 - accuracy: 0.8202\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4023 - accuracy: 0.8371\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.3788 - accuracy: 0.8427\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4199 - accuracy: 0.8090\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4502 - accuracy: 0.8315\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4423 - accuracy: 0.8090\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4561 - accuracy: 0.8371\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4120 - accuracy: 0.8090\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4451 - accuracy: 0.8146\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4225 - accuracy: 0.8315\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4108 - accuracy: 0.8315\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4509 - accuracy: 0.8090\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4536 - accuracy: 0.8090\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4155 - accuracy: 0.8202\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4294 - accuracy: 0.8315\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3871 - accuracy: 0.8483\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4883 - accuracy: 0.8034\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4192 - accuracy: 0.8315\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4524 - accuracy: 0.7978\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4281 - accuracy: 0.8427\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.3948 - accuracy: 0.8258\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4198 - accuracy: 0.8315\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4267 - accuracy: 0.8315\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 304us/step - loss: 0.4097 - accuracy: 0.8315\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4637 - accuracy: 0.7697\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4208 - accuracy: 0.8146\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4183 - accuracy: 0.8258\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4431 - accuracy: 0.8315\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4277 - accuracy: 0.8427\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4240 - accuracy: 0.8315\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4594 - accuracy: 0.8034\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.4578 - accuracy: 0.8427\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.4033 - accuracy: 0.8146\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 303us/step - loss: 0.4221 - accuracy: 0.8371\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3902 - accuracy: 0.8596\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4154 - accuracy: 0.8315\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4199 - accuracy: 0.8427\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4505 - accuracy: 0.8258\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4603 - accuracy: 0.8090\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.3860 - accuracy: 0.8820\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.3970 - accuracy: 0.8427\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 283us/step - loss: 0.4352 - accuracy: 0.7978\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.4057 - accuracy: 0.8596\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4354 - accuracy: 0.8371\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.4626 - accuracy: 0.8258\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4552 - accuracy: 0.7978\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4548 - accuracy: 0.8315\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4191 - accuracy: 0.8427\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.3991 - accuracy: 0.8483\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4272 - accuracy: 0.8258\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3870 - accuracy: 0.8483\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.3977 - accuracy: 0.8427\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.3884 - accuracy: 0.8427\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4398 - accuracy: 0.8146\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4012 - accuracy: 0.8371\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4280 - accuracy: 0.8258\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4646 - accuracy: 0.7865\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4249 - accuracy: 0.8258\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4416 - accuracy: 0.7978\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4209 - accuracy: 0.8539\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4355 - accuracy: 0.8034\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4416 - accuracy: 0.8146\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4246 - accuracy: 0.7978\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4059 - accuracy: 0.8258\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.3862 - accuracy: 0.8427\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4239 - accuracy: 0.8258\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.5156 - accuracy: 0.7584\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3943 - accuracy: 0.8427\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 279us/step - loss: 0.4305 - accuracy: 0.8258\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.3906 - accuracy: 0.8315\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4795 - accuracy: 0.7865\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 285us/step - loss: 0.4161 - accuracy: 0.8596\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4298 - accuracy: 0.8202\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4100 - accuracy: 0.8202\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4229 - accuracy: 0.8090\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.4089 - accuracy: 0.8427\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 278us/step - loss: 0.4423 - accuracy: 0.8315\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4111 - accuracy: 0.8315\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.3855 - accuracy: 0.8427\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4482 - accuracy: 0.8034\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.4268 - accuracy: 0.8315\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.3823 - accuracy: 0.8483\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4512 - accuracy: 0.8202\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.4378 - accuracy: 0.8258\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4090 - accuracy: 0.8315\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.4155 - accuracy: 0.8539\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 283us/step - loss: 0.4064 - accuracy: 0.8146\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3994 - accuracy: 0.8371\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.4107 - accuracy: 0.8427\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 280us/step - loss: 0.4060 - accuracy: 0.8483\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 284us/step - loss: 0.3936 - accuracy: 0.8539\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 309us/step - loss: 0.4287 - accuracy: 0.8371\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.4522 - accuracy: 0.8090\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3973 - accuracy: 0.8539\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4094 - accuracy: 0.8090\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4230 - accuracy: 0.8539\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4232 - accuracy: 0.8202\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 300us/step - loss: 0.4000 - accuracy: 0.8371\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4262 - accuracy: 0.8202\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4161 - accuracy: 0.8371\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.3664 - accuracy: 0.8652\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4014 - accuracy: 0.8483\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4398 - accuracy: 0.8202\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.3755 - accuracy: 0.8483\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4114 - accuracy: 0.8596\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3889 - accuracy: 0.8596\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.4028 - accuracy: 0.8315\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 301us/step - loss: 0.4184 - accuracy: 0.8202\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 302us/step - loss: 0.4192 - accuracy: 0.8202\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4121 - accuracy: 0.8258\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 289us/step - loss: 0.4106 - accuracy: 0.8315\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 293us/step - loss: 0.4101 - accuracy: 0.8427\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4360 - accuracy: 0.8427\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4548 - accuracy: 0.8090\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4071 - accuracy: 0.8371\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.3914 - accuracy: 0.8708\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.4004 - accuracy: 0.8539\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4209 - accuracy: 0.8202\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4249 - accuracy: 0.8258\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 294us/step - loss: 0.4247 - accuracy: 0.8258\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.4204 - accuracy: 0.8146\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4014 - accuracy: 0.8315\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.3693 - accuracy: 0.8708\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 298us/step - loss: 0.3973 - accuracy: 0.8539\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 291us/step - loss: 0.4051 - accuracy: 0.8315\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 297us/step - loss: 0.3723 - accuracy: 0.8708\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4267 - accuracy: 0.7978\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3947 - accuracy: 0.8539\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.3868 - accuracy: 0.8708\n",
      "713/713 [==============================] - 1s 990us/step\n",
      "Epoch 1/400\n",
      "570/891 [==================>...........] - ETA: 0s - loss: 0.4813 - accuracy: 0.7947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 295us/step - loss: 0.4756 - accuracy: 0.7980\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 274us/step - loss: 0.4716 - accuracy: 0.8013\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 275us/step - loss: 0.4639 - accuracy: 0.7935\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 274us/step - loss: 0.4660 - accuracy: 0.8002\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.4673 - accuracy: 0.8058\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4700 - accuracy: 0.7991\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 275us/step - loss: 0.4644 - accuracy: 0.8092\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.4582 - accuracy: 0.8137\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4511 - accuracy: 0.8159\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.4633 - accuracy: 0.8002\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.4382 - accuracy: 0.8092\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 275us/step - loss: 0.4489 - accuracy: 0.8148\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 276us/step - loss: 0.4629 - accuracy: 0.8036\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 278us/step - loss: 0.4490 - accuracy: 0.8081\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 277us/step - loss: 0.4458 - accuracy: 0.8204\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4471 - accuracy: 0.8081\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4379 - accuracy: 0.8238\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4306 - accuracy: 0.8227\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4556 - accuracy: 0.8036\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4630 - accuracy: 0.8025\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4488 - accuracy: 0.8103\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4508 - accuracy: 0.8182\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4371 - accuracy: 0.8137\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4400 - accuracy: 0.8070\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4233 - accuracy: 0.8249\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4413 - accuracy: 0.8215\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4446 - accuracy: 0.8070\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4503 - accuracy: 0.8047\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4352 - accuracy: 0.8171\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4481 - accuracy: 0.8126\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4624 - accuracy: 0.8036\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4452 - accuracy: 0.8070\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4432 - accuracy: 0.8204\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4575 - accuracy: 0.8081\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4366 - accuracy: 0.8328\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4606 - accuracy: 0.8081\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4383 - accuracy: 0.8204\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4207 - accuracy: 0.8294\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4429 - accuracy: 0.8092\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4341 - accuracy: 0.8182\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4626 - accuracy: 0.8025\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4333 - accuracy: 0.8215\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4265 - accuracy: 0.8260\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4694 - accuracy: 0.8025\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4335 - accuracy: 0.8294\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4349 - accuracy: 0.8238\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4485 - accuracy: 0.8148\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4216 - accuracy: 0.8182\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4518 - accuracy: 0.8182\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4447 - accuracy: 0.8070\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4340 - accuracy: 0.8215\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 464us/step - loss: 0.4315 - accuracy: 0.8193\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4344 - accuracy: 0.8350\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4423 - accuracy: 0.8148\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4256 - accuracy: 0.8215\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.4493 - accuracy: 0.8070\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4290 - accuracy: 0.8260\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4407 - accuracy: 0.8215\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4284 - accuracy: 0.8272\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4222 - accuracy: 0.8305\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4218 - accuracy: 0.8316\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4427 - accuracy: 0.8204\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4233 - accuracy: 0.8193\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4354 - accuracy: 0.8058\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4324 - accuracy: 0.8238\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4312 - accuracy: 0.8204\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4503 - accuracy: 0.8070\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4286 - accuracy: 0.8238\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4437 - accuracy: 0.8215\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4382 - accuracy: 0.8159\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4347 - accuracy: 0.8171\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4235 - accuracy: 0.8283\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4327 - accuracy: 0.8361\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4596 - accuracy: 0.8103\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4415 - accuracy: 0.8070\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4433 - accuracy: 0.8260\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4411 - accuracy: 0.8159\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4198 - accuracy: 0.8316\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4342 - accuracy: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4264 - accuracy: 0.8339\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4302 - accuracy: 0.8204\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4161 - accuracy: 0.8350\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4151 - accuracy: 0.8227\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4480 - accuracy: 0.8159\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.4217 - accuracy: 0.8182\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4384 - accuracy: 0.8182\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4397 - accuracy: 0.8215\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4151 - accuracy: 0.8339\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4102 - accuracy: 0.8395\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4185 - accuracy: 0.8305\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4232 - accuracy: 0.8193\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4231 - accuracy: 0.8294\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4399 - accuracy: 0.8204\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4193 - accuracy: 0.8260\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4316 - accuracy: 0.8193\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4219 - accuracy: 0.8260\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4446 - accuracy: 0.8159\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4328 - accuracy: 0.8148\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4284 - accuracy: 0.8316\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4562 - accuracy: 0.8013\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4040 - accuracy: 0.8507\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 286us/step - loss: 0.4480 - accuracy: 0.8148\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4228 - accuracy: 0.8159\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4320 - accuracy: 0.8260\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.4319 - accuracy: 0.8249\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4374 - accuracy: 0.8148\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.4274 - accuracy: 0.8272\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4288 - accuracy: 0.8283\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4332 - accuracy: 0.8249\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4235 - accuracy: 0.8238\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4446 - accuracy: 0.8148\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4287 - accuracy: 0.8159\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4227 - accuracy: 0.8283\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4181 - accuracy: 0.8316\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4406 - accuracy: 0.8036\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4339 - accuracy: 0.8294\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4433 - accuracy: 0.8025\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4289 - accuracy: 0.8148\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4183 - accuracy: 0.8182\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4147 - accuracy: 0.8395\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4139 - accuracy: 0.8316\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4457 - accuracy: 0.8171\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4164 - accuracy: 0.8249\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4414 - accuracy: 0.8182\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4396 - accuracy: 0.8171\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4382 - accuracy: 0.8193\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4262 - accuracy: 0.8070\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4426 - accuracy: 0.8148\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4105 - accuracy: 0.8316\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4261 - accuracy: 0.8148\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4318 - accuracy: 0.8193\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.4271 - accuracy: 0.8238\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.82 - 0s 292us/step - loss: 0.4233 - accuracy: 0.8260\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4330 - accuracy: 0.8126\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4271 - accuracy: 0.8238\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4194 - accuracy: 0.8406\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4211 - accuracy: 0.8316\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4339 - accuracy: 0.8238\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4135 - accuracy: 0.8395\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4380 - accuracy: 0.8114\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4233 - accuracy: 0.8215\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4303 - accuracy: 0.8193\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4302 - accuracy: 0.8204\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4271 - accuracy: 0.8272\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4181 - accuracy: 0.8294\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4192 - accuracy: 0.8305\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4034 - accuracy: 0.8418\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4278 - accuracy: 0.8294\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4291 - accuracy: 0.8283\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4413 - accuracy: 0.8171\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4146 - accuracy: 0.8350\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4182 - accuracy: 0.8227\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4089 - accuracy: 0.8350\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4288 - accuracy: 0.8215\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4096 - accuracy: 0.8283\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4342 - accuracy: 0.8260\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4317 - accuracy: 0.8204\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4388 - accuracy: 0.8182\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4190 - accuracy: 0.8272\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4125 - accuracy: 0.8373\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4213 - accuracy: 0.8305\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.4123 - accuracy: 0.8294\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4011 - accuracy: 0.8384\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4166 - accuracy: 0.8384\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4002 - accuracy: 0.8429\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4225 - accuracy: 0.8171\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.4231 - accuracy: 0.8182\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4257 - accuracy: 0.8215\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 284us/step - loss: 0.4453 - accuracy: 0.8171\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.4134 - accuracy: 0.8283\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4322 - accuracy: 0.8249\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.4193 - accuracy: 0.8294\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4116 - accuracy: 0.8294\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4139 - accuracy: 0.8272\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4353 - accuracy: 0.8171\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4176 - accuracy: 0.8249\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4324 - accuracy: 0.8182\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.4180 - accuracy: 0.8294\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 420us/step - loss: 0.4030 - accuracy: 0.8339\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.4218 - accuracy: 0.8204\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 439us/step - loss: 0.4190 - accuracy: 0.8305\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 406us/step - loss: 0.4081 - accuracy: 0.8316\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 535us/step - loss: 0.4279 - accuracy: 0.8272\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4367 - accuracy: 0.8171\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4323 - accuracy: 0.8249\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4209 - accuracy: 0.8249\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4135 - accuracy: 0.8283\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4070 - accuracy: 0.8373\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4107 - accuracy: 0.8316\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4073 - accuracy: 0.8294\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4161 - accuracy: 0.8249\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4056 - accuracy: 0.8316\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4148 - accuracy: 0.8361\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 283us/step - loss: 0.4238 - accuracy: 0.8171\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 286us/step - loss: 0.4129 - accuracy: 0.8328\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 281us/step - loss: 0.4361 - accuracy: 0.8159\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4087 - accuracy: 0.8249\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4223 - accuracy: 0.8316\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4156 - accuracy: 0.8373\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4106 - accuracy: 0.8350\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 384us/step - loss: 0.4200 - accuracy: 0.8283\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4038 - accuracy: 0.8406\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.4108 - accuracy: 0.8316\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4067 - accuracy: 0.8305\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4307 - accuracy: 0.8215\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4300 - accuracy: 0.8159\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4054 - accuracy: 0.8328\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4250 - accuracy: 0.8294\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4093 - accuracy: 0.8373\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4209 - accuracy: 0.8249\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4164 - accuracy: 0.8350\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.4191 - accuracy: 0.8418\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4018 - accuracy: 0.8429\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 349us/step - loss: 0.4161 - accuracy: 0.8260\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4312 - accuracy: 0.8238\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4174 - accuracy: 0.8238\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4303 - accuracy: 0.8159\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4004 - accuracy: 0.8395\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4049 - accuracy: 0.8238\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4143 - accuracy: 0.8260\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4288 - accuracy: 0.8193\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4268 - accuracy: 0.8227\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4120 - accuracy: 0.8215\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4067 - accuracy: 0.8294\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.3963 - accuracy: 0.8305\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4207 - accuracy: 0.8316\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4158 - accuracy: 0.8316\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4067 - accuracy: 0.8406\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 402us/step - loss: 0.4197 - accuracy: 0.8328\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 404us/step - loss: 0.4133 - accuracy: 0.8384\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.3971 - accuracy: 0.8440\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4328 - accuracy: 0.8182\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4165 - accuracy: 0.8384\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4149 - accuracy: 0.8328\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 333us/step - loss: 0.4319 - accuracy: 0.8249\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.4329 - accuracy: 0.8114\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.4225 - accuracy: 0.8395\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4146 - accuracy: 0.8294\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4158 - accuracy: 0.8305\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.3869 - accuracy: 0.8597\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4101 - accuracy: 0.8260\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4073 - accuracy: 0.8361\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.3942 - accuracy: 0.8507\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.3853 - accuracy: 0.8451\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4037 - accuracy: 0.8238\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4224 - accuracy: 0.8272\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4164 - accuracy: 0.8215\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4036 - accuracy: 0.8328\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.4187 - accuracy: 0.8260\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4216 - accuracy: 0.8260\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4009 - accuracy: 0.8305\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4247 - accuracy: 0.8215\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.4116 - accuracy: 0.8272\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4091 - accuracy: 0.8373\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4322 - accuracy: 0.8339\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3915 - accuracy: 0.8474\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4086 - accuracy: 0.8350\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4090 - accuracy: 0.8193\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4077 - accuracy: 0.8316\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 312us/step - loss: 0.4000 - accuracy: 0.8339\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.3916 - accuracy: 0.8373\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4129 - accuracy: 0.8395\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4270 - accuracy: 0.8171\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.4155 - accuracy: 0.8272\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4066 - accuracy: 0.8350\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4155 - accuracy: 0.8294\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4215 - accuracy: 0.8272\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.3979 - accuracy: 0.8406\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.4225 - accuracy: 0.8171\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4067 - accuracy: 0.8395\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.3965 - accuracy: 0.8339\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 285us/step - loss: 0.4121 - accuracy: 0.8238\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4013 - accuracy: 0.8227\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 291us/step - loss: 0.4097 - accuracy: 0.8283\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.4004 - accuracy: 0.8384\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.4402 - accuracy: 0.8114\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4248 - accuracy: 0.8316\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.4187 - accuracy: 0.8272\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.3991 - accuracy: 0.8305\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.3979 - accuracy: 0.8361\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4228 - accuracy: 0.8204\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4182 - accuracy: 0.8305\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4035 - accuracy: 0.8328\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4101 - accuracy: 0.8339\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4167 - accuracy: 0.8227\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4091 - accuracy: 0.8373\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4000 - accuracy: 0.8384\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4100 - accuracy: 0.8328\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4036 - accuracy: 0.8395\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4179 - accuracy: 0.8339\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4043 - accuracy: 0.8361\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4235 - accuracy: 0.8193\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.3903 - accuracy: 0.8283\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4043 - accuracy: 0.8305\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4015 - accuracy: 0.8272\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4035 - accuracy: 0.8350\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4001 - accuracy: 0.8418\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.3985 - accuracy: 0.8418\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3971 - accuracy: 0.8316\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4061 - accuracy: 0.8384\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4210 - accuracy: 0.8339\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.3959 - accuracy: 0.8474\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4257 - accuracy: 0.8350\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4192 - accuracy: 0.8215\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4053 - accuracy: 0.8361\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4092 - accuracy: 0.8373\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4062 - accuracy: 0.8305\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.3896 - accuracy: 0.8440\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4535 - accuracy: 0.7957\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4147 - accuracy: 0.8361\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 305us/step - loss: 0.4076 - accuracy: 0.8305\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4050 - accuracy: 0.8429\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4069 - accuracy: 0.8361\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 349us/step - loss: 0.4025 - accuracy: 0.8429\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4054 - accuracy: 0.8294\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4046 - accuracy: 0.8316\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4030 - accuracy: 0.8395\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.4060 - accuracy: 0.8328\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 306us/step - loss: 0.4148 - accuracy: 0.8350\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 302us/step - loss: 0.4055 - accuracy: 0.8339\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 307us/step - loss: 0.3962 - accuracy: 0.8328\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.3868 - accuracy: 0.8418\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 300us/step - loss: 0.4088 - accuracy: 0.8238\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 296us/step - loss: 0.4201 - accuracy: 0.8283\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4057 - accuracy: 0.8361\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4027 - accuracy: 0.8406\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.4130 - accuracy: 0.8294\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3977 - accuracy: 0.8305\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.4115 - accuracy: 0.8328\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 435us/step - loss: 0.4208 - accuracy: 0.8294\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 389us/step - loss: 0.4163 - accuracy: 0.8249\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.4104 - accuracy: 0.8260\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.4045 - accuracy: 0.8328\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 394us/step - loss: 0.4091 - accuracy: 0.8283\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 315us/step - loss: 0.4048 - accuracy: 0.8418\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4003 - accuracy: 0.8339\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4064 - accuracy: 0.8305\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 311us/step - loss: 0.4012 - accuracy: 0.8272\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3918 - accuracy: 0.8406\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 387us/step - loss: 0.4027 - accuracy: 0.8373\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.4049 - accuracy: 0.8350\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4094 - accuracy: 0.8361\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3981 - accuracy: 0.8339\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.4104 - accuracy: 0.8294\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4252 - accuracy: 0.8350\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 384us/step - loss: 0.4116 - accuracy: 0.8384\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 386us/step - loss: 0.4101 - accuracy: 0.8249\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 520us/step - loss: 0.4000 - accuracy: 0.8373\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 374us/step - loss: 0.4028 - accuracy: 0.8316\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4211 - accuracy: 0.8283\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4053 - accuracy: 0.8294\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3975 - accuracy: 0.8429\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4060 - accuracy: 0.8316\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.3831 - accuracy: 0.8406\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.4139 - accuracy: 0.8260\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.4057 - accuracy: 0.8283\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4263 - accuracy: 0.8249\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 316us/step - loss: 0.4318 - accuracy: 0.8238\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4044 - accuracy: 0.8384\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3897 - accuracy: 0.8373\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4036 - accuracy: 0.8395\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.4196 - accuracy: 0.8227\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4192 - accuracy: 0.8204\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.4018 - accuracy: 0.8350\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 368us/step - loss: 0.3989 - accuracy: 0.8350\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 375us/step - loss: 0.4039 - accuracy: 0.8373\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3950 - accuracy: 0.8373\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.3917 - accuracy: 0.8373\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 288us/step - loss: 0.4145 - accuracy: 0.8227\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.3924 - accuracy: 0.8406\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4075 - accuracy: 0.8227\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 374us/step - loss: 0.3997 - accuracy: 0.8305\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 382us/step - loss: 0.4081 - accuracy: 0.8316\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 451us/step - loss: 0.4141 - accuracy: 0.8339\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4056 - accuracy: 0.8272\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4065 - accuracy: 0.8373\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3903 - accuracy: 0.8474\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4099 - accuracy: 0.8260\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 386us/step - loss: 0.3933 - accuracy: 0.8316\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4045 - accuracy: 0.8283\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4142 - accuracy: 0.8328\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 309us/step - loss: 0.3982 - accuracy: 0.8384\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4004 - accuracy: 0.8294\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 313us/step - loss: 0.4005 - accuracy: 0.8373\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4035 - accuracy: 0.8406\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4149 - accuracy: 0.8260\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 308us/step - loss: 0.4042 - accuracy: 0.8316\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4095 - accuracy: 0.8361\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.4085 - accuracy: 0.8406\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4118 - accuracy: 0.8283\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 318us/step - loss: 0.4012 - accuracy: 0.8294\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 293us/step - loss: 0.4008 - accuracy: 0.8294\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 298us/step - loss: 0.3965 - accuracy: 0.8418\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 304us/step - loss: 0.3830 - accuracy: 0.8440\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3787 - accuracy: 0.8496\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3820 - accuracy: 0.8462\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 297us/step - loss: 0.4020 - accuracy: 0.8373\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 294us/step - loss: 0.3974 - accuracy: 0.8418\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 289us/step - loss: 0.4084 - accuracy: 0.8260\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 292us/step - loss: 0.4122 - accuracy: 0.8328\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 100, 1\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 3s 15ms/step - loss: 0.7751 - accuracy: 0.4607\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.6525 - accuracy: 0.6742\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.6611 - accuracy: 0.6573\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.6298 - accuracy: 0.6629\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 263us/step - loss: 0.6338 - accuracy: 0.6685\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.6069 - accuracy: 0.6966\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.5841 - accuracy: 0.6461\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.6106 - accuracy: 0.6517\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.5729 - accuracy: 0.6742\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.5774 - accuracy: 0.7360\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.5745 - accuracy: 0.6685\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.5709 - accuracy: 0.7247\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.5723 - accuracy: 0.7191\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.5297 - accuracy: 0.7528\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.5376 - accuracy: 0.7584\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.5824 - accuracy: 0.7247\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.5147 - accuracy: 0.7697\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.5423 - accuracy: 0.7528\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.5395 - accuracy: 0.7809\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.5445 - accuracy: 0.7472\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 288us/step - loss: 0.5006 - accuracy: 0.7584\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.5199 - accuracy: 0.7584\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 281us/step - loss: 0.5428 - accuracy: 0.7472\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4991 - accuracy: 0.7640\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.5052 - accuracy: 0.7640\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.4956 - accuracy: 0.7697\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.5123 - accuracy: 0.7697\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.4991 - accuracy: 0.7584\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.5661 - accuracy: 0.7472\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.5381 - accuracy: 0.7640\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 259us/step - loss: 0.5035 - accuracy: 0.7753\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.5118 - accuracy: 0.7416\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 259us/step - loss: 0.5100 - accuracy: 0.7472\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.5203 - accuracy: 0.7584\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4666 - accuracy: 0.7809\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.5158 - accuracy: 0.7697\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.4483 - accuracy: 0.8202\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.5016 - accuracy: 0.7697\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4664 - accuracy: 0.8146\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4888 - accuracy: 0.7921\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 290us/step - loss: 0.5130 - accuracy: 0.7472\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4742 - accuracy: 0.7809\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.4662 - accuracy: 0.8202\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.5217 - accuracy: 0.7640\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.5261 - accuracy: 0.7978\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.5120 - accuracy: 0.7697\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.4937 - accuracy: 0.7921\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.5104 - accuracy: 0.7640\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4280 - accuracy: 0.8202\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4634 - accuracy: 0.8258\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.5017 - accuracy: 0.7865\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4689 - accuracy: 0.8090\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4415 - accuracy: 0.7978\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4709 - accuracy: 0.7865\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4362 - accuracy: 0.8315\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.5116 - accuracy: 0.7921\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4573 - accuracy: 0.7921\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4350 - accuracy: 0.8371\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.4659 - accuracy: 0.8034\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 275us/step - loss: 0.5021 - accuracy: 0.7697\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4705 - accuracy: 0.8034\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.4954 - accuracy: 0.7697\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4499 - accuracy: 0.7865\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.4822 - accuracy: 0.7809\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.5184 - accuracy: 0.7809\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.4524 - accuracy: 0.8146\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4526 - accuracy: 0.7921\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.4811 - accuracy: 0.8090\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.4857 - accuracy: 0.7865\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.5046 - accuracy: 0.7753\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 269us/step - loss: 0.4889 - accuracy: 0.7697\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.4278 - accuracy: 0.8146\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 274us/step - loss: 0.4897 - accuracy: 0.7809\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4269 - accuracy: 0.7865\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.4573 - accuracy: 0.8090\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.4530 - accuracy: 0.8090\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.4283 - accuracy: 0.8146\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.4477 - accuracy: 0.8034\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 263us/step - loss: 0.4588 - accuracy: 0.7978\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4194 - accuracy: 0.8315\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4851 - accuracy: 0.7697\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4905 - accuracy: 0.7809\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4611 - accuracy: 0.8146\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4721 - accuracy: 0.7978\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4457 - accuracy: 0.8202\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4632 - accuracy: 0.8090\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4269 - accuracy: 0.8090\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4712 - accuracy: 0.7921\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4740 - accuracy: 0.7978\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4520 - accuracy: 0.7978\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4421 - accuracy: 0.7921\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.4393 - accuracy: 0.8146\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4199 - accuracy: 0.7865\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.4314 - accuracy: 0.8034\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4483 - accuracy: 0.8371\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4430 - accuracy: 0.8258\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4679 - accuracy: 0.8090\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4385 - accuracy: 0.8202\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4319 - accuracy: 0.7921\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4479 - accuracy: 0.8090\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4381 - accuracy: 0.8146\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4137 - accuracy: 0.8539\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4486 - accuracy: 0.8090\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4684 - accuracy: 0.7584\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4036 - accuracy: 0.8315\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4771 - accuracy: 0.7809\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 224us/step - loss: 0.4308 - accuracy: 0.8371\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4841 - accuracy: 0.7528\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4668 - accuracy: 0.8090\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4394 - accuracy: 0.8146\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.4657 - accuracy: 0.7978\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4549 - accuracy: 0.8034\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4034 - accuracy: 0.8258\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4447 - accuracy: 0.7809\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4012 - accuracy: 0.8202\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4203 - accuracy: 0.8315\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4366 - accuracy: 0.8427\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4335 - accuracy: 0.7921\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4172 - accuracy: 0.8202\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.4097 - accuracy: 0.7978\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4208 - accuracy: 0.8202\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4357 - accuracy: 0.8034\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4348 - accuracy: 0.8034\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4687 - accuracy: 0.7978\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.4463 - accuracy: 0.8146\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 295us/step - loss: 0.4071 - accuracy: 0.8371\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.4510 - accuracy: 0.7978\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.4761 - accuracy: 0.7753\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 296us/step - loss: 0.4588 - accuracy: 0.7865\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.4254 - accuracy: 0.8315\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4632 - accuracy: 0.7865\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4159 - accuracy: 0.8258\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4319 - accuracy: 0.7978\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.4315 - accuracy: 0.7865\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4477 - accuracy: 0.8258\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4461 - accuracy: 0.8146\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 227us/step - loss: 0.4561 - accuracy: 0.8090\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4200 - accuracy: 0.8090\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4428 - accuracy: 0.7978\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 231us/step - loss: 0.4302 - accuracy: 0.8315\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.4564 - accuracy: 0.8090\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3663 - accuracy: 0.8652\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 232us/step - loss: 0.3647 - accuracy: 0.8652\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 230us/step - loss: 0.4088 - accuracy: 0.8034\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4272 - accuracy: 0.8146\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 229us/step - loss: 0.4238 - accuracy: 0.8146\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 228us/step - loss: 0.4184 - accuracy: 0.8258\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4017 - accuracy: 0.8202\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 258us/step - loss: 0.4515 - accuracy: 0.8258\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.4444 - accuracy: 0.8258\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.4524 - accuracy: 0.8034\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4464 - accuracy: 0.7978\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4054 - accuracy: 0.8146\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4131 - accuracy: 0.8258\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4240 - accuracy: 0.8202\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4501 - accuracy: 0.8146\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 243us/step - loss: 0.4015 - accuracy: 0.8371\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4213 - accuracy: 0.8315\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4802 - accuracy: 0.7865\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4391 - accuracy: 0.8258\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3870 - accuracy: 0.8258\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.4088 - accuracy: 0.8146\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4081 - accuracy: 0.8315\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4092 - accuracy: 0.8483\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4265 - accuracy: 0.8315\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.4369 - accuracy: 0.7978\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3947 - accuracy: 0.8427\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3739 - accuracy: 0.8427\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4588 - accuracy: 0.8427\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.4137 - accuracy: 0.8315\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4105 - accuracy: 0.8202\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3714 - accuracy: 0.8427\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4344 - accuracy: 0.8202\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4068 - accuracy: 0.8258\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4166 - accuracy: 0.8315\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4245 - accuracy: 0.8146\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3755 - accuracy: 0.8483\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4495 - accuracy: 0.8146\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4092 - accuracy: 0.8258\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4520 - accuracy: 0.8090\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4190 - accuracy: 0.8652\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4197 - accuracy: 0.8258\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4197 - accuracy: 0.8371\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4034 - accuracy: 0.8371\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3916 - accuracy: 0.8371\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4401 - accuracy: 0.7865\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4185 - accuracy: 0.8202\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3913 - accuracy: 0.8596\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4313 - accuracy: 0.8258\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4084 - accuracy: 0.8371\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4047 - accuracy: 0.8371\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4241 - accuracy: 0.8258\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3924 - accuracy: 0.8427\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4181 - accuracy: 0.8483\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4406 - accuracy: 0.7865\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4622 - accuracy: 0.8146\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.4211 - accuracy: 0.8371\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.4190 - accuracy: 0.8315\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 259us/step - loss: 0.4287 - accuracy: 0.8258\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4190 - accuracy: 0.8258\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 260us/step - loss: 0.4381 - accuracy: 0.8315\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4131 - accuracy: 0.8371\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.4447 - accuracy: 0.7978\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3814 - accuracy: 0.8371\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.4129 - accuracy: 0.8315\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 255us/step - loss: 0.4502 - accuracy: 0.7921\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.3670 - accuracy: 0.8427\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3906 - accuracy: 0.8483\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3802 - accuracy: 0.8539\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 287us/step - loss: 0.3797 - accuracy: 0.8258\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4504 - accuracy: 0.8146\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.4159 - accuracy: 0.8371\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4272 - accuracy: 0.8202\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 266us/step - loss: 0.3995 - accuracy: 0.8090\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.4491 - accuracy: 0.8090\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.4124 - accuracy: 0.8146\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.4237 - accuracy: 0.8258\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.4521 - accuracy: 0.8202\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.4217 - accuracy: 0.8034\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4159 - accuracy: 0.8371\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 255us/step - loss: 0.4197 - accuracy: 0.8202\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4181 - accuracy: 0.8315\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.4183 - accuracy: 0.8034\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 273us/step - loss: 0.4101 - accuracy: 0.8258\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.3885 - accuracy: 0.8596\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 261us/step - loss: 0.4000 - accuracy: 0.8315\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3749 - accuracy: 0.8764\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.4178 - accuracy: 0.8427\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4154 - accuracy: 0.8315\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3875 - accuracy: 0.8258\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.4016 - accuracy: 0.8427\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 265us/step - loss: 0.4353 - accuracy: 0.8202\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 277us/step - loss: 0.3999 - accuracy: 0.8483\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.4062 - accuracy: 0.8315\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 264us/step - loss: 0.3648 - accuracy: 0.8596\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 262us/step - loss: 0.3710 - accuracy: 0.8427\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.4237 - accuracy: 0.8258\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.4122 - accuracy: 0.8315\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.4086 - accuracy: 0.8483\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4381 - accuracy: 0.8315\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3854 - accuracy: 0.8539\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4028 - accuracy: 0.8146\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3840 - accuracy: 0.8371\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3621 - accuracy: 0.8539\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3788 - accuracy: 0.8539\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.4153 - accuracy: 0.8258\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4027 - accuracy: 0.8202\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.4557 - accuracy: 0.8034\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3946 - accuracy: 0.8596\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3893 - accuracy: 0.8371\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4266 - accuracy: 0.8258\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4305 - accuracy: 0.8090\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.4451 - accuracy: 0.8090\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.3898 - accuracy: 0.8483\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3935 - accuracy: 0.8539\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.4119 - accuracy: 0.8090\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4190 - accuracy: 0.8146\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3798 - accuracy: 0.8539\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4196 - accuracy: 0.8371\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3841 - accuracy: 0.8596\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3969 - accuracy: 0.8596\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4023 - accuracy: 0.8315\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4119 - accuracy: 0.8427\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.4383 - accuracy: 0.8202\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3706 - accuracy: 0.8315\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.4409 - accuracy: 0.7921\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4468 - accuracy: 0.8146\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3724 - accuracy: 0.8596\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.4219 - accuracy: 0.8146\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3581 - accuracy: 0.8708\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4455 - accuracy: 0.8034\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3885 - accuracy: 0.8539\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4141 - accuracy: 0.8427\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4184 - accuracy: 0.8258\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3840 - accuracy: 0.8371\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4016 - accuracy: 0.7978\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3886 - accuracy: 0.8539\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3873 - accuracy: 0.8315\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3972 - accuracy: 0.8539\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.3912 - accuracy: 0.8315\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4053 - accuracy: 0.8371\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3870 - accuracy: 0.8202\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4146 - accuracy: 0.8258\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3694 - accuracy: 0.8371\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3914 - accuracy: 0.8202\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.4157 - accuracy: 0.8090\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4079 - accuracy: 0.8202\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3894 - accuracy: 0.8202\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3889 - accuracy: 0.8427\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3851 - accuracy: 0.8202\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3874 - accuracy: 0.8483\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.3950 - accuracy: 0.8315\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.4120 - accuracy: 0.8202\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3965 - accuracy: 0.8539\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 263us/step - loss: 0.3992 - accuracy: 0.8315\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 256us/step - loss: 0.4089 - accuracy: 0.8371\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3810 - accuracy: 0.8315\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3968 - accuracy: 0.8371\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3936 - accuracy: 0.8596\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3667 - accuracy: 0.8652\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.4022 - accuracy: 0.8539\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.4153 - accuracy: 0.8371\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3851 - accuracy: 0.8539\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3936 - accuracy: 0.8202\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3952 - accuracy: 0.8371\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.3777 - accuracy: 0.8483\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3749 - accuracy: 0.8315\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3749 - accuracy: 0.8371\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3657 - accuracy: 0.8764\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3447 - accuracy: 0.8596\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3883 - accuracy: 0.8315\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4145 - accuracy: 0.8146\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 242us/step - loss: 0.4366 - accuracy: 0.8146\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 233us/step - loss: 0.3977 - accuracy: 0.8090\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3576 - accuracy: 0.8539\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.3984 - accuracy: 0.8371\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 236us/step - loss: 0.3973 - accuracy: 0.8202\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3983 - accuracy: 0.8315\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3874 - accuracy: 0.8371\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 235us/step - loss: 0.3819 - accuracy: 0.8427\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3995 - accuracy: 0.8258\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4232 - accuracy: 0.8371\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3445 - accuracy: 0.8764\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.4072 - accuracy: 0.8258\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3974 - accuracy: 0.8427\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3697 - accuracy: 0.8427\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.3942 - accuracy: 0.8315\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3654 - accuracy: 0.8483\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3590 - accuracy: 0.8596\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3542 - accuracy: 0.8315\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3948 - accuracy: 0.8427\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3409 - accuracy: 0.8652\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3796 - accuracy: 0.8371\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4418 - accuracy: 0.8371\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3766 - accuracy: 0.8539\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.4018 - accuracy: 0.8202\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3774 - accuracy: 0.8427\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3665 - accuracy: 0.8596\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3737 - accuracy: 0.8596\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3978 - accuracy: 0.8202\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.4108 - accuracy: 0.8539\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3949 - accuracy: 0.8371\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 249us/step - loss: 0.3675 - accuracy: 0.8764\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.4004 - accuracy: 0.8371\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3819 - accuracy: 0.8483\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4076 - accuracy: 0.8315\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3971 - accuracy: 0.8427\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3570 - accuracy: 0.8596\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3884 - accuracy: 0.8202\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3821 - accuracy: 0.8371\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3296 - accuracy: 0.8652\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 272us/step - loss: 0.3698 - accuracy: 0.8596\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.3664 - accuracy: 0.8427\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 254us/step - loss: 0.3624 - accuracy: 0.8427\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3864 - accuracy: 0.8427\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3652 - accuracy: 0.8427\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 234us/step - loss: 0.3811 - accuracy: 0.8596\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3824 - accuracy: 0.8371\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4286 - accuracy: 0.8146\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.3680 - accuracy: 0.8427\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 268us/step - loss: 0.3855 - accuracy: 0.8652\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 299us/step - loss: 0.4001 - accuracy: 0.8371\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 239us/step - loss: 0.3657 - accuracy: 0.8652\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 245us/step - loss: 0.3606 - accuracy: 0.8427\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 240us/step - loss: 0.3556 - accuracy: 0.8483\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 252us/step - loss: 0.3986 - accuracy: 0.8371\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 292us/step - loss: 0.3460 - accuracy: 0.8539\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.3718 - accuracy: 0.8258\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 258us/step - loss: 0.3646 - accuracy: 0.8427\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 257us/step - loss: 0.4172 - accuracy: 0.8371\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4064 - accuracy: 0.8315\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3546 - accuracy: 0.8539\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 237us/step - loss: 0.3454 - accuracy: 0.8539\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.4120 - accuracy: 0.8258\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 395us/step - loss: 0.3774 - accuracy: 0.8539\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 588us/step - loss: 0.3968 - accuracy: 0.8258\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 396us/step - loss: 0.3831 - accuracy: 0.8258\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.4038 - accuracy: 0.7809\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3963 - accuracy: 0.8539\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 238us/step - loss: 0.4042 - accuracy: 0.8202\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 243us/step - loss: 0.3844 - accuracy: 0.8483\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 247us/step - loss: 0.3490 - accuracy: 0.8483\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 270us/step - loss: 0.3182 - accuracy: 0.8708\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 242us/step - loss: 0.4093 - accuracy: 0.8427\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.3327 - accuracy: 0.8596\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3634 - accuracy: 0.8202\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3690 - accuracy: 0.8596\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 241us/step - loss: 0.3536 - accuracy: 0.8596\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3511 - accuracy: 0.8315\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 253us/step - loss: 0.3670 - accuracy: 0.8258\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 251us/step - loss: 0.4205 - accuracy: 0.8315\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 276us/step - loss: 0.3786 - accuracy: 0.8427\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 248us/step - loss: 0.4046 - accuracy: 0.8202\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 244us/step - loss: 0.3419 - accuracy: 0.8596\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 250us/step - loss: 0.3711 - accuracy: 0.8371\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 282us/step - loss: 0.3593 - accuracy: 0.8483\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 267us/step - loss: 0.3638 - accuracy: 0.8371\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 286us/step - loss: 0.4086 - accuracy: 0.8258\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 246us/step - loss: 0.3584 - accuracy: 0.8652\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.3491 - accuracy: 0.8652\n",
      "713/713 [==============================] - 1s 840us/step\n",
      "Epoch 1/400\n",
      "690/891 [======================>.......] - ETA: 0s - loss: 0.4603 - accuracy: 0.8087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 245us/step - loss: 0.4770 - accuracy: 0.7991\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.4642 - accuracy: 0.7912\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4346 - accuracy: 0.7957\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4508 - accuracy: 0.8114\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4571 - accuracy: 0.7946\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4299 - accuracy: 0.8137\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 287us/step - loss: 0.4345 - accuracy: 0.8047\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4448 - accuracy: 0.8070\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 265us/step - loss: 0.4457 - accuracy: 0.8025\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.4545 - accuracy: 0.8036\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 295us/step - loss: 0.4301 - accuracy: 0.8182\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.4239 - accuracy: 0.8272\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4360 - accuracy: 0.8070\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4461 - accuracy: 0.8081\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4370 - accuracy: 0.8193\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 303us/step - loss: 0.4370 - accuracy: 0.8092\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4292 - accuracy: 0.8103\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 272us/step - loss: 0.4355 - accuracy: 0.8137\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.4410 - accuracy: 0.8126\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4241 - accuracy: 0.8193\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.4355 - accuracy: 0.8137\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.4227 - accuracy: 0.8182\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.4432 - accuracy: 0.8047\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4359 - accuracy: 0.8103\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 290us/step - loss: 0.4465 - accuracy: 0.8092\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4337 - accuracy: 0.8126\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4346 - accuracy: 0.8171\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4322 - accuracy: 0.8070\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4360 - accuracy: 0.8260\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 264us/step - loss: 0.4173 - accuracy: 0.8294\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4245 - accuracy: 0.8148\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4072 - accuracy: 0.8339\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4246 - accuracy: 0.8193\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4432 - accuracy: 0.8171\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4583 - accuracy: 0.7969\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4335 - accuracy: 0.8182\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4213 - accuracy: 0.8204\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4438 - accuracy: 0.8137\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4363 - accuracy: 0.8103\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4284 - accuracy: 0.8215\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4089 - accuracy: 0.8294\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4284 - accuracy: 0.8126\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4366 - accuracy: 0.8148\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4173 - accuracy: 0.8316\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.4412 - accuracy: 0.8137\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4294 - accuracy: 0.8171\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4163 - accuracy: 0.8215\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4198 - accuracy: 0.8249\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4214 - accuracy: 0.8294\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4410 - accuracy: 0.8103\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4185 - accuracy: 0.8272\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4217 - accuracy: 0.8171\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4167 - accuracy: 0.8204\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4416 - accuracy: 0.8126\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4224 - accuracy: 0.8249\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4165 - accuracy: 0.8159\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4214 - accuracy: 0.8283\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4220 - accuracy: 0.8238\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4347 - accuracy: 0.8294\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4269 - accuracy: 0.8193\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4191 - accuracy: 0.8249\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.4339 - accuracy: 0.8159\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.4170 - accuracy: 0.8227\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4291 - accuracy: 0.8182\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4160 - accuracy: 0.8227\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4183 - accuracy: 0.8339\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4135 - accuracy: 0.8328\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 310us/step - loss: 0.4102 - accuracy: 0.8159\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 257us/step - loss: 0.4351 - accuracy: 0.8137\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.4184 - accuracy: 0.8305\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.4186 - accuracy: 0.8227\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4121 - accuracy: 0.8204\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4215 - accuracy: 0.8215\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4184 - accuracy: 0.8148\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4140 - accuracy: 0.8215\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4103 - accuracy: 0.8215\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4256 - accuracy: 0.8182\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4084 - accuracy: 0.8238\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4067 - accuracy: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4212 - accuracy: 0.8159\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4220 - accuracy: 0.8215\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4318 - accuracy: 0.8171\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4279 - accuracy: 0.8137\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4208 - accuracy: 0.8316\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4094 - accuracy: 0.8260\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4214 - accuracy: 0.8361\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4194 - accuracy: 0.8159\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4258 - accuracy: 0.8294\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4276 - accuracy: 0.8294\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.4152 - accuracy: 0.8350\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4314 - accuracy: 0.8193\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4168 - accuracy: 0.8272\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4055 - accuracy: 0.8294\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4180 - accuracy: 0.8339\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4233 - accuracy: 0.8193\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4185 - accuracy: 0.8227\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4088 - accuracy: 0.8339\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4225 - accuracy: 0.8193\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4189 - accuracy: 0.8339\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4123 - accuracy: 0.8294\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3999 - accuracy: 0.8272\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4014 - accuracy: 0.8384\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4160 - accuracy: 0.8294\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4136 - accuracy: 0.8339\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4028 - accuracy: 0.8440\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4124 - accuracy: 0.8272\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4010 - accuracy: 0.8283\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4012 - accuracy: 0.8260\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4075 - accuracy: 0.8294\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4245 - accuracy: 0.8215\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3966 - accuracy: 0.8305\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4188 - accuracy: 0.8114\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4038 - accuracy: 0.8373\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4301 - accuracy: 0.8182\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4112 - accuracy: 0.8316\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4182 - accuracy: 0.8260\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4163 - accuracy: 0.8204\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.4140 - accuracy: 0.8294\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4156 - accuracy: 0.82270s - loss: 0.4203 - accuracy: \n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3991 - accuracy: 0.8429\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4074 - accuracy: 0.8316\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4037 - accuracy: 0.8350\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3998 - accuracy: 0.8384\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4117 - accuracy: 0.8260\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4064 - accuracy: 0.8204\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4165 - accuracy: 0.8272\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4150 - accuracy: 0.8283\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4282 - accuracy: 0.8137\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3945 - accuracy: 0.8373\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3973 - accuracy: 0.8227\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4099 - accuracy: 0.8350\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4078 - accuracy: 0.8395\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 279us/step - loss: 0.3984 - accuracy: 0.8361\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4016 - accuracy: 0.8294\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3954 - accuracy: 0.8328\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4112 - accuracy: 0.8193\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4280 - accuracy: 0.8159\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.4066 - accuracy: 0.8260\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3961 - accuracy: 0.8350\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4115 - accuracy: 0.8305\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.4029 - accuracy: 0.8339\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3970 - accuracy: 0.8339\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3959 - accuracy: 0.8316\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4029 - accuracy: 0.8339\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4072 - accuracy: 0.8305\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3959 - accuracy: 0.8440\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3908 - accuracy: 0.8361\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4054 - accuracy: 0.8272\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4085 - accuracy: 0.8350\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4144 - accuracy: 0.8316\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4037 - accuracy: 0.8328\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3972 - accuracy: 0.8406\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4198 - accuracy: 0.8384\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4198 - accuracy: 0.8182\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4096 - accuracy: 0.8283\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4212 - accuracy: 0.8114\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4080 - accuracy: 0.8294\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4004 - accuracy: 0.8373\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3872 - accuracy: 0.8395\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4220 - accuracy: 0.8193\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4102 - accuracy: 0.8328\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4190 - accuracy: 0.8182\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4034 - accuracy: 0.8328\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4026 - accuracy: 0.8384\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3971 - accuracy: 0.8361\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3911 - accuracy: 0.8384\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3945 - accuracy: 0.8260\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4129 - accuracy: 0.8272\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.4095 - accuracy: 0.8406\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4069 - accuracy: 0.8294\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3985 - accuracy: 0.8395\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3941 - accuracy: 0.8474\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.4049 - accuracy: 0.8361\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3854 - accuracy: 0.8429\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4267 - accuracy: 0.8204\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3978 - accuracy: 0.8361\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3897 - accuracy: 0.8373\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3914 - accuracy: 0.8485\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3853 - accuracy: 0.8395\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3849 - accuracy: 0.8418\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4020 - accuracy: 0.8350\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3902 - accuracy: 0.8395\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3997 - accuracy: 0.8249\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3909 - accuracy: 0.8294\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4091 - accuracy: 0.8283\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4007 - accuracy: 0.8339\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3905 - accuracy: 0.8429\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4164 - accuracy: 0.8238\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4208 - accuracy: 0.8227\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4169 - accuracy: 0.8316\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.4031 - accuracy: 0.8350\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4212 - accuracy: 0.8305\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.4048 - accuracy: 0.8249\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4037 - accuracy: 0.8339\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3927 - accuracy: 0.8215\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3826 - accuracy: 0.8418\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4031 - accuracy: 0.8316\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4011 - accuracy: 0.8462\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4178 - accuracy: 0.8204\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3908 - accuracy: 0.8440\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3960 - accuracy: 0.8339\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3865 - accuracy: 0.8440\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3969 - accuracy: 0.8395\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3932 - accuracy: 0.8339\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4152 - accuracy: 0.8114\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3977 - accuracy: 0.8361\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4057 - accuracy: 0.8238\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3901 - accuracy: 0.8328\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4143 - accuracy: 0.8238\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3971 - accuracy: 0.8361\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3897 - accuracy: 0.8373\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3864 - accuracy: 0.8361\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4030 - accuracy: 0.8373\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3873 - accuracy: 0.8373\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3931 - accuracy: 0.8406\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4071 - accuracy: 0.8328\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3931 - accuracy: 0.8406\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3991 - accuracy: 0.8316\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.4070 - accuracy: 0.8148\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3902 - accuracy: 0.8339\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3751 - accuracy: 0.8294\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3997 - accuracy: 0.8260\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.4029 - accuracy: 0.8373\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.4049 - accuracy: 0.8283\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3914 - accuracy: 0.8328\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3747 - accuracy: 0.8507\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4082 - accuracy: 0.8227\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3911 - accuracy: 0.8339\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3855 - accuracy: 0.8496\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3906 - accuracy: 0.8429\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4010 - accuracy: 0.8272\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.4062 - accuracy: 0.8249\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.4059 - accuracy: 0.8238\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.4075 - accuracy: 0.8249\n",
      "Epoch 235/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 233us/step - loss: 0.3898 - accuracy: 0.8361\n",
      "Epoch 236/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4113 - accuracy: 0.8294\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4182 - accuracy: 0.8171\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3956 - accuracy: 0.8451\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3838 - accuracy: 0.8496\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3997 - accuracy: 0.8395\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3972 - accuracy: 0.8350\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3992 - accuracy: 0.8272\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3757 - accuracy: 0.8530\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3805 - accuracy: 0.8496\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4110 - accuracy: 0.8227\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3892 - accuracy: 0.8316\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4086 - accuracy: 0.8249\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4016 - accuracy: 0.8339\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 229us/step - loss: 0.3922 - accuracy: 0.8384\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3895 - accuracy: 0.8328\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3950 - accuracy: 0.8328\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3902 - accuracy: 0.8384\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3950 - accuracy: 0.8316\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.4022 - accuracy: 0.8350\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3894 - accuracy: 0.8350\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3972 - accuracy: 0.8395\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3876 - accuracy: 0.8462\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3967 - accuracy: 0.8316\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4128 - accuracy: 0.8204\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3681 - accuracy: 0.8496\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.4142 - accuracy: 0.8215\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3959 - accuracy: 0.8215\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4003 - accuracy: 0.8283\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3983 - accuracy: 0.8373\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4010 - accuracy: 0.8316\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3999 - accuracy: 0.8238\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3933 - accuracy: 0.8328\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.4068 - accuracy: 0.8361\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3894 - accuracy: 0.8339\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3774 - accuracy: 0.8474\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.4073 - accuracy: 0.8384\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3915 - accuracy: 0.8406\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.4015 - accuracy: 0.8227\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3962 - accuracy: 0.8339\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3968 - accuracy: 0.8328\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3842 - accuracy: 0.8316\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3859 - accuracy: 0.8373\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3974 - accuracy: 0.8373\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3935 - accuracy: 0.8316\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.4031 - accuracy: 0.8350\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3810 - accuracy: 0.8339\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3809 - accuracy: 0.8563\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3825 - accuracy: 0.8485\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 252us/step - loss: 0.3904 - accuracy: 0.8339\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3891 - accuracy: 0.8316\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.4061 - accuracy: 0.8339\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3751 - accuracy: 0.8418\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3801 - accuracy: 0.8316\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3893 - accuracy: 0.8451\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.4194 - accuracy: 0.8272\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3863 - accuracy: 0.8451\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3747 - accuracy: 0.8350\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3935 - accuracy: 0.8283\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.4053 - accuracy: 0.8339\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3832 - accuracy: 0.8418\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.3925 - accuracy: 0.8418\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3913 - accuracy: 0.8485\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3919 - accuracy: 0.8406\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3868 - accuracy: 0.8429\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 232us/step - loss: 0.3930 - accuracy: 0.8305\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.4059 - accuracy: 0.8272\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3811 - accuracy: 0.8462\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3955 - accuracy: 0.8294\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3944 - accuracy: 0.8384\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3999 - accuracy: 0.8328\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3928 - accuracy: 0.8350\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3924 - accuracy: 0.8350\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 230us/step - loss: 0.3849 - accuracy: 0.8406\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 231us/step - loss: 0.3840 - accuracy: 0.8496\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3875 - accuracy: 0.8350\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3978 - accuracy: 0.8294\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3794 - accuracy: 0.8418\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3713 - accuracy: 0.8384\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.4001 - accuracy: 0.8328\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3870 - accuracy: 0.8373\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.4014 - accuracy: 0.8305\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3808 - accuracy: 0.8316\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3888 - accuracy: 0.8350\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 282us/step - loss: 0.3663 - accuracy: 0.8530\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.3716 - accuracy: 0.8260\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.3894 - accuracy: 0.8350\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3826 - accuracy: 0.8451\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3857 - accuracy: 0.8272\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3851 - accuracy: 0.8305\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3813 - accuracy: 0.8316\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 239us/step - loss: 0.3832 - accuracy: 0.8530\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3757 - accuracy: 0.8406\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 236us/step - loss: 0.3720 - accuracy: 0.8361\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 234us/step - loss: 0.3919 - accuracy: 0.8418\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3848 - accuracy: 0.8429\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3853 - accuracy: 0.8440\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3854 - accuracy: 0.8395\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 257us/step - loss: 0.4069 - accuracy: 0.8238\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3833 - accuracy: 0.8305\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3931 - accuracy: 0.8418\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3838 - accuracy: 0.8451\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 241us/step - loss: 0.3989 - accuracy: 0.8328\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3965 - accuracy: 0.8406\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 233us/step - loss: 0.3756 - accuracy: 0.8316\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3809 - accuracy: 0.8429\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 299us/step - loss: 0.3916 - accuracy: 0.8328\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 268us/step - loss: 0.3824 - accuracy: 0.8474\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 235us/step - loss: 0.3754 - accuracy: 0.8361\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 449us/step - loss: 0.3951 - accuracy: 0.8283\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 407us/step - loss: 0.3691 - accuracy: 0.8474\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.3867 - accuracy: 0.8339\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.3753 - accuracy: 0.8361\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3793 - accuracy: 0.8373\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.4042 - accuracy: 0.8350\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 265us/step - loss: 0.3849 - accuracy: 0.8519\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3795 - accuracy: 0.8395\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3959 - accuracy: 0.8406\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3753 - accuracy: 0.8451\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 251us/step - loss: 0.3928 - accuracy: 0.8272\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3764 - accuracy: 0.8339\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 249us/step - loss: 0.3821 - accuracy: 0.8451\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 250us/step - loss: 0.3903 - accuracy: 0.8429\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 259us/step - loss: 0.3845 - accuracy: 0.8316\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3946 - accuracy: 0.8294\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 280us/step - loss: 0.3857 - accuracy: 0.8384\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 255us/step - loss: 0.3864 - accuracy: 0.8328\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3705 - accuracy: 0.8474\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3942 - accuracy: 0.8406\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.3876 - accuracy: 0.8406\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3936 - accuracy: 0.8339\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3928 - accuracy: 0.8305\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 273us/step - loss: 0.3714 - accuracy: 0.8474\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 253us/step - loss: 0.3732 - accuracy: 0.8462\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.3895 - accuracy: 0.8328\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.3810 - accuracy: 0.8350\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 301us/step - loss: 0.3743 - accuracy: 0.8384\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 248us/step - loss: 0.3956 - accuracy: 0.8328\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 243us/step - loss: 0.3833 - accuracy: 0.8418\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 254us/step - loss: 0.3826 - accuracy: 0.8530\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3758 - accuracy: 0.8541\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.3859 - accuracy: 0.8474\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 267us/step - loss: 0.3775 - accuracy: 0.8395\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 260us/step - loss: 0.3792 - accuracy: 0.8474\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 262us/step - loss: 0.3818 - accuracy: 0.8485\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3809 - accuracy: 0.8507\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 261us/step - loss: 0.3815 - accuracy: 0.8350\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.4039 - accuracy: 0.8328\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 266us/step - loss: 0.3733 - accuracy: 0.8440\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.3843 - accuracy: 0.8552\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.3682 - accuracy: 0.8440\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 256us/step - loss: 0.3883 - accuracy: 0.8373\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 264us/step - loss: 0.3726 - accuracy: 0.8440\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 258us/step - loss: 0.4068 - accuracy: 0.8328\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 269us/step - loss: 0.3860 - accuracy: 0.8440\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 270us/step - loss: 0.3892 - accuracy: 0.8294\n",
      "Epoch 391/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 263us/step - loss: 0.3797 - accuracy: 0.8530\n",
      "Epoch 392/400\n",
      "891/891 [==============================] - 0s 247us/step - loss: 0.3971 - accuracy: 0.8260\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 240us/step - loss: 0.3820 - accuracy: 0.8395\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3771 - accuracy: 0.8406\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 246us/step - loss: 0.3546 - accuracy: 0.8586\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 245us/step - loss: 0.3775 - accuracy: 0.8451\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 237us/step - loss: 0.3713 - accuracy: 0.8384\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 244us/step - loss: 0.3824 - accuracy: 0.8339\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 242us/step - loss: 0.3957 - accuracy: 0.8238\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 238us/step - loss: 0.3671 - accuracy: 0.8485\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n",
      "sigmoid, 100, 2\n",
      "********************************************************************************************************************************************************************************\n",
      "********************************************************************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "178/178 [==============================] - 4s 23ms/step - loss: 0.7306 - accuracy: 0.5449\n",
      "Epoch 2/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.6663 - accuracy: 0.6517\n",
      "Epoch 3/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.6440 - accuracy: 0.6685\n",
      "Epoch 4/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.6393 - accuracy: 0.6404\n",
      "Epoch 5/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.6522 - accuracy: 0.6404\n",
      "Epoch 6/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.6085 - accuracy: 0.6798\n",
      "Epoch 7/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.6279 - accuracy: 0.6461\n",
      "Epoch 8/400\n",
      "178/178 [==============================] - 0s 313us/step - loss: 0.6394 - accuracy: 0.6573\n",
      "Epoch 9/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.6321 - accuracy: 0.6629\n",
      "Epoch 10/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.6153 - accuracy: 0.6685\n",
      "Epoch 11/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.5941 - accuracy: 0.6742\n",
      "Epoch 12/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.5879 - accuracy: 0.6910\n",
      "Epoch 13/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.6188 - accuracy: 0.6742\n",
      "Epoch 14/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.5550 - accuracy: 0.6966\n",
      "Epoch 15/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.5666 - accuracy: 0.7079\n",
      "Epoch 16/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.5900 - accuracy: 0.6798\n",
      "Epoch 17/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.5885 - accuracy: 0.7079\n",
      "Epoch 18/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.5308 - accuracy: 0.7753\n",
      "Epoch 19/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.5572 - accuracy: 0.7697\n",
      "Epoch 20/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.5521 - accuracy: 0.7079\n",
      "Epoch 21/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5461 - accuracy: 0.7247\n",
      "Epoch 22/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.5654 - accuracy: 0.7360\n",
      "Epoch 23/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.5633 - accuracy: 0.7303\n",
      "Epoch 24/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.5643 - accuracy: 0.7584\n",
      "Epoch 25/400\n",
      "178/178 [==============================] - 0s 306us/step - loss: 0.5257 - accuracy: 0.7472\n",
      "Epoch 26/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.5408 - accuracy: 0.7191\n",
      "Epoch 27/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.5581 - accuracy: 0.7247\n",
      "Epoch 28/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5302 - accuracy: 0.7640\n",
      "Epoch 29/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.5072 - accuracy: 0.8090\n",
      "Epoch 30/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.5551 - accuracy: 0.7360\n",
      "Epoch 31/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.5317 - accuracy: 0.7753\n",
      "Epoch 32/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5124 - accuracy: 0.7697\n",
      "Epoch 33/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.5392 - accuracy: 0.7753\n",
      "Epoch 34/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4842 - accuracy: 0.7640\n",
      "Epoch 35/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.5325 - accuracy: 0.7416\n",
      "Epoch 36/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.5042 - accuracy: 0.7640\n",
      "Epoch 37/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4721 - accuracy: 0.7640\n",
      "Epoch 38/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.4875 - accuracy: 0.7697\n",
      "Epoch 39/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.4791 - accuracy: 0.7978\n",
      "Epoch 40/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4983 - accuracy: 0.7472\n",
      "Epoch 41/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.5036 - accuracy: 0.7247\n",
      "Epoch 42/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.5196 - accuracy: 0.7584\n",
      "Epoch 43/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.5457 - accuracy: 0.7472\n",
      "Epoch 44/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4847 - accuracy: 0.7640\n",
      "Epoch 45/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4797 - accuracy: 0.7528\n",
      "Epoch 46/400\n",
      "178/178 [==============================] - 0s 311us/step - loss: 0.5081 - accuracy: 0.7809\n",
      "Epoch 47/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4997 - accuracy: 0.7247\n",
      "Epoch 48/400\n",
      "178/178 [==============================] - 0s 307us/step - loss: 0.4764 - accuracy: 0.7921\n",
      "Epoch 49/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.5535 - accuracy: 0.7472\n",
      "Epoch 50/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4819 - accuracy: 0.7865\n",
      "Epoch 51/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.5157 - accuracy: 0.7640\n",
      "Epoch 52/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4756 - accuracy: 0.7640\n",
      "Epoch 53/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4966 - accuracy: 0.7697\n",
      "Epoch 54/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4900 - accuracy: 0.7697\n",
      "Epoch 55/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4974 - accuracy: 0.7978\n",
      "Epoch 56/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.5300 - accuracy: 0.7584\n",
      "Epoch 57/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5312 - accuracy: 0.7584\n",
      "Epoch 58/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.4936 - accuracy: 0.7921\n",
      "Epoch 59/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4968 - accuracy: 0.7753\n",
      "Epoch 60/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4993 - accuracy: 0.8090\n",
      "Epoch 61/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4937 - accuracy: 0.7416\n",
      "Epoch 62/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.5041 - accuracy: 0.7416\n",
      "Epoch 63/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4977 - accuracy: 0.7978\n",
      "Epoch 64/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4938 - accuracy: 0.7978\n",
      "Epoch 65/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4713 - accuracy: 0.7865\n",
      "Epoch 66/400\n",
      "178/178 [==============================] - 0s 315us/step - loss: 0.5367 - accuracy: 0.7584\n",
      "Epoch 67/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4726 - accuracy: 0.7978\n",
      "Epoch 68/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4829 - accuracy: 0.7584\n",
      "Epoch 69/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4673 - accuracy: 0.7978\n",
      "Epoch 70/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4904 - accuracy: 0.7640\n",
      "Epoch 71/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4595 - accuracy: 0.8034\n",
      "Epoch 72/400\n",
      "178/178 [==============================] - 0s 381us/step - loss: 0.4711 - accuracy: 0.7921\n",
      "Epoch 73/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4651 - accuracy: 0.8202\n",
      "Epoch 74/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4826 - accuracy: 0.7865\n",
      "Epoch 75/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.5229 - accuracy: 0.7640\n",
      "Epoch 76/400\n",
      "178/178 [==============================] - 0s 310us/step - loss: 0.4689 - accuracy: 0.7921\n",
      "Epoch 77/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.5227 - accuracy: 0.7921\n",
      "Epoch 78/400\n",
      "178/178 [==============================] - 0s 314us/step - loss: 0.4860 - accuracy: 0.7640\n",
      "Epoch 79/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.4701 - accuracy: 0.7921\n",
      "Epoch 80/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.4590 - accuracy: 0.8202\n",
      "Epoch 81/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.4463 - accuracy: 0.8202\n",
      "Epoch 82/400\n",
      "178/178 [==============================] - 0s 305us/step - loss: 0.4896 - accuracy: 0.7865\n",
      "Epoch 83/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4928 - accuracy: 0.7697\n",
      "Epoch 84/400\n",
      "178/178 [==============================] - 0s 369us/step - loss: 0.4808 - accuracy: 0.7865\n",
      "Epoch 85/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.4875 - accuracy: 0.7809\n",
      "Epoch 86/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.5237 - accuracy: 0.7640\n",
      "Epoch 87/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4905 - accuracy: 0.7697\n",
      "Epoch 88/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.5001 - accuracy: 0.7865\n",
      "Epoch 89/400\n",
      "178/178 [==============================] - 0s 316us/step - loss: 0.4773 - accuracy: 0.7865\n",
      "Epoch 90/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4466 - accuracy: 0.8090\n",
      "Epoch 91/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.4888 - accuracy: 0.7865\n",
      "Epoch 92/400\n",
      "178/178 [==============================] - 0s 308us/step - loss: 0.4989 - accuracy: 0.7697\n",
      "Epoch 93/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4990 - accuracy: 0.8034\n",
      "Epoch 94/400\n",
      "178/178 [==============================] - 0s 312us/step - loss: 0.4271 - accuracy: 0.8483\n",
      "Epoch 95/400\n",
      "178/178 [==============================] - 0s 317us/step - loss: 0.4844 - accuracy: 0.7584\n",
      "Epoch 96/400\n",
      "178/178 [==============================] - 0s 379us/step - loss: 0.4514 - accuracy: 0.7865\n",
      "Epoch 97/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4764 - accuracy: 0.7921\n",
      "Epoch 98/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4212 - accuracy: 0.8034\n",
      "Epoch 99/400\n",
      "178/178 [==============================] - 0s 332us/step - loss: 0.4996 - accuracy: 0.7416\n",
      "Epoch 100/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4914 - accuracy: 0.7809\n",
      "Epoch 101/400\n",
      "178/178 [==============================] - 0s 374us/step - loss: 0.4798 - accuracy: 0.7865\n",
      "Epoch 102/400\n",
      "178/178 [==============================] - 0s 406us/step - loss: 0.4816 - accuracy: 0.7809\n",
      "Epoch 103/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.4545 - accuracy: 0.8034\n",
      "Epoch 104/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4719 - accuracy: 0.7809\n",
      "Epoch 105/400\n",
      "178/178 [==============================] - 0s 376us/step - loss: 0.4789 - accuracy: 0.7865\n",
      "Epoch 106/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4789 - accuracy: 0.7978\n",
      "Epoch 107/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.5025 - accuracy: 0.7528\n",
      "Epoch 108/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4851 - accuracy: 0.7865\n",
      "Epoch 109/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.4685 - accuracy: 0.8034\n",
      "Epoch 110/400\n",
      "178/178 [==============================] - 0s 318us/step - loss: 0.4637 - accuracy: 0.7865\n",
      "Epoch 111/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.5172 - accuracy: 0.7753\n",
      "Epoch 112/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4245 - accuracy: 0.8315\n",
      "Epoch 113/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.5110 - accuracy: 0.7865\n",
      "Epoch 114/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4591 - accuracy: 0.7921\n",
      "Epoch 115/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4635 - accuracy: 0.8090\n",
      "Epoch 116/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4665 - accuracy: 0.8090\n",
      "Epoch 117/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4470 - accuracy: 0.7865\n",
      "Epoch 118/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.4366 - accuracy: 0.8202\n",
      "Epoch 119/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.4701 - accuracy: 0.7865\n",
      "Epoch 120/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4583 - accuracy: 0.8034\n",
      "Epoch 121/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.5059 - accuracy: 0.7865\n",
      "Epoch 122/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4668 - accuracy: 0.8146\n",
      "Epoch 123/400\n",
      "178/178 [==============================] - 0s 383us/step - loss: 0.4393 - accuracy: 0.8146\n",
      "Epoch 124/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.4080 - accuracy: 0.8483\n",
      "Epoch 125/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4619 - accuracy: 0.8146\n",
      "Epoch 126/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4730 - accuracy: 0.7865\n",
      "Epoch 127/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4418 - accuracy: 0.8146\n",
      "Epoch 128/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4311 - accuracy: 0.8427\n",
      "Epoch 129/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.5187 - accuracy: 0.7640\n",
      "Epoch 130/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4619 - accuracy: 0.8034\n",
      "Epoch 131/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4725 - accuracy: 0.8034\n",
      "Epoch 132/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4548 - accuracy: 0.8258\n",
      "Epoch 133/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4441 - accuracy: 0.8034\n",
      "Epoch 134/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4607 - accuracy: 0.7865\n",
      "Epoch 135/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4258 - accuracy: 0.8258\n",
      "Epoch 136/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.4598 - accuracy: 0.8202\n",
      "Epoch 137/400\n",
      "178/178 [==============================] - 0s 356us/step - loss: 0.4364 - accuracy: 0.8146\n",
      "Epoch 138/400\n",
      "178/178 [==============================] - 0s 372us/step - loss: 0.4918 - accuracy: 0.8034\n",
      "Epoch 139/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.4473 - accuracy: 0.7697\n",
      "Epoch 140/400\n",
      "178/178 [==============================] - 0s 408us/step - loss: 0.4776 - accuracy: 0.7921\n",
      "Epoch 141/400\n",
      "178/178 [==============================] - 0s 356us/step - loss: 0.4540 - accuracy: 0.8146\n",
      "Epoch 142/400\n",
      "178/178 [==============================] - 0s 417us/step - loss: 0.4475 - accuracy: 0.8090\n",
      "Epoch 143/400\n",
      "178/178 [==============================] - 0s 391us/step - loss: 0.5058 - accuracy: 0.8090\n",
      "Epoch 144/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.4697 - accuracy: 0.8146\n",
      "Epoch 145/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.4529 - accuracy: 0.8202\n",
      "Epoch 146/400\n",
      "178/178 [==============================] - 0s 368us/step - loss: 0.4217 - accuracy: 0.8258\n",
      "Epoch 147/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.4297 - accuracy: 0.8146\n",
      "Epoch 148/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.4411 - accuracy: 0.8202\n",
      "Epoch 149/400\n",
      "178/178 [==============================] - 0s 370us/step - loss: 0.4702 - accuracy: 0.7865\n",
      "Epoch 150/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4400 - accuracy: 0.8202\n",
      "Epoch 151/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4277 - accuracy: 0.8371\n",
      "Epoch 152/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.4352 - accuracy: 0.8258\n",
      "Epoch 153/400\n",
      "178/178 [==============================] - 0s 376us/step - loss: 0.4465 - accuracy: 0.8090\n",
      "Epoch 154/400\n",
      "178/178 [==============================] - 0s 388us/step - loss: 0.4026 - accuracy: 0.8371\n",
      "Epoch 155/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.4849 - accuracy: 0.7865\n",
      "Epoch 156/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4481 - accuracy: 0.8202\n",
      "Epoch 157/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 389us/step - loss: 0.4493 - accuracy: 0.7978\n",
      "Epoch 158/400\n",
      "178/178 [==============================] - 0s 372us/step - loss: 0.4309 - accuracy: 0.8258\n",
      "Epoch 159/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.4906 - accuracy: 0.7921\n",
      "Epoch 160/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4324 - accuracy: 0.8258\n",
      "Epoch 161/400\n",
      "178/178 [==============================] - 0s 367us/step - loss: 0.4712 - accuracy: 0.7921\n",
      "Epoch 162/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.4330 - accuracy: 0.8090\n",
      "Epoch 163/400\n",
      "178/178 [==============================] - 0s 370us/step - loss: 0.4810 - accuracy: 0.7865\n",
      "Epoch 164/400\n",
      "178/178 [==============================] - 0s 360us/step - loss: 0.4565 - accuracy: 0.7978\n",
      "Epoch 165/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4993 - accuracy: 0.7978\n",
      "Epoch 166/400\n",
      "178/178 [==============================] - 0s 339us/step - loss: 0.4297 - accuracy: 0.8202\n",
      "Epoch 167/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4021 - accuracy: 0.8427\n",
      "Epoch 168/400\n",
      "178/178 [==============================] - 0s 398us/step - loss: 0.4839 - accuracy: 0.7640\n",
      "Epoch 169/400\n",
      "178/178 [==============================] - 0s 392us/step - loss: 0.4161 - accuracy: 0.8202\n",
      "Epoch 170/400\n",
      "178/178 [==============================] - 0s 368us/step - loss: 0.4343 - accuracy: 0.7978\n",
      "Epoch 171/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.4272 - accuracy: 0.8258\n",
      "Epoch 172/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.4938 - accuracy: 0.7865\n",
      "Epoch 173/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4485 - accuracy: 0.7978\n",
      "Epoch 174/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4184 - accuracy: 0.8258\n",
      "Epoch 175/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4432 - accuracy: 0.8202\n",
      "Epoch 176/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.3958 - accuracy: 0.8315\n",
      "Epoch 177/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4759 - accuracy: 0.7865\n",
      "Epoch 178/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4410 - accuracy: 0.8146\n",
      "Epoch 179/400\n",
      "178/178 [==============================] - 0s 367us/step - loss: 0.4925 - accuracy: 0.7809\n",
      "Epoch 180/400\n",
      "178/178 [==============================] - 0s 403us/step - loss: 0.4574 - accuracy: 0.8146\n",
      "Epoch 181/400\n",
      "178/178 [==============================] - 0s 377us/step - loss: 0.4765 - accuracy: 0.7809\n",
      "Epoch 182/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.4695 - accuracy: 0.8258\n",
      "Epoch 183/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.4572 - accuracy: 0.7978\n",
      "Epoch 184/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.4495 - accuracy: 0.8034\n",
      "Epoch 185/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4464 - accuracy: 0.8371\n",
      "Epoch 186/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4434 - accuracy: 0.8258\n",
      "Epoch 187/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4547 - accuracy: 0.7921\n",
      "Epoch 188/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4433 - accuracy: 0.8202\n",
      "Epoch 189/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4089 - accuracy: 0.8483\n",
      "Epoch 190/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.4495 - accuracy: 0.8034\n",
      "Epoch 191/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.4187 - accuracy: 0.8315\n",
      "Epoch 192/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4125 - accuracy: 0.8371\n",
      "Epoch 193/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.4233 - accuracy: 0.8315\n",
      "Epoch 194/400\n",
      "178/178 [==============================] - 0s 385us/step - loss: 0.4172 - accuracy: 0.8146\n",
      "Epoch 195/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.4402 - accuracy: 0.8315\n",
      "Epoch 196/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.4561 - accuracy: 0.7978\n",
      "Epoch 197/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4209 - accuracy: 0.8539\n",
      "Epoch 198/400\n",
      "178/178 [==============================] - 0s 428us/step - loss: 0.4455 - accuracy: 0.8202\n",
      "Epoch 199/400\n",
      "178/178 [==============================] - 0s 434us/step - loss: 0.4159 - accuracy: 0.8202\n",
      "Epoch 200/400\n",
      "178/178 [==============================] - 0s 397us/step - loss: 0.4313 - accuracy: 0.8202\n",
      "Epoch 201/400\n",
      "178/178 [==============================] - 0s 407us/step - loss: 0.4610 - accuracy: 0.7865\n",
      "Epoch 202/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.4597 - accuracy: 0.7809\n",
      "Epoch 203/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4251 - accuracy: 0.8202\n",
      "Epoch 204/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.4670 - accuracy: 0.8034\n",
      "Epoch 205/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4218 - accuracy: 0.8315\n",
      "Epoch 206/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4114 - accuracy: 0.8371\n",
      "Epoch 207/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4282 - accuracy: 0.8258\n",
      "Epoch 208/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.4405 - accuracy: 0.8202\n",
      "Epoch 209/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4381 - accuracy: 0.8202\n",
      "Epoch 210/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4318 - accuracy: 0.8315\n",
      "Epoch 211/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4323 - accuracy: 0.8034\n",
      "Epoch 212/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.4892 - accuracy: 0.7865\n",
      "Epoch 213/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4597 - accuracy: 0.7921\n",
      "Epoch 214/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4442 - accuracy: 0.8202\n",
      "Epoch 215/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4393 - accuracy: 0.8090\n",
      "Epoch 216/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.4422 - accuracy: 0.8034\n",
      "Epoch 217/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4555 - accuracy: 0.8034\n",
      "Epoch 218/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4387 - accuracy: 0.8371\n",
      "Epoch 219/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4853 - accuracy: 0.7865\n",
      "Epoch 220/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.4247 - accuracy: 0.8258\n",
      "Epoch 221/400\n",
      "178/178 [==============================] - 0s 321us/step - loss: 0.4501 - accuracy: 0.8034\n",
      "Epoch 222/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.4226 - accuracy: 0.8202\n",
      "Epoch 223/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4097 - accuracy: 0.8427\n",
      "Epoch 224/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3985 - accuracy: 0.8315\n",
      "Epoch 225/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4759 - accuracy: 0.7921\n",
      "Epoch 226/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4488 - accuracy: 0.8202\n",
      "Epoch 227/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4693 - accuracy: 0.8146\n",
      "Epoch 228/400\n",
      "178/178 [==============================] - 0s 343us/step - loss: 0.4700 - accuracy: 0.7978\n",
      "Epoch 229/400\n",
      "178/178 [==============================] - 0s 440us/step - loss: 0.4259 - accuracy: 0.8258\n",
      "Epoch 230/400\n",
      "178/178 [==============================] - 0s 362us/step - loss: 0.4124 - accuracy: 0.8315\n",
      "Epoch 231/400\n",
      "178/178 [==============================] - 0s 383us/step - loss: 0.4559 - accuracy: 0.8034\n",
      "Epoch 232/400\n",
      "178/178 [==============================] - 0s 418us/step - loss: 0.4137 - accuracy: 0.8315\n",
      "Epoch 233/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4474 - accuracy: 0.8034\n",
      "Epoch 234/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4568 - accuracy: 0.8090\n",
      "Epoch 235/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4485 - accuracy: 0.8427\n",
      "Epoch 236/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.3899 - accuracy: 0.8764\n",
      "Epoch 237/400\n",
      "178/178 [==============================] - 0s 363us/step - loss: 0.4013 - accuracy: 0.8258\n",
      "Epoch 238/400\n",
      "178/178 [==============================] - 0s 343us/step - loss: 0.4238 - accuracy: 0.8258\n",
      "Epoch 239/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4650 - accuracy: 0.8202\n",
      "Epoch 240/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4143 - accuracy: 0.8539\n",
      "Epoch 241/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4240 - accuracy: 0.8258\n",
      "Epoch 242/400\n",
      "178/178 [==============================] - 0s 360us/step - loss: 0.4137 - accuracy: 0.7921\n",
      "Epoch 243/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4342 - accuracy: 0.8146\n",
      "Epoch 244/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4371 - accuracy: 0.8315\n",
      "Epoch 245/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4544 - accuracy: 0.8090\n",
      "Epoch 246/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.4299 - accuracy: 0.8258\n",
      "Epoch 247/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.4156 - accuracy: 0.8258\n",
      "Epoch 248/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.4067 - accuracy: 0.8427\n",
      "Epoch 249/400\n",
      "178/178 [==============================] - 0s 319us/step - loss: 0.4361 - accuracy: 0.7921\n",
      "Epoch 250/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.5110 - accuracy: 0.7584\n",
      "Epoch 251/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4042 - accuracy: 0.8427\n",
      "Epoch 252/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4296 - accuracy: 0.8034\n",
      "Epoch 253/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3975 - accuracy: 0.8596\n",
      "Epoch 254/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4425 - accuracy: 0.7978\n",
      "Epoch 255/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4025 - accuracy: 0.8258\n",
      "Epoch 256/400\n",
      "178/178 [==============================] - 0s 325us/step - loss: 0.3932 - accuracy: 0.8371\n",
      "Epoch 257/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.4364 - accuracy: 0.8483\n",
      "Epoch 258/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.4207 - accuracy: 0.8371\n",
      "Epoch 259/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.4096 - accuracy: 0.8371\n",
      "Epoch 260/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.4339 - accuracy: 0.8371\n",
      "Epoch 261/400\n",
      "178/178 [==============================] - 0s 327us/step - loss: 0.4089 - accuracy: 0.8427\n",
      "Epoch 262/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4106 - accuracy: 0.8258\n",
      "Epoch 263/400\n",
      "178/178 [==============================] - 0s 323us/step - loss: 0.4152 - accuracy: 0.8315\n",
      "Epoch 264/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4330 - accuracy: 0.8090\n",
      "Epoch 265/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3757 - accuracy: 0.8820\n",
      "Epoch 266/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4472 - accuracy: 0.8258\n",
      "Epoch 267/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.4653 - accuracy: 0.7865\n",
      "Epoch 268/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4154 - accuracy: 0.8258\n",
      "Epoch 269/400\n",
      "178/178 [==============================] - 0s 378us/step - loss: 0.3949 - accuracy: 0.8258\n",
      "Epoch 270/400\n",
      "178/178 [==============================] - 0s 391us/step - loss: 0.4106 - accuracy: 0.8539\n",
      "Epoch 271/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.4213 - accuracy: 0.8315\n",
      "Epoch 272/400\n",
      "178/178 [==============================] - 0s 384us/step - loss: 0.4163 - accuracy: 0.8146\n",
      "Epoch 273/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.5079 - accuracy: 0.8034\n",
      "Epoch 274/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4007 - accuracy: 0.8315\n",
      "Epoch 275/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4587 - accuracy: 0.8034\n",
      "Epoch 276/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.3808 - accuracy: 0.8427\n",
      "Epoch 277/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4374 - accuracy: 0.8146\n",
      "Epoch 278/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4045 - accuracy: 0.8539\n",
      "Epoch 279/400\n",
      "178/178 [==============================] - 0s 324us/step - loss: 0.3977 - accuracy: 0.8315\n",
      "Epoch 280/400\n",
      "178/178 [==============================] - 0s 322us/step - loss: 0.3908 - accuracy: 0.8483\n",
      "Epoch 281/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4156 - accuracy: 0.8258\n",
      "Epoch 282/400\n",
      "178/178 [==============================] - 0s 382us/step - loss: 0.4256 - accuracy: 0.8315\n",
      "Epoch 283/400\n",
      "178/178 [==============================] - 0s 383us/step - loss: 0.4324 - accuracy: 0.8146\n",
      "Epoch 284/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4531 - accuracy: 0.7921\n",
      "Epoch 285/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4243 - accuracy: 0.7978\n",
      "Epoch 286/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.4172 - accuracy: 0.8371\n",
      "Epoch 287/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4128 - accuracy: 0.8090\n",
      "Epoch 288/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4259 - accuracy: 0.8202\n",
      "Epoch 289/400\n",
      "178/178 [==============================] - 0s 329us/step - loss: 0.3815 - accuracy: 0.8596\n",
      "Epoch 290/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.4007 - accuracy: 0.8483\n",
      "Epoch 291/400\n",
      "178/178 [==============================] - 0s 594us/step - loss: 0.3745 - accuracy: 0.8596\n",
      "Epoch 292/400\n",
      "178/178 [==============================] - 0s 376us/step - loss: 0.4078 - accuracy: 0.8427\n",
      "Epoch 293/400\n",
      "178/178 [==============================] - 0s 368us/step - loss: 0.4098 - accuracy: 0.8371\n",
      "Epoch 294/400\n",
      "178/178 [==============================] - 0s 367us/step - loss: 0.4215 - accuracy: 0.8202\n",
      "Epoch 295/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4050 - accuracy: 0.8427\n",
      "Epoch 296/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.3618 - accuracy: 0.8371\n",
      "Epoch 297/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4192 - accuracy: 0.8315\n",
      "Epoch 298/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.4511 - accuracy: 0.8258\n",
      "Epoch 299/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4068 - accuracy: 0.8315\n",
      "Epoch 300/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4420 - accuracy: 0.8258\n",
      "Epoch 301/400\n",
      "178/178 [==============================] - 0s 378us/step - loss: 0.3775 - accuracy: 0.8371\n",
      "Epoch 302/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.3893 - accuracy: 0.8427\n",
      "Epoch 303/400\n",
      "178/178 [==============================] - 0s 343us/step - loss: 0.4191 - accuracy: 0.8427\n",
      "Epoch 304/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.3955 - accuracy: 0.8202\n",
      "Epoch 305/400\n",
      "178/178 [==============================] - 0s 349us/step - loss: 0.3941 - accuracy: 0.8427\n",
      "Epoch 306/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.3856 - accuracy: 0.8596\n",
      "Epoch 307/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.4015 - accuracy: 0.8202\n",
      "Epoch 308/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4199 - accuracy: 0.8146\n",
      "Epoch 309/400\n",
      "178/178 [==============================] - 0s 393us/step - loss: 0.4419 - accuracy: 0.8034\n",
      "Epoch 310/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4159 - accuracy: 0.8202\n",
      "Epoch 311/400\n",
      "178/178 [==============================] - 0s 348us/step - loss: 0.4005 - accuracy: 0.8483\n",
      "Epoch 312/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.4366 - accuracy: 0.8090\n",
      "Epoch 313/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 346us/step - loss: 0.4218 - accuracy: 0.8483\n",
      "Epoch 314/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.4453 - accuracy: 0.8090\n",
      "Epoch 315/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4384 - accuracy: 0.8202\n",
      "Epoch 316/400\n",
      "178/178 [==============================] - 0s 360us/step - loss: 0.4564 - accuracy: 0.7978\n",
      "Epoch 317/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.4039 - accuracy: 0.8258\n",
      "Epoch 318/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.3902 - accuracy: 0.8427\n",
      "Epoch 319/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.4007 - accuracy: 0.8146\n",
      "Epoch 320/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.4040 - accuracy: 0.8146\n",
      "Epoch 321/400\n",
      "178/178 [==============================] - 0s 345us/step - loss: 0.4194 - accuracy: 0.8427\n",
      "Epoch 322/400\n",
      "178/178 [==============================] - 0s 330us/step - loss: 0.4054 - accuracy: 0.8258\n",
      "Epoch 323/400\n",
      "178/178 [==============================] - 0s 333us/step - loss: 0.4552 - accuracy: 0.8034\n",
      "Epoch 324/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.4076 - accuracy: 0.8315\n",
      "Epoch 325/400\n",
      "178/178 [==============================] - 0s 391us/step - loss: 0.4248 - accuracy: 0.8371\n",
      "Epoch 326/400\n",
      "178/178 [==============================] - 0s 425us/step - loss: 0.4030 - accuracy: 0.8483\n",
      "Epoch 327/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.4104 - accuracy: 0.8315\n",
      "Epoch 328/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.4061 - accuracy: 0.8146\n",
      "Epoch 329/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4204 - accuracy: 0.8090\n",
      "Epoch 330/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.3801 - accuracy: 0.8483\n",
      "Epoch 331/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.3964 - accuracy: 0.8539\n",
      "Epoch 332/400\n",
      "178/178 [==============================] - 0s 342us/step - loss: 0.4262 - accuracy: 0.8258\n",
      "Epoch 333/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4505 - accuracy: 0.8034\n",
      "Epoch 334/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.4020 - accuracy: 0.8371\n",
      "Epoch 335/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4806 - accuracy: 0.7809\n",
      "Epoch 336/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.4297 - accuracy: 0.8090\n",
      "Epoch 337/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4132 - accuracy: 0.8146\n",
      "Epoch 338/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4007 - accuracy: 0.8258\n",
      "Epoch 339/400\n",
      "178/178 [==============================] - 0s 337us/step - loss: 0.4459 - accuracy: 0.8146\n",
      "Epoch 340/400\n",
      "178/178 [==============================] - 0s 334us/step - loss: 0.3863 - accuracy: 0.8708\n",
      "Epoch 341/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4368 - accuracy: 0.8202\n",
      "Epoch 342/400\n",
      "178/178 [==============================] - 0s 341us/step - loss: 0.4037 - accuracy: 0.8146\n",
      "Epoch 343/400\n",
      "178/178 [==============================] - 0s 364us/step - loss: 0.4129 - accuracy: 0.8427\n",
      "Epoch 344/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4048 - accuracy: 0.8371\n",
      "Epoch 345/400\n",
      "178/178 [==============================] - 0s 382us/step - loss: 0.4034 - accuracy: 0.8427\n",
      "Epoch 346/400\n",
      "178/178 [==============================] - 0s 383us/step - loss: 0.3856 - accuracy: 0.8427\n",
      "Epoch 347/400\n",
      "178/178 [==============================] - 0s 417us/step - loss: 0.4341 - accuracy: 0.8090\n",
      "Epoch 348/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.4147 - accuracy: 0.8315\n",
      "Epoch 349/400\n",
      "178/178 [==============================] - 0s 361us/step - loss: 0.3911 - accuracy: 0.8315\n",
      "Epoch 350/400\n",
      "178/178 [==============================] - 0s 377us/step - loss: 0.4294 - accuracy: 0.7921\n",
      "Epoch 351/400\n",
      "178/178 [==============================] - 0s 400us/step - loss: 0.4589 - accuracy: 0.8146\n",
      "Epoch 352/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.3925 - accuracy: 0.8315\n",
      "Epoch 353/400\n",
      "178/178 [==============================] - 0s 350us/step - loss: 0.3940 - accuracy: 0.8483\n",
      "Epoch 354/400\n",
      "178/178 [==============================] - 0s 472us/step - loss: 0.3843 - accuracy: 0.8539\n",
      "Epoch 355/400\n",
      "178/178 [==============================] - 0s 516us/step - loss: 0.3756 - accuracy: 0.8539\n",
      "Epoch 356/400\n",
      "178/178 [==============================] - 0s 456us/step - loss: 0.4111 - accuracy: 0.8371\n",
      "Epoch 357/400\n",
      "178/178 [==============================] - 0s 367us/step - loss: 0.3674 - accuracy: 0.8539\n",
      "Epoch 358/400\n",
      "178/178 [==============================] - 0s 368us/step - loss: 0.4167 - accuracy: 0.8315\n",
      "Epoch 359/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.3680 - accuracy: 0.8708\n",
      "Epoch 360/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3815 - accuracy: 0.8427\n",
      "Epoch 361/400\n",
      "178/178 [==============================] - 0s 354us/step - loss: 0.4262 - accuracy: 0.8315\n",
      "Epoch 362/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4422 - accuracy: 0.8146\n",
      "Epoch 363/400\n",
      "178/178 [==============================] - 0s 537us/step - loss: 0.4086 - accuracy: 0.8315\n",
      "Epoch 364/400\n",
      "178/178 [==============================] - 0s 572us/step - loss: 0.4008 - accuracy: 0.8483\n",
      "Epoch 365/400\n",
      "178/178 [==============================] - 0s 474us/step - loss: 0.4230 - accuracy: 0.8146\n",
      "Epoch 366/400\n",
      "178/178 [==============================] - 0s 422us/step - loss: 0.4161 - accuracy: 0.8202\n",
      "Epoch 367/400\n",
      "178/178 [==============================] - 0s 371us/step - loss: 0.4348 - accuracy: 0.8258\n",
      "Epoch 368/400\n",
      "178/178 [==============================] - 0s 366us/step - loss: 0.3976 - accuracy: 0.8202\n",
      "Epoch 369/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.3892 - accuracy: 0.8596\n",
      "Epoch 370/400\n",
      "178/178 [==============================] - 0s 360us/step - loss: 0.4010 - accuracy: 0.8427\n",
      "Epoch 371/400\n",
      "178/178 [==============================] - 0s 358us/step - loss: 0.4562 - accuracy: 0.7978\n",
      "Epoch 372/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.4166 - accuracy: 0.8427\n",
      "Epoch 373/400\n",
      "178/178 [==============================] - 0s 352us/step - loss: 0.4232 - accuracy: 0.8146\n",
      "Epoch 374/400\n",
      "178/178 [==============================] - 0s 351us/step - loss: 0.4509 - accuracy: 0.8090\n",
      "Epoch 375/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.3764 - accuracy: 0.8652\n",
      "Epoch 376/400\n",
      "178/178 [==============================] - 0s 356us/step - loss: 0.4038 - accuracy: 0.8483\n",
      "Epoch 377/400\n",
      "178/178 [==============================] - 0s 344us/step - loss: 0.4207 - accuracy: 0.8146\n",
      "Epoch 378/400\n",
      "178/178 [==============================] - 0s 346us/step - loss: 0.3880 - accuracy: 0.8371\n",
      "Epoch 379/400\n",
      "178/178 [==============================] - 0s 355us/step - loss: 0.3997 - accuracy: 0.8315\n",
      "Epoch 380/400\n",
      "178/178 [==============================] - 0s 367us/step - loss: 0.4326 - accuracy: 0.8202\n",
      "Epoch 381/400\n",
      "178/178 [==============================] - 0s 393us/step - loss: 0.4262 - accuracy: 0.8202\n",
      "Epoch 382/400\n",
      "178/178 [==============================] - 0s 359us/step - loss: 0.3892 - accuracy: 0.8315\n",
      "Epoch 383/400\n",
      "178/178 [==============================] - 0s 372us/step - loss: 0.3894 - accuracy: 0.8483\n",
      "Epoch 384/400\n",
      "178/178 [==============================] - 0s 365us/step - loss: 0.4236 - accuracy: 0.8146\n",
      "Epoch 385/400\n",
      "178/178 [==============================] - 0s 366us/step - loss: 0.4223 - accuracy: 0.8427\n",
      "Epoch 386/400\n",
      "178/178 [==============================] - 0s 357us/step - loss: 0.3693 - accuracy: 0.8764\n",
      "Epoch 387/400\n",
      "178/178 [==============================] - 0s 410us/step - loss: 0.3919 - accuracy: 0.8371\n",
      "Epoch 388/400\n",
      "178/178 [==============================] - 0s 353us/step - loss: 0.4115 - accuracy: 0.8315\n",
      "Epoch 389/400\n",
      "178/178 [==============================] - 0s 336us/step - loss: 0.3803 - accuracy: 0.8539\n",
      "Epoch 390/400\n",
      "178/178 [==============================] - 0s 426us/step - loss: 0.3553 - accuracy: 0.8596\n",
      "Epoch 391/400\n",
      "178/178 [==============================] - 0s 375us/step - loss: 0.3822 - accuracy: 0.8483\n",
      "Epoch 392/400\n",
      "178/178 [==============================] - 0s 340us/step - loss: 0.4368 - accuracy: 0.8202\n",
      "Epoch 393/400\n",
      "178/178 [==============================] - 0s 338us/step - loss: 0.4270 - accuracy: 0.8034\n",
      "Epoch 394/400\n",
      "178/178 [==============================] - 0s 335us/step - loss: 0.3724 - accuracy: 0.8539\n",
      "Epoch 395/400\n",
      "178/178 [==============================] - 0s 326us/step - loss: 0.4237 - accuracy: 0.8427\n",
      "Epoch 396/400\n",
      "178/178 [==============================] - 0s 328us/step - loss: 0.4037 - accuracy: 0.8315\n",
      "Epoch 397/400\n",
      "178/178 [==============================] - 0s 320us/step - loss: 0.3881 - accuracy: 0.8539\n",
      "Epoch 398/400\n",
      "178/178 [==============================] - 0s 331us/step - loss: 0.3847 - accuracy: 0.8427\n",
      "Epoch 399/400\n",
      "178/178 [==============================] - 0s 347us/step - loss: 0.3862 - accuracy: 0.8258\n",
      "Epoch 400/400\n",
      "178/178 [==============================] - 0s 362us/step - loss: 0.4220 - accuracy: 0.8146\n",
      "713/713 [==============================] - 1s 1ms/step\n",
      "Epoch 1/400\n",
      "480/891 [===============>..............] - ETA: 0s - loss: 0.5210 - accuracy: 0.7667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xaf/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 341us/step - loss: 0.4933 - accuracy: 0.7868\n",
      "Epoch 2/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4795 - accuracy: 0.7856\n",
      "Epoch 3/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4568 - accuracy: 0.8070\n",
      "Epoch 4/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4666 - accuracy: 0.7969\n",
      "Epoch 5/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.4560 - accuracy: 0.8025\n",
      "Epoch 6/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4523 - accuracy: 0.7991\n",
      "Epoch 7/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4491 - accuracy: 0.8260\n",
      "Epoch 8/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4824 - accuracy: 0.7834\n",
      "Epoch 9/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.4597 - accuracy: 0.8103\n",
      "Epoch 10/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4463 - accuracy: 0.8238\n",
      "Epoch 11/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4411 - accuracy: 0.8159\n",
      "Epoch 12/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.4589 - accuracy: 0.8081\n",
      "Epoch 13/400\n",
      "891/891 [==============================] - 0s 391us/step - loss: 0.4543 - accuracy: 0.8025\n",
      "Epoch 14/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4461 - accuracy: 0.8081\n",
      "Epoch 15/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4344 - accuracy: 0.8260\n",
      "Epoch 16/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.4429 - accuracy: 0.8047\n",
      "Epoch 17/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.4596 - accuracy: 0.8103\n",
      "Epoch 18/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.4317 - accuracy: 0.8249\n",
      "Epoch 19/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.4541 - accuracy: 0.8070\n",
      "Epoch 20/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.4443 - accuracy: 0.8103\n",
      "Epoch 21/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.4351 - accuracy: 0.8249\n",
      "Epoch 22/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.4496 - accuracy: 0.8025\n",
      "Epoch 23/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4468 - accuracy: 0.7980\n",
      "Epoch 24/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4459 - accuracy: 0.8047\n",
      "Epoch 25/400\n",
      "891/891 [==============================] - 0s 379us/step - loss: 0.4516 - accuracy: 0.8058\n",
      "Epoch 26/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.4551 - accuracy: 0.8114\n",
      "Epoch 27/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.4486 - accuracy: 0.8081\n",
      "Epoch 28/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4434 - accuracy: 0.8070\n",
      "Epoch 29/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.4421 - accuracy: 0.8114\n",
      "Epoch 30/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4357 - accuracy: 0.8159\n",
      "Epoch 31/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4490 - accuracy: 0.8070\n",
      "Epoch 32/400\n",
      "891/891 [==============================] - 0s 381us/step - loss: 0.4219 - accuracy: 0.8373\n",
      "Epoch 33/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4420 - accuracy: 0.8137\n",
      "Epoch 34/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.4446 - accuracy: 0.8103\n",
      "Epoch 35/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.4253 - accuracy: 0.8328\n",
      "Epoch 36/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4454 - accuracy: 0.8204\n",
      "Epoch 37/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4361 - accuracy: 0.8126\n",
      "Epoch 38/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.4472 - accuracy: 0.8126\n",
      "Epoch 39/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.4391 - accuracy: 0.8171\n",
      "Epoch 40/400\n",
      "891/891 [==============================] - 0s 349us/step - loss: 0.4368 - accuracy: 0.8137\n",
      "Epoch 41/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.4607 - accuracy: 0.7856\n",
      "Epoch 42/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.4250 - accuracy: 0.8305\n",
      "Epoch 43/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.4432 - accuracy: 0.8070\n",
      "Epoch 44/400\n",
      "891/891 [==============================] - 0s 379us/step - loss: 0.4384 - accuracy: 0.8215\n",
      "Epoch 45/400\n",
      "891/891 [==============================] - 0s 382us/step - loss: 0.4186 - accuracy: 0.8260\n",
      "Epoch 46/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.4302 - accuracy: 0.8339\n",
      "Epoch 47/400\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.4497 - accuracy: 0.8137\n",
      "Epoch 48/400\n",
      "891/891 [==============================] - 0s 411us/step - loss: 0.4325 - accuracy: 0.8171\n",
      "Epoch 49/400\n",
      "891/891 [==============================] - 0s 389us/step - loss: 0.4282 - accuracy: 0.8204\n",
      "Epoch 50/400\n",
      "891/891 [==============================] - 0s 391us/step - loss: 0.4478 - accuracy: 0.8148\n",
      "Epoch 51/400\n",
      "891/891 [==============================] - 0s 418us/step - loss: 0.4250 - accuracy: 0.8328\n",
      "Epoch 52/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4346 - accuracy: 0.8193\n",
      "Epoch 53/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.4327 - accuracy: 0.8159\n",
      "Epoch 54/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.4473 - accuracy: 0.8047\n",
      "Epoch 55/400\n",
      "891/891 [==============================] - 0s 407us/step - loss: 0.4188 - accuracy: 0.8350\n",
      "Epoch 56/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4377 - accuracy: 0.8204\n",
      "Epoch 57/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4603 - accuracy: 0.7969\n",
      "Epoch 58/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4354 - accuracy: 0.8215\n",
      "Epoch 59/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4215 - accuracy: 0.8249\n",
      "Epoch 60/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4421 - accuracy: 0.8137\n",
      "Epoch 61/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4201 - accuracy: 0.8227\n",
      "Epoch 62/400\n",
      "891/891 [==============================] - 0s 390us/step - loss: 0.4330 - accuracy: 0.8238\n",
      "Epoch 63/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.4322 - accuracy: 0.8058\n",
      "Epoch 64/400\n",
      "891/891 [==============================] - 0s 381us/step - loss: 0.4387 - accuracy: 0.8103\n",
      "Epoch 65/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4467 - accuracy: 0.8126\n",
      "Epoch 66/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.4184 - accuracy: 0.8294\n",
      "Epoch 67/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4339 - accuracy: 0.8126\n",
      "Epoch 68/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.4340 - accuracy: 0.8249\n",
      "Epoch 69/400\n",
      "891/891 [==============================] - 0s 368us/step - loss: 0.4306 - accuracy: 0.8260\n",
      "Epoch 70/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.4087 - accuracy: 0.8339\n",
      "Epoch 71/400\n",
      "891/891 [==============================] - 0s 392us/step - loss: 0.4090 - accuracy: 0.8406\n",
      "Epoch 72/400\n",
      "891/891 [==============================] - 0s 438us/step - loss: 0.4142 - accuracy: 0.8305\n",
      "Epoch 73/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4308 - accuracy: 0.8114\n",
      "Epoch 74/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4389 - accuracy: 0.8047\n",
      "Epoch 75/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4401 - accuracy: 0.8036\n",
      "Epoch 76/400\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4225 - accuracy: 0.8193\n",
      "Epoch 77/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4216 - accuracy: 0.8316\n",
      "Epoch 78/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4345 - accuracy: 0.8126\n",
      "Epoch 79/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.4492 - accuracy: 0.8092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4514 - accuracy: 0.8148\n",
      "Epoch 81/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4294 - accuracy: 0.8182\n",
      "Epoch 82/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4233 - accuracy: 0.8305\n",
      "Epoch 83/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4069 - accuracy: 0.8316\n",
      "Epoch 84/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4179 - accuracy: 0.8249\n",
      "Epoch 85/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4140 - accuracy: 0.8339\n",
      "Epoch 86/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4263 - accuracy: 0.8182\n",
      "Epoch 87/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4184 - accuracy: 0.8272\n",
      "Epoch 88/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4559 - accuracy: 0.7980\n",
      "Epoch 89/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4099 - accuracy: 0.8328\n",
      "Epoch 90/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4240 - accuracy: 0.8238\n",
      "Epoch 91/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4187 - accuracy: 0.8193\n",
      "Epoch 92/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4118 - accuracy: 0.8350\n",
      "Epoch 93/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4312 - accuracy: 0.8126\n",
      "Epoch 94/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4360 - accuracy: 0.8171\n",
      "Epoch 95/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4169 - accuracy: 0.8305\n",
      "Epoch 96/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4503 - accuracy: 0.8058\n",
      "Epoch 97/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4240 - accuracy: 0.8260\n",
      "Epoch 98/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4102 - accuracy: 0.8328\n",
      "Epoch 99/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4267 - accuracy: 0.8193\n",
      "Epoch 100/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4106 - accuracy: 0.8260\n",
      "Epoch 101/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4307 - accuracy: 0.8148\n",
      "Epoch 102/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4303 - accuracy: 0.8238\n",
      "Epoch 103/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4285 - accuracy: 0.8294\n",
      "Epoch 104/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4222 - accuracy: 0.8238\n",
      "Epoch 105/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4219 - accuracy: 0.8283\n",
      "Epoch 106/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4419 - accuracy: 0.8092\n",
      "Epoch 107/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4313 - accuracy: 0.8283\n",
      "Epoch 108/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4229 - accuracy: 0.8182\n",
      "Epoch 109/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4135 - accuracy: 0.8260\n",
      "Epoch 110/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4308 - accuracy: 0.8193\n",
      "Epoch 111/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4238 - accuracy: 0.8272\n",
      "Epoch 112/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4245 - accuracy: 0.8215\n",
      "Epoch 113/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4400 - accuracy: 0.8182\n",
      "Epoch 114/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4160 - accuracy: 0.8305\n",
      "Epoch 115/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4185 - accuracy: 0.8249\n",
      "Epoch 116/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4258 - accuracy: 0.8193\n",
      "Epoch 117/400\n",
      "891/891 [==============================] - 0s 314us/step - loss: 0.4188 - accuracy: 0.8283\n",
      "Epoch 118/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4278 - accuracy: 0.8159\n",
      "Epoch 119/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.4280 - accuracy: 0.8159\n",
      "Epoch 120/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4119 - accuracy: 0.8283\n",
      "Epoch 121/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4135 - accuracy: 0.8238\n",
      "Epoch 122/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4147 - accuracy: 0.8249\n",
      "Epoch 123/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4235 - accuracy: 0.8182\n",
      "Epoch 124/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4292 - accuracy: 0.8249\n",
      "Epoch 125/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4325 - accuracy: 0.8148\n",
      "Epoch 126/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4255 - accuracy: 0.8126\n",
      "Epoch 127/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4133 - accuracy: 0.8305\n",
      "Epoch 128/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4331 - accuracy: 0.8249\n",
      "Epoch 129/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4440 - accuracy: 0.8126\n",
      "Epoch 130/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4266 - accuracy: 0.8204\n",
      "Epoch 131/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4113 - accuracy: 0.8272\n",
      "Epoch 132/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4167 - accuracy: 0.8215\n",
      "Epoch 133/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.4189 - accuracy: 0.8283\n",
      "Epoch 134/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4190 - accuracy: 0.8193\n",
      "Epoch 135/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.4313 - accuracy: 0.8238\n",
      "Epoch 136/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.4391 - accuracy: 0.8092\n",
      "Epoch 137/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.4093 - accuracy: 0.8305\n",
      "Epoch 138/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4152 - accuracy: 0.8373\n",
      "Epoch 139/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4097 - accuracy: 0.8272\n",
      "Epoch 140/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4083 - accuracy: 0.8294\n",
      "Epoch 141/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4241 - accuracy: 0.8283\n",
      "Epoch 142/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.4134 - accuracy: 0.8373\n",
      "Epoch 143/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4199 - accuracy: 0.8328\n",
      "Epoch 144/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4117 - accuracy: 0.8260\n",
      "Epoch 145/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4395 - accuracy: 0.8215\n",
      "Epoch 146/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4098 - accuracy: 0.8451\n",
      "Epoch 147/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4297 - accuracy: 0.8182\n",
      "Epoch 148/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4150 - accuracy: 0.8294\n",
      "Epoch 149/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4120 - accuracy: 0.8272\n",
      "Epoch 150/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4288 - accuracy: 0.8193\n",
      "Epoch 151/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4185 - accuracy: 0.8182\n",
      "Epoch 152/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4212 - accuracy: 0.8238\n",
      "Epoch 153/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4115 - accuracy: 0.8395\n",
      "Epoch 154/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4186 - accuracy: 0.8339\n",
      "Epoch 155/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4416 - accuracy: 0.7980\n",
      "Epoch 156/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4127 - accuracy: 0.8272\n",
      "Epoch 157/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4249 - accuracy: 0.8283\n",
      "Epoch 158/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4409 - accuracy: 0.8126\n",
      "Epoch 159/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4195 - accuracy: 0.8294\n",
      "Epoch 160/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4180 - accuracy: 0.8238\n",
      "Epoch 161/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.4219 - accuracy: 0.8081\n",
      "Epoch 162/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.4153 - accuracy: 0.8272\n",
      "Epoch 163/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3986 - accuracy: 0.8283\n",
      "Epoch 164/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4245 - accuracy: 0.8171\n",
      "Epoch 165/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4162 - accuracy: 0.8148\n",
      "Epoch 166/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4212 - accuracy: 0.8260\n",
      "Epoch 167/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4319 - accuracy: 0.8126\n",
      "Epoch 168/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4103 - accuracy: 0.8249\n",
      "Epoch 169/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4172 - accuracy: 0.8361\n",
      "Epoch 170/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4155 - accuracy: 0.8373\n",
      "Epoch 171/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4095 - accuracy: 0.8328\n",
      "Epoch 172/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4269 - accuracy: 0.8227\n",
      "Epoch 173/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4209 - accuracy: 0.8193\n",
      "Epoch 174/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.4200 - accuracy: 0.8283\n",
      "Epoch 175/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4045 - accuracy: 0.8316\n",
      "Epoch 176/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4075 - accuracy: 0.8328\n",
      "Epoch 177/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4064 - accuracy: 0.8260\n",
      "Epoch 178/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4049 - accuracy: 0.8373\n",
      "Epoch 179/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.3955 - accuracy: 0.8305\n",
      "Epoch 180/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4206 - accuracy: 0.8316\n",
      "Epoch 181/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4130 - accuracy: 0.8305\n",
      "Epoch 182/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4101 - accuracy: 0.8350\n",
      "Epoch 183/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4025 - accuracy: 0.8462\n",
      "Epoch 184/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4250 - accuracy: 0.8159\n",
      "Epoch 185/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3979 - accuracy: 0.8272\n",
      "Epoch 186/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.4238 - accuracy: 0.8126\n",
      "Epoch 187/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4224 - accuracy: 0.8193\n",
      "Epoch 188/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4108 - accuracy: 0.8260\n",
      "Epoch 189/400\n",
      "891/891 [==============================] - 0s 329us/step - loss: 0.3989 - accuracy: 0.8429\n",
      "Epoch 190/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4205 - accuracy: 0.8283\n",
      "Epoch 191/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4102 - accuracy: 0.8316\n",
      "Epoch 192/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.4101 - accuracy: 0.8384\n",
      "Epoch 193/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.4114 - accuracy: 0.8272\n",
      "Epoch 194/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4233 - accuracy: 0.8193\n",
      "Epoch 195/400\n",
      "891/891 [==============================] - 0s 332us/step - loss: 0.4175 - accuracy: 0.8260\n",
      "Epoch 196/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4132 - accuracy: 0.8283\n",
      "Epoch 197/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4085 - accuracy: 0.8272\n",
      "Epoch 198/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4203 - accuracy: 0.8238\n",
      "Epoch 199/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3922 - accuracy: 0.8451\n",
      "Epoch 200/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.4232 - accuracy: 0.8148\n",
      "Epoch 201/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.4314 - accuracy: 0.8283\n",
      "Epoch 202/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4165 - accuracy: 0.8227\n",
      "Epoch 203/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4042 - accuracy: 0.8260\n",
      "Epoch 204/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4098 - accuracy: 0.8316\n",
      "Epoch 205/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4125 - accuracy: 0.8339\n",
      "Epoch 206/400\n",
      "891/891 [==============================] - 0s 322us/step - loss: 0.4169 - accuracy: 0.8260\n",
      "Epoch 207/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.3989 - accuracy: 0.8339\n",
      "Epoch 208/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.4167 - accuracy: 0.8272\n",
      "Epoch 209/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4186 - accuracy: 0.8182\n",
      "Epoch 210/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4299 - accuracy: 0.8137\n",
      "Epoch 211/400\n",
      "891/891 [==============================] - 0s 317us/step - loss: 0.3976 - accuracy: 0.8305\n",
      "Epoch 212/400\n",
      "891/891 [==============================] - 0s 367us/step - loss: 0.4050 - accuracy: 0.8339\n",
      "Epoch 213/400\n",
      "891/891 [==============================] - 0s 418us/step - loss: 0.3965 - accuracy: 0.8519\n",
      "Epoch 214/400\n",
      "891/891 [==============================] - 0s 386us/step - loss: 0.4021 - accuracy: 0.8305\n",
      "Epoch 215/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4032 - accuracy: 0.8294\n",
      "Epoch 216/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.4151 - accuracy: 0.8350\n",
      "Epoch 217/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4241 - accuracy: 0.8204\n",
      "Epoch 218/400\n",
      "891/891 [==============================] - 0s 330us/step - loss: 0.4095 - accuracy: 0.8350\n",
      "Epoch 219/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.4083 - accuracy: 0.8384\n",
      "Epoch 220/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.4029 - accuracy: 0.8193\n",
      "Epoch 221/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4144 - accuracy: 0.8272\n",
      "Epoch 222/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.4106 - accuracy: 0.8215\n",
      "Epoch 223/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3987 - accuracy: 0.8328\n",
      "Epoch 224/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4009 - accuracy: 0.8384\n",
      "Epoch 225/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4012 - accuracy: 0.8339\n",
      "Epoch 226/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 227/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3991 - accuracy: 0.8339\n",
      "Epoch 228/400\n",
      "891/891 [==============================] - 0s 318us/step - loss: 0.4024 - accuracy: 0.8361\n",
      "Epoch 229/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.4138 - accuracy: 0.8328\n",
      "Epoch 230/400\n",
      "891/891 [==============================] - 0s 319us/step - loss: 0.3983 - accuracy: 0.8339\n",
      "Epoch 231/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4029 - accuracy: 0.8395\n",
      "Epoch 232/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4204 - accuracy: 0.8272\n",
      "Epoch 233/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3855 - accuracy: 0.8418\n",
      "Epoch 234/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4013 - accuracy: 0.8305\n",
      "Epoch 235/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3866 - accuracy: 0.8316\n",
      "Epoch 236/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 322us/step - loss: 0.4230 - accuracy: 0.8081\n",
      "Epoch 237/400\n",
      "891/891 [==============================] - 0s 320us/step - loss: 0.4022 - accuracy: 0.8429\n",
      "Epoch 238/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4093 - accuracy: 0.8361\n",
      "Epoch 239/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4110 - accuracy: 0.8204\n",
      "Epoch 240/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.4220 - accuracy: 0.8182\n",
      "Epoch 241/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4127 - accuracy: 0.8305\n",
      "Epoch 242/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.4097 - accuracy: 0.8260\n",
      "Epoch 243/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4281 - accuracy: 0.8171\n",
      "Epoch 244/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4047 - accuracy: 0.8316\n",
      "Epoch 245/400\n",
      "891/891 [==============================] - 0s 427us/step - loss: 0.3927 - accuracy: 0.8395\n",
      "Epoch 246/400\n",
      "891/891 [==============================] - 0s 340us/step - loss: 0.3911 - accuracy: 0.8440\n",
      "Epoch 247/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3845 - accuracy: 0.8485\n",
      "Epoch 248/400\n",
      "891/891 [==============================] - 0s 382us/step - loss: 0.3935 - accuracy: 0.8361\n",
      "Epoch 249/400\n",
      "891/891 [==============================] - 0s 326us/step - loss: 0.3959 - accuracy: 0.8350\n",
      "Epoch 250/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.4037 - accuracy: 0.8429\n",
      "Epoch 251/400\n",
      "891/891 [==============================] - 0s 411us/step - loss: 0.4122 - accuracy: 0.8260\n",
      "Epoch 252/400\n",
      "891/891 [==============================] - 0s 510us/step - loss: 0.4130 - accuracy: 0.8294\n",
      "Epoch 253/400\n",
      "891/891 [==============================] - 0s 374us/step - loss: 0.4019 - accuracy: 0.8395\n",
      "Epoch 254/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.4053 - accuracy: 0.8373\n",
      "Epoch 255/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3922 - accuracy: 0.8294\n",
      "Epoch 256/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.4160 - accuracy: 0.8328\n",
      "Epoch 257/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.3952 - accuracy: 0.8406\n",
      "Epoch 258/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.4099 - accuracy: 0.8272\n",
      "Epoch 259/400\n",
      "891/891 [==============================] - 0s 339us/step - loss: 0.3956 - accuracy: 0.8395\n",
      "Epoch 260/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.4138 - accuracy: 0.8361\n",
      "Epoch 261/400\n",
      "891/891 [==============================] - 0s 362us/step - loss: 0.4154 - accuracy: 0.8272\n",
      "Epoch 262/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4052 - accuracy: 0.8350\n",
      "Epoch 263/400\n",
      "891/891 [==============================] - 0s 397us/step - loss: 0.3962 - accuracy: 0.8339\n",
      "Epoch 264/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.3884 - accuracy: 0.8316\n",
      "Epoch 265/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4167 - accuracy: 0.8215\n",
      "Epoch 266/400\n",
      "891/891 [==============================] - 0s 465us/step - loss: 0.4031 - accuracy: 0.8350\n",
      "Epoch 267/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.3919 - accuracy: 0.8339\n",
      "Epoch 268/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.4266 - accuracy: 0.8171\n",
      "Epoch 269/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4150 - accuracy: 0.8260\n",
      "Epoch 270/400\n",
      "891/891 [==============================] - 0s 348us/step - loss: 0.4332 - accuracy: 0.8047\n",
      "Epoch 271/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3999 - accuracy: 0.8418\n",
      "Epoch 272/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4052 - accuracy: 0.8238\n",
      "Epoch 273/400\n",
      "891/891 [==============================] - 0s 325us/step - loss: 0.3956 - accuracy: 0.8283\n",
      "Epoch 274/400\n",
      "891/891 [==============================] - 0s 323us/step - loss: 0.4057 - accuracy: 0.8294\n",
      "Epoch 275/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3997 - accuracy: 0.8429\n",
      "Epoch 276/400\n",
      "891/891 [==============================] - 0s 428us/step - loss: 0.4243 - accuracy: 0.8227\n",
      "Epoch 277/400\n",
      "891/891 [==============================] - 0s 381us/step - loss: 0.4115 - accuracy: 0.8418\n",
      "Epoch 278/400\n",
      "891/891 [==============================] - 0s 397us/step - loss: 0.4069 - accuracy: 0.8350\n",
      "Epoch 279/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3850 - accuracy: 0.8328\n",
      "Epoch 280/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4038 - accuracy: 0.8137\n",
      "Epoch 281/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.4008 - accuracy: 0.8339\n",
      "Epoch 282/400\n",
      "891/891 [==============================] - 0s 365us/step - loss: 0.4088 - accuracy: 0.8339\n",
      "Epoch 283/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3968 - accuracy: 0.8451\n",
      "Epoch 284/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4080 - accuracy: 0.8227\n",
      "Epoch 285/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4111 - accuracy: 0.8260\n",
      "Epoch 286/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4007 - accuracy: 0.8361\n",
      "Epoch 287/400\n",
      "891/891 [==============================] - 0s 335us/step - loss: 0.4170 - accuracy: 0.8227\n",
      "Epoch 288/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.4146 - accuracy: 0.8249\n",
      "Epoch 289/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3894 - accuracy: 0.8418\n",
      "Epoch 290/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4016 - accuracy: 0.8339\n",
      "Epoch 291/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.3944 - accuracy: 0.8339\n",
      "Epoch 292/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.3916 - accuracy: 0.8406\n",
      "Epoch 293/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.4103 - accuracy: 0.8171\n",
      "Epoch 294/400\n",
      "891/891 [==============================] - 0s 366us/step - loss: 0.4020 - accuracy: 0.8272\n",
      "Epoch 295/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.3902 - accuracy: 0.8406\n",
      "Epoch 296/400\n",
      "891/891 [==============================] - 0s 425us/step - loss: 0.3810 - accuracy: 0.8384\n",
      "Epoch 297/400\n",
      "891/891 [==============================] - 0s 368us/step - loss: 0.4126 - accuracy: 0.8238\n",
      "Epoch 298/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.3997 - accuracy: 0.8283\n",
      "Epoch 299/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3935 - accuracy: 0.8384\n",
      "Epoch 300/400\n",
      "891/891 [==============================] - 0s 392us/step - loss: 0.4102 - accuracy: 0.8272\n",
      "Epoch 301/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3950 - accuracy: 0.8395\n",
      "Epoch 302/400\n",
      "891/891 [==============================] - 0s 378us/step - loss: 0.4089 - accuracy: 0.8294\n",
      "Epoch 303/400\n",
      "891/891 [==============================] - 0s 396us/step - loss: 0.3986 - accuracy: 0.8418\n",
      "Epoch 304/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.4039 - accuracy: 0.8204\n",
      "Epoch 305/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.4018 - accuracy: 0.8429\n",
      "Epoch 306/400\n",
      "891/891 [==============================] - 0s 392us/step - loss: 0.4079 - accuracy: 0.8215\n",
      "Epoch 307/400\n",
      "891/891 [==============================] - 0s 384us/step - loss: 0.3924 - accuracy: 0.8395\n",
      "Epoch 308/400\n",
      "891/891 [==============================] - 0s 384us/step - loss: 0.4028 - accuracy: 0.8373\n",
      "Epoch 309/400\n",
      "891/891 [==============================] - 0s 356us/step - loss: 0.3879 - accuracy: 0.8361\n",
      "Epoch 310/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.4107 - accuracy: 0.8249\n",
      "Epoch 311/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4106 - accuracy: 0.8249\n",
      "Epoch 312/400\n",
      "891/891 [==============================] - 0s 350us/step - loss: 0.3928 - accuracy: 0.8418\n",
      "Epoch 313/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3979 - accuracy: 0.8316\n",
      "Epoch 314/400\n",
      "891/891 [==============================] - 0s 336us/step - loss: 0.3790 - accuracy: 0.8373\n",
      "Epoch 315/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3918 - accuracy: 0.8373\n",
      "Epoch 316/400\n",
      "891/891 [==============================] - 0s 324us/step - loss: 0.3892 - accuracy: 0.8328\n",
      "Epoch 317/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.3985 - accuracy: 0.8283\n",
      "Epoch 318/400\n",
      "891/891 [==============================] - 0s 321us/step - loss: 0.4083 - accuracy: 0.8328\n",
      "Epoch 319/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.4003 - accuracy: 0.8294\n",
      "Epoch 320/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.4019 - accuracy: 0.8137\n",
      "Epoch 321/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.3854 - accuracy: 0.8418\n",
      "Epoch 322/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3925 - accuracy: 0.8462\n",
      "Epoch 323/400\n",
      "891/891 [==============================] - 0s 347us/step - loss: 0.3871 - accuracy: 0.8485\n",
      "Epoch 324/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3843 - accuracy: 0.8361\n",
      "Epoch 325/400\n",
      "891/891 [==============================] - 0s 338us/step - loss: 0.3816 - accuracy: 0.8462\n",
      "Epoch 326/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.3996 - accuracy: 0.8339\n",
      "Epoch 327/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3864 - accuracy: 0.8227\n",
      "Epoch 328/400\n",
      "891/891 [==============================] - 0s 360us/step - loss: 0.3888 - accuracy: 0.8406\n",
      "Epoch 329/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3907 - accuracy: 0.8440\n",
      "Epoch 330/400\n",
      "891/891 [==============================] - 0s 341us/step - loss: 0.3972 - accuracy: 0.8451\n",
      "Epoch 331/400\n",
      "891/891 [==============================] - 0s 342us/step - loss: 0.4020 - accuracy: 0.8316\n",
      "Epoch 332/400\n",
      "891/891 [==============================] - 0s 355us/step - loss: 0.4093 - accuracy: 0.8260\n",
      "Epoch 333/400\n",
      "891/891 [==============================] - 0s 357us/step - loss: 0.3872 - accuracy: 0.8350\n",
      "Epoch 334/400\n",
      "891/891 [==============================] - 0s 392us/step - loss: 0.3968 - accuracy: 0.8339\n",
      "Epoch 335/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3939 - accuracy: 0.8328\n",
      "Epoch 336/400\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.3989 - accuracy: 0.8339\n",
      "Epoch 337/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4157 - accuracy: 0.8171\n",
      "Epoch 338/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.4106 - accuracy: 0.8171\n",
      "Epoch 339/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.4049 - accuracy: 0.8204\n",
      "Epoch 340/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3929 - accuracy: 0.8350\n",
      "Epoch 341/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.4032 - accuracy: 0.8148\n",
      "Epoch 342/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.4032 - accuracy: 0.8316\n",
      "Epoch 343/400\n",
      "891/891 [==============================] - 0s 371us/step - loss: 0.4006 - accuracy: 0.8361\n",
      "Epoch 344/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3939 - accuracy: 0.8429\n",
      "Epoch 345/400\n",
      "891/891 [==============================] - 0s 367us/step - loss: 0.3909 - accuracy: 0.8429\n",
      "Epoch 346/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3968 - accuracy: 0.8294\n",
      "Epoch 347/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3946 - accuracy: 0.8462\n",
      "Epoch 348/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3933 - accuracy: 0.8429\n",
      "Epoch 349/400\n",
      "891/891 [==============================] - 0s 381us/step - loss: 0.3845 - accuracy: 0.8429\n",
      "Epoch 350/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.3966 - accuracy: 0.8462\n",
      "Epoch 351/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.3936 - accuracy: 0.8283\n",
      "Epoch 352/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3864 - accuracy: 0.8283\n",
      "Epoch 353/400\n",
      "891/891 [==============================] - 0s 354us/step - loss: 0.3922 - accuracy: 0.8249\n",
      "Epoch 354/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.4110 - accuracy: 0.8406\n",
      "Epoch 355/400\n",
      "891/891 [==============================] - 0s 351us/step - loss: 0.3842 - accuracy: 0.8272\n",
      "Epoch 356/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.3946 - accuracy: 0.8339\n",
      "Epoch 357/400\n",
      "891/891 [==============================] - 0s 375us/step - loss: 0.3912 - accuracy: 0.8406\n",
      "Epoch 358/400\n",
      "891/891 [==============================] - 0s 343us/step - loss: 0.3924 - accuracy: 0.8260\n",
      "Epoch 359/400\n",
      "891/891 [==============================] - 0s 430us/step - loss: 0.4072 - accuracy: 0.8294\n",
      "Epoch 360/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3829 - accuracy: 0.8451\n",
      "Epoch 361/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.4085 - accuracy: 0.8103\n",
      "Epoch 362/400\n",
      "891/891 [==============================] - 0s 376us/step - loss: 0.4036 - accuracy: 0.8272\n",
      "Epoch 363/400\n",
      "891/891 [==============================] - 0s 383us/step - loss: 0.3817 - accuracy: 0.8384\n",
      "Epoch 364/400\n",
      "891/891 [==============================] - 0s 369us/step - loss: 0.3946 - accuracy: 0.8373\n",
      "Epoch 365/400\n",
      "891/891 [==============================] - 0s 352us/step - loss: 0.3960 - accuracy: 0.8316\n",
      "Epoch 366/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.3908 - accuracy: 0.8350\n",
      "Epoch 367/400\n",
      "891/891 [==============================] - 0s 372us/step - loss: 0.3989 - accuracy: 0.8294\n",
      "Epoch 368/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.3981 - accuracy: 0.8294\n",
      "Epoch 369/400\n",
      "891/891 [==============================] - 0s 385us/step - loss: 0.3867 - accuracy: 0.8328\n",
      "Epoch 370/400\n",
      "891/891 [==============================] - 0s 377us/step - loss: 0.4068 - accuracy: 0.8384\n",
      "Epoch 371/400\n",
      "891/891 [==============================] - 0s 359us/step - loss: 0.3926 - accuracy: 0.8361\n",
      "Epoch 372/400\n",
      "891/891 [==============================] - 0s 374us/step - loss: 0.3993 - accuracy: 0.8350\n",
      "Epoch 373/400\n",
      "891/891 [==============================] - 0s 388us/step - loss: 0.4108 - accuracy: 0.8294\n",
      "Epoch 374/400\n",
      "891/891 [==============================] - 0s 407us/step - loss: 0.3896 - accuracy: 0.8350\n",
      "Epoch 375/400\n",
      "891/891 [==============================] - 0s 393us/step - loss: 0.4115 - accuracy: 0.8283\n",
      "Epoch 376/400\n",
      "891/891 [==============================] - 0s 368us/step - loss: 0.3681 - accuracy: 0.8440\n",
      "Epoch 377/400\n",
      "891/891 [==============================] - 0s 364us/step - loss: 0.3910 - accuracy: 0.8305\n",
      "Epoch 378/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.3972 - accuracy: 0.8339\n",
      "Epoch 379/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3805 - accuracy: 0.8474\n",
      "Epoch 380/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.3999 - accuracy: 0.8440\n",
      "Epoch 381/400\n",
      "891/891 [==============================] - 0s 370us/step - loss: 0.3870 - accuracy: 0.8384\n",
      "Epoch 382/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3933 - accuracy: 0.8227\n",
      "Epoch 383/400\n",
      "891/891 [==============================] - 0s 387us/step - loss: 0.3859 - accuracy: 0.8406\n",
      "Epoch 384/400\n",
      "891/891 [==============================] - 0s 373us/step - loss: 0.3912 - accuracy: 0.8316\n",
      "Epoch 385/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3996 - accuracy: 0.8328\n",
      "Epoch 386/400\n",
      "891/891 [==============================] - 0s 361us/step - loss: 0.3943 - accuracy: 0.8339\n",
      "Epoch 387/400\n",
      "891/891 [==============================] - 0s 353us/step - loss: 0.4006 - accuracy: 0.8238\n",
      "Epoch 388/400\n",
      "891/891 [==============================] - 0s 344us/step - loss: 0.4051 - accuracy: 0.8260\n",
      "Epoch 389/400\n",
      "891/891 [==============================] - 0s 358us/step - loss: 0.3949 - accuracy: 0.8406\n",
      "Epoch 390/400\n",
      "891/891 [==============================] - 0s 371us/step - loss: 0.4131 - accuracy: 0.8204\n",
      "Epoch 391/400\n",
      "891/891 [==============================] - 0s 363us/step - loss: 0.3979 - accuracy: 0.8429\n",
      "Epoch 392/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 356us/step - loss: 0.3872 - accuracy: 0.8294\n",
      "Epoch 393/400\n",
      "891/891 [==============================] - 0s 345us/step - loss: 0.4011 - accuracy: 0.8316\n",
      "Epoch 394/400\n",
      "891/891 [==============================] - 0s 337us/step - loss: 0.3973 - accuracy: 0.8361\n",
      "Epoch 395/400\n",
      "891/891 [==============================] - 0s 346us/step - loss: 0.4005 - accuracy: 0.8406\n",
      "Epoch 396/400\n",
      "891/891 [==============================] - 0s 331us/step - loss: 0.3939 - accuracy: 0.8238\n",
      "Epoch 397/400\n",
      "891/891 [==============================] - 0s 333us/step - loss: 0.3934 - accuracy: 0.8395\n",
      "Epoch 398/400\n",
      "891/891 [==============================] - 0s 327us/step - loss: 0.3922 - accuracy: 0.8361\n",
      "Epoch 399/400\n",
      "891/891 [==============================] - 0s 328us/step - loss: 0.3944 - accuracy: 0.8283\n",
      "Epoch 400/400\n",
      "891/891 [==============================] - 0s 334us/step - loss: 0.3878 - accuracy: 0.8272\n"
     ]
    }
   ],
   "source": [
    "Contador2 = pd.DataFrame()\n",
    "\n",
    "submission_NN4= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "Activacion= [\"relu\",'sigmoid']\n",
    "\n",
    "Neuronas = [25, 50, 100] #,'300']\n",
    "\n",
    "Capas = [1, 2] #,4]\n",
    "\n",
    "\n",
    "\n",
    "for activacion in Activacion:\n",
    "    for neurona in Neuronas:\n",
    "        for capa in Capas:\n",
    "            \n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print (str(str(activacion)+', '+ str(neurona)+', '+str(capa)))\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "         \n",
    "            result,data = NN_0(activacion, neurona, capa)\n",
    "            Contador2[str(str(activacion)+', '+ str(neurona)+', '+str(capa))] = result\n",
    "            submission_NN4[str(str(activacion)+', '+ str(neurona)+', '+str(capa))]=data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relu, 25, 1</th>\n",
       "      <th>relu, 25, 2</th>\n",
       "      <th>relu, 50, 1</th>\n",
       "      <th>relu, 50, 2</th>\n",
       "      <th>relu, 100, 1</th>\n",
       "      <th>relu, 100, 2</th>\n",
       "      <th>sigmoid, 25, 1</th>\n",
       "      <th>sigmoid, 25, 2</th>\n",
       "      <th>sigmoid, 50, 1</th>\n",
       "      <th>sigmoid, 50, 2</th>\n",
       "      <th>sigmoid, 100, 1</th>\n",
       "      <th>sigmoid, 100, 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.502421</td>\n",
       "      <td>0.504699</td>\n",
       "      <td>0.534049</td>\n",
       "      <td>0.524286</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.546473</td>\n",
       "      <td>0.453064</td>\n",
       "      <td>0.463849</td>\n",
       "      <td>0.469466</td>\n",
       "      <td>0.458614</td>\n",
       "      <td>0.468176</td>\n",
       "      <td>0.458679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.785414</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>0.775596</td>\n",
       "      <td>0.784011</td>\n",
       "      <td>0.781206</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.795231</td>\n",
       "      <td>0.789621</td>\n",
       "      <td>0.793829</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>0.799439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relu, 25, 1  relu, 25, 2  relu, 50, 1  relu, 50, 2  relu, 100, 1  \\\n",
       "0     0.502421     0.504699     0.534049     0.524286      0.633643   \n",
       "1     0.785414     0.791024     0.775596     0.784011      0.781206   \n",
       "\n",
       "   relu, 100, 2  sigmoid, 25, 1  sigmoid, 25, 2  sigmoid, 50, 1  \\\n",
       "0      0.546473        0.453064        0.463849        0.469466   \n",
       "1      0.782609        0.795231        0.789621        0.793829   \n",
       "\n",
       "   sigmoid, 50, 2  sigmoid, 100, 1  sigmoid, 100, 2  \n",
       "0        0.458614         0.468176         0.458679  \n",
       "1        0.792426         0.791024         0.799439  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contador2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>relu, 25, 1</th>\n",
       "      <th>relu, 25, 2</th>\n",
       "      <th>relu, 50, 1</th>\n",
       "      <th>relu, 50, 2</th>\n",
       "      <th>relu, 100, 1</th>\n",
       "      <th>relu, 100, 2</th>\n",
       "      <th>sigmoid, 25, 1</th>\n",
       "      <th>sigmoid, 25, 2</th>\n",
       "      <th>sigmoid, 50, 1</th>\n",
       "      <th>sigmoid, 50, 2</th>\n",
       "      <th>sigmoid, 100, 1</th>\n",
       "      <th>sigmoid, 100, 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  relu, 25, 1  relu, 25, 2  relu, 50, 1  relu, 50, 2  \\\n",
       "891           892          0.0          0.0          0.0          0.0   \n",
       "892           893          0.0          1.0          0.0          1.0   \n",
       "893           894          0.0          0.0          0.0          0.0   \n",
       "894           895          0.0          0.0          0.0          0.0   \n",
       "895           896          1.0          0.0          1.0          1.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1304         1305          0.0          0.0          0.0          0.0   \n",
       "1305         1306          1.0          1.0          1.0          1.0   \n",
       "1306         1307          0.0          0.0          0.0          0.0   \n",
       "1307         1308          0.0          0.0          0.0          0.0   \n",
       "1308         1309          1.0          1.0          1.0          1.0   \n",
       "\n",
       "      relu, 100, 1  relu, 100, 2  sigmoid, 25, 1  sigmoid, 25, 2  \\\n",
       "891            0.0           0.0             0.0             0.0   \n",
       "892            0.0           1.0             0.0             1.0   \n",
       "893            0.0           0.0             0.0             0.0   \n",
       "894            0.0           0.0             0.0             0.0   \n",
       "895            1.0           1.0             1.0             1.0   \n",
       "...            ...           ...             ...             ...   \n",
       "1304           0.0           0.0             0.0             0.0   \n",
       "1305           1.0           1.0             1.0             1.0   \n",
       "1306           0.0           0.0             0.0             0.0   \n",
       "1307           0.0           0.0             0.0             0.0   \n",
       "1308           1.0           1.0             1.0             1.0   \n",
       "\n",
       "      sigmoid, 50, 1  sigmoid, 50, 2  sigmoid, 100, 1  sigmoid, 100, 2  \n",
       "891              0.0             0.0              0.0              0.0  \n",
       "892              0.0             0.0              0.0              0.0  \n",
       "893              0.0             0.0              0.0              0.0  \n",
       "894              0.0             0.0              0.0              0.0  \n",
       "895              0.0             1.0              1.0              1.0  \n",
       "...              ...             ...              ...              ...  \n",
       "1304             0.0             0.0              0.0              0.0  \n",
       "1305             1.0             1.0              1.0              1.0  \n",
       "1306             0.0             0.0              0.0              0.0  \n",
       "1307             0.0             0.0              0.0              0.0  \n",
       "1308             1.0             1.0              1.0              1.0  \n",
       "\n",
       "[418 rows x 13 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigmoid, 100, 2</th>\n",
       "      <th>sigmoid, 25, 1</th>\n",
       "      <th>sigmoid, 50, 1</th>\n",
       "      <th>sigmoid, 50, 2</th>\n",
       "      <th>relu, 25, 2</th>\n",
       "      <th>sigmoid, 100, 1</th>\n",
       "      <th>sigmoid, 25, 2</th>\n",
       "      <th>relu, 25, 1</th>\n",
       "      <th>relu, 50, 2</th>\n",
       "      <th>relu, 100, 2</th>\n",
       "      <th>relu, 100, 1</th>\n",
       "      <th>relu, 50, 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.458679</td>\n",
       "      <td>0.453064</td>\n",
       "      <td>0.469466</td>\n",
       "      <td>0.458614</td>\n",
       "      <td>0.504699</td>\n",
       "      <td>0.468176</td>\n",
       "      <td>0.463849</td>\n",
       "      <td>0.502421</td>\n",
       "      <td>0.524286</td>\n",
       "      <td>0.546473</td>\n",
       "      <td>0.633643</td>\n",
       "      <td>0.534049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.799439</td>\n",
       "      <td>0.795231</td>\n",
       "      <td>0.793829</td>\n",
       "      <td>0.792426</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>0.789621</td>\n",
       "      <td>0.785414</td>\n",
       "      <td>0.784011</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.781206</td>\n",
       "      <td>0.775596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigmoid, 100, 2  sigmoid, 25, 1  sigmoid, 50, 1  sigmoid, 50, 2  \\\n",
       "0         0.458679        0.453064        0.469466        0.458614   \n",
       "1         0.799439        0.795231        0.793829        0.792426   \n",
       "\n",
       "   relu, 25, 2  sigmoid, 100, 1  sigmoid, 25, 2  relu, 25, 1  relu, 50, 2  \\\n",
       "0     0.504699         0.468176        0.463849     0.502421     0.524286   \n",
       "1     0.791024         0.791024        0.789621     0.785414     0.784011   \n",
       "\n",
       "   relu, 100, 2  relu, 100, 1  relu, 50, 1  \n",
       "0      0.546473      0.633643     0.534049  \n",
       "1      0.782609      0.781206     0.775596  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contador2=Contador2.sort_values(by=1, ascending=False, axis=1)\n",
    "Contador2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un df para la entrega a Kaggle\n",
    "submission_Best_NN_Original= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "arr = np.array(submission_NN4['sigmoid, 100, 2'])\n",
    "data=arr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived\n",
       "891           892         0\n",
       "892           893         0\n",
       "893           894         0\n",
       "894           895         0\n",
       "895           896         1\n",
       "...           ...       ...\n",
       "1304         1305         0\n",
       "1305         1306         1\n",
       "1306         1307         0\n",
       "1307         1308         0\n",
       "1308         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_Best_NN_Original['Survived']= data\n",
    "submission_Best_NN_Original['Survived'] = submission_Best_NN_Original['Survived'].astype(int)\n",
    "submission_Best_NN_Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_Best_NN_Original.to_csv((\"submission_Best_NN_Original2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un 0.78947 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id34'/>\n",
    "\n",
    "### [3.4. Combinación del modelo de red neuronal](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se obtiene una combinación de los 6 resultados con redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>891</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>892</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>893</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>894</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1304</td>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1305</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1306</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1307</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1308</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived\n",
       "891           892         0\n",
       "892           893         0\n",
       "893           894         0\n",
       "894           895         0\n",
       "895           896         1\n",
       "...           ...       ...\n",
       "1304         1305         0\n",
       "1305         1306         1\n",
       "1306         1307         0\n",
       "1307         1308         0\n",
       "1308         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_NN42= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "submission_NN42['Survived'] = (np.round((submission_NN4['sigmoid, 100, 2'] + submission_NN4['sigmoid, 25, 1'] + submission_NN4['sigmoid, 50, 1'] + submission_NN4['sigmoid, 50, 2'] + submission_NN4['relu, 25, 2'] + submission_NN4['sigmoid, 100, 1'])/6)).astype(int) \n",
    "submission_NN42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN42.to_csv((\"submission_sum_NN42.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta predicción ha conseguido un 0.78947 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de muchos otros intentos no parece que ninguna estructura en la red neuronal pueda mejorar estos resultados.\n",
    "\n",
    "Entendemos que para seguir mejorando, deberíamos volver a modificar aspectos de la limpieza original de datos o crear nuevas combinaciones de elementos a partir de los ya existentes. \n",
    "\n",
    "Aun así, una predicción del 0.80382, que nos situa entre los 9% mejores de los 23000 participantes en este concurso de Kaggle nos parece bastante aceptable, de momento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

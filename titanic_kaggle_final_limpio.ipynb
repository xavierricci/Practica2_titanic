{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">TIPOLOGÍA Y CICLO DE VIDA DE LOS DATOS</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster en Ciencia de Datos</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "## \n",
    "\n",
    "#### Alumnos: Xavier Ricci y Guillermo Monzón\n",
    "\n",
    "## PRÁCTICA 2:\n",
    "#### CONTENIDO  \n",
    "\n",
    "<div id='id00'/>\n",
    "\n",
    "\n",
    "[1. PRESENTACIÓN DE LA PRÁCTICA Y DESCRIPCIÓN DEL *DATASET*](#id1)\n",
    "\n",
    "[2. LIMPIEZA DE DATOS](#id2)\n",
    "\n",
    "   [2.1 Pclass](#id21)  \n",
    "   [2.2 Name](#id22)   \n",
    "   [2.3 Sex](#id23)  \n",
    "   [2.4 Sibsp](#id24)  \n",
    "   [2.5 Parch](#id25)   \n",
    "   [2.6 Age](#id26)  \n",
    "   [2.7 Fare](#id27)  \n",
    "   [2.8 Ticket](#id28)  \n",
    "   [2.9 Cabin](#id29)   \n",
    "   [2.10 Embarked](#id210)   \n",
    "     \n",
    "[3. ANÁLISIS DE LOS DATOS Y CONCLUSIONES](#id3)\n",
    "\n",
    "   [3.1. Modelos de regresión](#id31)    \n",
    "   [3.2. Combinación de modelos de regresión](#id32)  \n",
    "   [3.3. Modelo Neuronal](#id33)  \n",
    "   [3.4. Combinación de modelos neuronales](#id34)     \n",
    "\n",
    "* * * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id1'/> \n",
    "\n",
    "### [1. PRESENTACIÓN DE LA PRÁCTICA Y DESCRIPCIÓN DEL *DATASET* ](#id00)\n",
    "\n",
    "Hemos escogido estudiar el dataset del Titanic de kaggle.com, porque se trata de un reto en el que participan personas que se dedican al análisis de datos de todo el mundo y nos queríamos participar en este reto. Se trata de una forma de medir nuestras capacidades dentro de este mundo profesional, ya que, aunque esta es una competición para principiantes, en ella participan muchos profesionales y equipos de personas. \n",
    "Nuestro reto inicial, era conseguir estar dentro de la lista del 10% con mejores resultados de los 23 mil equipos participantes. Cabe destacar que, aunque la mayoría de personas en esta lista están participando con códigos propios, también hay muchas personas que utilizan métodos tramposos, ya sea simplemente copiando los resultados finales y consiguiendo un imposible 100% de aciertos o utilizando los códigos de otros con alto rendimiento. \n",
    "Es de lógica entender que en cualquier situación natural estamos hablando de probabilidades a partir de una cantidad limitada de datos. Aunque se tuvieran miles de datos de cada uno de los pasajeros del Titanic una hora antes del accidente, sería imposible predecir todas las circunstancias que llevan a la supervivencia de cada una de las personas. Los que resbalaron, los que decidieron ceder su asiente en un bote salvavidas, los que pisaron a otra persona para ocupar su lugar… son circunstancias impredecibles que no se pueden calcular a partir de una docena de características. \n",
    "Entendemos que a base de mandar resultados se puede ir ajustando las respuestas a las correctas, aunque eso no sería la creación de un modelo de predicción, sino una especie de proceso de descubrimiento de una clave, y este no es nuestro objetivo. \n",
    "A decir verdad, nuestra sensación es que solo con los datos originales, nos parece fantástico poder superar el 80% de aciertos. \n",
    "\n",
    "Para llevar a cabo este estudio, los responsables de Kaggle, nos ofrecen un listado de  891 personas con 11 características y el resultado de supervivencia o no de cada uno de ellos. A partir de estos datos se nos propone predecir la supervivencia de 418 pasajeros a partir de las mismas 11 caracteristicas. \n",
    " Para decidir los datos de interés a analizar entendemos que primero es necesario conocer los datos en profundidad y ver su estado, así, que empezamos directamente con el limpiado de los datos, para posteriormente decidir cuales son realmente útiles para nuestra predicción. \n",
    "\n",
    "Los atributos del dataset son los siguientes:  \n",
    "\n",
    "- **PassengerId:** \n",
    "- **Survived:** indicador de supervivencia (0 - sobrevive / 1 - muere).\n",
    "- **Pclass:** indicador de la clase del billete (1 - primera / 2 - segunda / 3 - tercera).\n",
    "- **Name:** nombre del pasajero.\n",
    "- **Sex:** sex (male - hombre  / female - mujer).\n",
    "- **Age**: edad en años (si es menor de un año se estima de forma fraccionaria).\n",
    "- **SibSp:** \n",
    "- **Parch:**\n",
    "- **Ticket:** número de ticket.\n",
    "- **Fare:** tarifa.\n",
    "- **Cabin:** número de camarote.\n",
    "- **Embarked:** puerto de embarque (C - Cherbourg / Q - Queenstown / S - Southamton).\n",
    "\n",
    "Así pues, una vez realizado un proceso de limpieza del conjunto de datos trataremos de determinar cómo pudo afectar a las posibilidades de superviviencia del pasaje del Titanic en función de sus caracterísitcas: edad, sexo, clase, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as plot\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset import\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos ambos *datasets* para tener una visión conjunta de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos datasets\n",
    "fullData = pd.concat([train, test], ignore_index=True, sort=False)\n",
    "fullData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData_NA = fullData.isna().sum()\n",
    "train_NA = train.isna().sum()\n",
    "test_NA = test.isna().sum()\n",
    "\n",
    "pd.concat([train_NA, test_NA, fullData_NA], axis=1, sort = False, keys = ['train NA', 'test NA', 'fullData NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que entre los datos hay muchos datos vacíos, especialmente en *Cabin* y en *Age*, también observamos 2 valores vacíos en *Embarked* y uno en *Fare*. Todos ellos serán tratados adecuadamente en el apartado de limpieza de datos.  \n",
    "\n",
    "También vemos que de las 11 atributos 2 son floats, 5 son integers y 5 son objetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vemos algunas distribuciones iniciales de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData['Survived'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un 62% de los pasajeros murieron mientras que un 38 % se salvaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, podemos observar como un 63% de los pasajeros de PRIMERA CLASE sobrevivió al naufragio. Un 47 % para SEGUNDA CLASE y los que viajaban en TERCERA CLASE tan sólo sobrevivió un 24 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se observa que las mujeres sobreviven significativamente más que los hombres.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion relacionamos algunas variables, para ver su importancia en la supervivencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporando la **edad** a este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soberviven = 'soberviven'\n",
    "mueren = 'mueren'\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
    "mujeres = fullData[fullData['Sex']=='female']\n",
    "hombres = fullData[fullData['Sex']=='male']\n",
    "ax = sns.distplot(mujeres[mujeres['Survived']==1].Age.dropna(), bins=18, label = soberviven, ax = axes[0], kde =False)\n",
    "ax = sns.distplot(mujeres[mujeres['Survived']==0].Age.dropna(), bins=40, label = mueren, ax = axes[0], kde =False)\n",
    "ax.legend()\n",
    "ax.set_title('Mujeres')\n",
    "ax = sns.distplot(hombres[hombres['Survived']==1].Age.dropna(), bins=18, label = soberviven, ax = axes[1], kde = False)\n",
    "ax = sns.distplot(hombres[hombres['Survived']==0].Age.dropna(), bins=40, label = mueren, ax = axes[1], kde = False)\n",
    "ax.legend()\n",
    "_ = ax.set_title('Hombres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los niños también tienen tasas de supervivencia muy superiores comparados con los adultos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra característica que podemos observar de un análisis previo de los datos es que lo pasajeros que embarcan en el puerto francés de Chebourg sobreviven de forma notoriamente superior a los pasajeros del resto de puertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Embarked', y='Survived', data=fullData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El puerto de de embarque también parece ser un factor importante a la hora de predecir la supervivencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id2'/>\n",
    "\n",
    "## [2. LIMPIEZA DE DATOS](#id00)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la limpieza y ajuste de los datos vamos a ir tratando variable a variable del dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos eliminando las variables *PassengerId* y *Survived*, pues no aportan nada para el análisis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id21'/> \n",
    "\n",
    "### [2.1 Pclass](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fullData[fullData['Pclass'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id22'/> \n",
    "\n",
    "### [2.2 Name](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fullData[fullData['Name'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la varible *name* podemos determinar el titutlo que nos va a ser útil más adelante. Procedemos a extraer esta información. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData['Title'] = fullData.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(fullData['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Agunas notas sobre los títulos:\n",
    "\n",
    "Nobles: the Countess, lady is what you use to address someone of Nobility.  \n",
    "\n",
    "Mlle = Miss\n",
    "\n",
    "Madame = Mrs.  Usually, a servant (in Britain) addersses her Mistress as Madame.  But only if the mistress is married. \n",
    "\n",
    "\n",
    "Master = title for an underage male. If a person is under 18. En el caso del titanic todos los masters son de menos de 14.5 años. \n",
    "\n",
    "Colonel is a honorary title of conferred by several states in the US and certain military units of the Commonwealth of Nations.\n",
    "\n",
    "\n",
    "\"Ms\" is a recent term for those ladies who don't think anyone needs to know whether they are married or not, like the generic \n",
    "\n",
    "\n",
    "Jonkheer is an honorific in the Low Countries denoting the lowest rank within the nobility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que relación tienen con el índice de supervivencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobrevivenxtitulo(titulo):\n",
    "    a=(len(fullData[(fullData['Survived']==0) & (fullData['Title']==titulo)]))\n",
    "    b=(len(fullData[(fullData['Survived']==1) & (fullData['Title']==titulo)]))\n",
    "    print(f\" de {(a+b)}, {titulo} sobreviven: {b}, un {b/(a+b)}\")\n",
    "\n",
    "titulos = pd.unique(fullData['Title'])\n",
    "for titulo in titulos:\n",
    "    sobrevivenxtitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos datos esperamos extraer la importancia de la clase y la profesion, para poderlos agrupar en conjuntos más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observamos los siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los hombres:\n",
    "\n",
    "Sr (Adultos en general): Con muy poco indice de supervivencia. Apenas el 15% sobreviven.\n",
    "\n",
    "Master (Jovenes): Aunque a primera vista parecia que Master podia referirse a la clase social aparte de a la edad comprobamos a continuacion que simplemente se refiere a los menores de 15 anyos. De los jovenes el 57% sobreviven\n",
    "\n",
    "Reverendos: Vemos que todos mueren (6 de 6 ya empieza a ser un valor interesante) 0% sobreviven\n",
    "\n",
    "Doctores: 2 de 6 el 33% sobreviven\n",
    "\n",
    "Major, Col y Capt (Militares) vemos que los rangos militares sobreviven en un 3/5, un 60% sobreviven\n",
    "\n",
    "Los nobles: Sir, Don y Jonkheer 1/3 baja al 33.3% sobreviven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las mujeres:\n",
    "\n",
    "Mrs y Mme (Casadas): Con muy alto indice de supervivencia del 79% sobreviven\n",
    "\n",
    "Miss y Mille (Solteras 0 y 63 años): 69% sobreviven\n",
    "\n",
    "El resto son muy pocos casos para generalizar pero vemos que una doctora sobrevive y que la Lady y la Countess sobreviven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset import\n",
    "dataTrainXY = pd.read_csv(\"./train.csv\")\n",
    "dataTestX = pd.read_csv(\"./test.csv\")\n",
    "frames = [dataTrainXY,dataTestX]\n",
    "DF = pd.concat(frames, ignore_index=True, sort=False)\n",
    "DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo = DF.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.', expand=False)\n",
    "len(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los valores originales:  'Mr', 'Mrs', 'Miss', 'Master', 'Don','Sir','Jonkheer','Major', 'Capt', 'Col', 'Rev', 'Dr', 'Mme', 'Ms', 'Mlle', 'Lady',    'the Countess']\n",
    "\n",
    "# Las agrupaciones propuestas:\n",
    "# Major, Col y Capt = Militares\n",
    "# Sir, Don, Jonkheer, Lady y Countess  = Aristocratas\n",
    "# Mrs y Mme (Casadas)\n",
    "# Miss y Mlle (Solteras) tb incluyo Ms (porque entiendo que se trata de mujeres solas que querian evitar la presion social de no estar casadas)\n",
    "\n",
    "lista = []\n",
    "for word in titulo:\n",
    "    if word == 'Don':\n",
    "        lista.append('Arist')\n",
    "    elif word =='Sir':\n",
    "        lista.append('Arist')\n",
    "    elif word =='Jonkheer':\n",
    "        lista.append('Arist')\n",
    "    \n",
    "    elif word == 'Major':\n",
    "        lista.append('Army')\n",
    "    elif word =='Col':\n",
    "        lista.append('Army')\n",
    "    elif word =='Capt':\n",
    "        lista.append('Army')\n",
    "            \n",
    "        \n",
    "    elif word =='Mme':\n",
    "        lista.append('Mrs')      \n",
    "        \n",
    "    elif word =='Mlle':\n",
    "        lista.append('Miss')      \n",
    "        \n",
    "    elif word =='Ms':\n",
    "        lista.append('Miss')  \n",
    "        \n",
    "    elif word == 'Lady':\n",
    "        lista.append('Arist')\n",
    "    elif word == 'the Countess':\n",
    "        lista.append('Arist')\n",
    "    elif word == 'Dona':\n",
    "        lista.append('Arist')\n",
    "          \n",
    "    else:\n",
    "        lista.append(word)\n",
    "print(len(lista))\n",
    "print(pd.unique(lista))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Title'] = lista\n",
    "DF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos la edad máxima de los *Master* y nos aseguramos que no haya niños no *Master*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(DF[DF['Title']==\"Master\"].Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos a estos niños en *Master* para unificar el criterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\") , \"Title\" ] = 'Master'\n",
    "DF[(DF[\"Age\"]<15)&(DF[\"Title\"]!=\"Master\")&(DF[\"Sex\"]==\"male\")]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id23'/> \n",
    "\n",
    "### [2.3 Sex](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Sex* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Sex\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id24'/> \n",
    "\n",
    "### [2.4 SibSp](#id00)\n",
    "Número de hermanos / esposas-maridos a bordo. 0 si se viajaba solo.  \n",
    "Definición en el dataset:  \n",
    " *Sibling = brother, sister, stepbrother, stepsister\n",
    " *Spouse = husband, wife (mistresses and fiancés were ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Sibsp* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"SibSp\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id25'/> \n",
    "\n",
    "### [2.5 Parch](#id00)\n",
    "Número de padres / niños. 0 si se viajaba soloo niños con nanny.\n",
    "\n",
    "Definición en el dataset:  \n",
    " *Parent = mother, father\n",
    " *Child = daughter, son, stepdaughter, stepson\n",
    " *Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Parch* no tiene datos vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Parch\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id26'/> \n",
    "\n",
    "### [2.6 Age](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La problemática de la variable *Age*, como hemos visto en el apartado de anterior, estriba en que tiene un número elevado de valores perdidos, 263 concretamente. A continuación procedemos a resolver esta problemática asignando un valor para cada uno de los registros desconocidos de la variable edad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para rellenar los datos vacios con la máxima precisión posible, los agrupamos según el titulo par ver si existe alguna relación entre este y la edad, como hemos visto que sucedia con los *Master*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerEdadXTitulo(titulo):\n",
    "    medianaDeEdad = np.median(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    conEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    sinEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].isna())])\n",
    "    \n",
    "    print(f\"La mediana de edad de los {conEdad} {titulo} con Age es de {medianaDeEdad}. Faltan: {sinEdad} \")\n",
    "    \n",
    "for titulo in (pd.unique(DF.Title)):\n",
    "    VerEdadXTitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que efecticamente los titulos estan relacionados con la edad. Así que utilizamos esta referencia para rellenar los datos.\n",
    "Primero corregimos los que hay menos casos: *Dr* y *Master*, asignándoles la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF['Title']=='Master') & (DF[\"Age\"].isna()), \"Age\" ] = np.median(DF[(DF['Title']=='Master') & (DF[\"Age\"].notnull())]['Age'])\n",
    "DF[(DF['Title']=='Master') & (DF[\"Age\"].isna())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF['Title']=='Dr') & (DF[\"Age\"].isna()), \"Age\" ] = np.median(DF[(DF['Title']=='Dr') & (DF[\"Age\"].notnull())]['Age'])\n",
    "DF[(DF['Title']=='Dr') & (DF[\"Age\"].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las edades no registradas de pasajeros con los títulos de Mr, Mrs y Miss aplicaremos una regresion lineal, a partir de las variables *Pclass*, *Fare* y *Family*. Esta última la crearemos a partir de las variables *SibSP* y *Parch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la nueva variable *Family*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Family'] = DF.SibSp + DF.Parch\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder hacer la regresion nos aseguramos primero de que no hay elementos vacios en las columnas que utilizaremos para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Pclass\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Family\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Fare\"].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF[DF[\"Fare\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para completar este valor vacío en el precio del billete, utilizaremos la mediana del precio de pasajeros con las mismas características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianaPrecio = np.median(DF[(DF['Title']==\"Mr\") &   (DF['Pclass']==3)  &  (DF['Fare'].notnull()) &  (DF['Sex']=='male') & (DF[\"Embarked\"]=='S') & (DF[\"SibSp\"]== 0)& (DF[\"Parch\"]== 0)]['Fare'])\n",
    "\n",
    "DF.loc[((DF['Title']==\"Mr\") &   (DF['Pclass']==3)  &  (DF['Fare'].isna()) &  (DF['Sex']=='male') & (DF[\"Embarked\"]=='S') & (DF[\"SibSp\"]== 0)& (DF[\"Parch\"]== 0)) , \"Fare\" ] = medianaPrecio\n",
    "\n",
    "DF[DF[\"Fare\"].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos aplicar la regresión lineal y asignar la edad calculada a cada uno de los pasajeros correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#creamos un grupo segun el titulo con la edad sabida Known Age\n",
    "def RegresionEdad(Titulo):\n",
    "    KA = DF[(DF['Title']==Titulo) & (DF[\"Age\"].notnull())]\n",
    "\n",
    "\n",
    "    X = KA[['Pclass','Family','Fare']]\n",
    "    Y = KA['Age']\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X, Y)\n",
    "    print(clf.coef_)\n",
    "    print(clf.intercept_)\n",
    "\n",
    "    #creamos un grupo segun el titulo con la edad desconocida Unknown Age\n",
    "    UA = DF[(DF['Title']==Titulo) & (DF[\"Age\"].isna())]\n",
    "    X = UA[['Pclass', 'Family','Fare']]\n",
    "    Y=clf.predict(X)\n",
    "    p=0\n",
    "    for y in Y:\n",
    "        if y < 0:\n",
    "            Y[p]=0.555\n",
    "        p=p+1\n",
    "    print(Y)\n",
    "\n",
    "    DF.loc[((DF['Title']==Titulo) & (DF[\"Age\"].isna())) , \"Age\" ] = Y\n",
    "\n",
    "    print(len(DF[(DF['Title']==Titulo) & (DF[\"Age\"].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegresionEdad(\"Mr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegresionEdad(\"Mrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegresionEdad(\"Miss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a hacer un último ajuste sobre la variable *Title*. De forma que tengamos la correspondiente equivalencia femenina para el valor *Master*. A estos valores los clasificaremos como *Girl*\n",
    "\n",
    "De igual modo vamos a crear una separación para los pasajeros mayores de 60. Clasificándolos como *MrSenior* para los hombres mayores de 60 años y *MrSSenior* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[((DF[\"Age\"]<15)&(DF[\"Title\"]==\"Miss\")) , \"Title\" ] = 'Girl'\n",
    "DF[(DF[\"Title\"]==\"Miss\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[((DF[\"Age\"]>60)&(DF[\"Title\"]==\"Mr\")) , \"Title\" ] = 'MrSenior'\n",
    "len(DF[(DF[\"Title\"]==\"MrSenior\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[((DF[\"Age\"]>60)&(DF[\"Title\"]==\"Mrs\")) , \"Title\" ] = 'MrSSenior'\n",
    "len(DF[(DF[\"Title\"]==\"MrSSenior\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recapitulando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VerEdadXTitulo(titulo):\n",
    "    medianaDeEdad = np.median(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    conEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].notnull())]['Age'])\n",
    "    sinEdad = len(DF[(DF['Title']==titulo) & (DF[\"Age\"].isna())])\n",
    "    \n",
    "    print(f\"La mediana de edad de los {conEdad} {titulo} con Age es de {medianaDeEdad}. Faltan: {sinEdad} \")\n",
    "    \n",
    "for titulo in (pd.unique(DF.Title)):\n",
    "    VerEdadXTitulo(titulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id27'/> \n",
    "\n",
    "### [2.7 Fare](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos podido observar que hay un grupo de personas que no pagan el billete y que en la variable Ticket aparece la anotación LINE. En general son hombres que viajan solos y embarcaron en el puerto de Southamton y que en su mayoria murieron (al margen de la clase en que viajaran). Se podría deducir de ello que se trata de personas con alguna relacion especial con la compañía propietaria del barco. Se opta por identficarles como Empleados en la variable Title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF[DF[\"Fare\"]<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Fare\"]<1), \"Title\" ] = 'Empleados'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, para no distorsionar la variable *Fare* se decide asignarles,en este caso, el valor de la media de la variable *Fare* según la clase a la que pertenezcan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==1), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==1)][\"Fare\"])\n",
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==2), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==2)][\"Fare\"])\n",
    "DF.loc[(DF[\"Fare\"]<1)&(DF[\"Pclass\"]==3), \"Fare\" ] = np.mean(DF[(DF[\"Pclass\"]==3)][\"Fare\"])\n",
    "#DF[DF[\"Title\"]==\"Empleados\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez eliminado el precio ilógico de 0, vemos que hay un outlayer entre los precios altos, lo analizamos y lo justamos a los siguientes precios más elevados para evitar que se distorsione el analisis general de este dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[(DF[\"Fare\"] == max(DF[\"Fare\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next tarife after 512 is:\n",
    "DF[(DF[\"Fare\"]== max(DF[DF[\"Fare\"] != max(DF[\"Fare\"])][\"Fare\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF[\"Fare\"] == max(DF[\"Fare\"])), \"Fare\" ] =  263\n",
    "max(DF[\"Fare\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un siguiente paso categorizamos los precios para facilitar la posterior creacion de modelos de prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['precio'] = pd.qcut(DF[\"Fare\"], 10, labels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "DF.boxplot(['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id28'/> \n",
    "\n",
    "### [3.8 Ticket](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Ticket\"].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al intentar analizar los Tickets en detalle vemos que se trata de un dato muy confuso que en algunos casos es numérico y en otros es alfanumérico, para unificar el criterio de forma simple, recogemos solo los numeros finales ignorando las letras iniciales. Posteriormente, si finalmente decidimos que este aspecto es relevante podría ser interesante volver a este apartado para recoger también las letras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puesto que la mayoria no tienen letras recuperamos solo el ultimo numero.\n",
    "\n",
    "billetes = []\n",
    "for ticket in DF[\"Ticket\"]:\n",
    "    billetes.append(ticket.split()[-1])\n",
    "    \n",
    "len(billetes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['billete'] = billetes\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF['billete']=='LINE'), \"billete\" ] = '99999'\n",
    "DF['billete'] = DF['billete'].astype(int)\n",
    "plt.figure()\n",
    "DF.boxplot(['billete'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corregimos los valores extremos dandoles un valor cercano al siguiente valor máximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[(DF['billete']>400000), \"billete\" ] = 400000\n",
    "plt.figure()\n",
    "DF.boxplot(['billete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(DF.billete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DF\n",
    "x_var = 'billete'\n",
    "groupby_var = 'Pclass'\n",
    "df_agg = DF.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [DF[x_var].values.tolist() for i, DF in df_agg]\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, 80, stacked=True, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(DF[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.xticks(ticks=bins[::3], labels=[round(b,1) for b in bins[::3]])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esta representacion visual, vemos que el número de billlete tiene claramente alguna relación con la clase, especialmente a partir del billete número 40000 aproximadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo esta apreciación visual categorizamos la variable *billete* en 5 grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "DF['billete'] = DF['billete'].astype(int)\n",
    "DF.loc[ DF['billete'] <= 40000, 'billete'] = 1\n",
    "DF.loc[(DF['billete'] > 40000) & (DF['billete'] <= 104000), 'billete'] = 2\n",
    "DF.loc[(DF['billete'] > 104000) & (DF['billete'] <= 170000), 'billete'] = 3\n",
    "DF.loc[(DF['billete'] > 170000) & (DF['billete'] <= 252000), 'billete'] = 4\n",
    "DF.loc[ DF['billete'] > 252000, 'billete'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DF\n",
    "x_var = 'billete'\n",
    "groupby_var = 'Pclass'\n",
    "df_agg = DF.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [DF[x_var].values.tolist() for i, DF in df_agg]\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, 5, stacked=True, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(DF[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "#plt.xticks(ticks=bins[::3], labels=[round(b,1) for b in bins[::3]])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id29'/> \n",
    "\n",
    "### [2.9 Cabin](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Cabin\"].isna()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponiendo que las letras hacen referencia a las distintas cubiertas del barco y considerando este hecho un factor primordial un la supervivencia, recogemos estos datos y rellenamos los desconocidos con la letra U de Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rellenamos los vacios con un codigo:\n",
    "for l in DF['Cabin']:\n",
    "    DF['Cabin'] = DF['Cabin'].fillna(\"U0\")\n",
    "len(DF[DF[\"Cabin\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(DF[\"Cabin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de estas letras, creamos una clasificación numérica para facilitar su analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planta = []\n",
    "letras = []    \n",
    "planta.append(DF['Cabin'])\n",
    "for letra in planta[0]:\n",
    "    if letra[0]== \"A\":\n",
    "        letras.append(1)\n",
    "    elif letra[0]== \"B\":\n",
    "        letras.append(2)  \n",
    "    elif letra[0]== \"C\":\n",
    "        letras.append(3)\n",
    "    elif letra[0]== \"D\":\n",
    "        letras.append(4)\n",
    "    elif letra[0]== \"E\":\n",
    "        letras.append(5)\n",
    "    elif letra[0]== \"F\":\n",
    "        letras.append(6)\n",
    "    elif letra[0]== \"G\":\n",
    "        letras.append(7)\n",
    "    else:\n",
    "        letras.append(8)\n",
    "        \n",
    "\n",
    "len(letras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['Planta'] = letras\n",
    "pd.unique(DF['Planta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prueba = DF[DF.Survived.notnull()]\n",
    "sns.barplot(x='Planta', y='Survived', data=Prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id210'/> \n",
    "\n",
    "### [2.10 Embarked](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable *Embarked* tan sólo tiene dos valores perdidos. Vamos a tratar darle un valor a estos dos registros a partir de los\n",
    "de la variable *Fare*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF[DF[\"Embarked\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[DF[\"Embarked\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesto que no hay rasgos que nos indiquen el lugar de embarque, elegimos el puerto donde subieron la mayoria de personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.loc[( DF[\"Embarked\"].isna()), \"Embarked\" ] = 'S'\n",
    "DF[DF[\"Embarked\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id3'/>\n",
    "\n",
    "# [3. Análisis de los datos y conclusiones](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar la limpieza y preparación de nuestro *dateset* realizamos unos últimos ajustes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2=DF\n",
    "len(DF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de probar modelos, para evitar el sobre entrenamiento, ahora que ya conocemos los datos seleccionados, seleccionamos los apartados que nos parecen más relevantes y eliminamos los que aportan menos informacion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2=DF2.drop('PassengerId', axis=1) # Esta informacion es irrelevante\n",
    "DF2=DF2.drop('Name', axis=1) # La informacion mas relevante ya esta en Title\n",
    "DF2=DF2.drop('SibSp', axis=1) # Esta informacion ya esta en Family\n",
    "DF2=DF2.drop('Parch', axis=1) # Esta informacion ya esta en Family\n",
    "DF2=DF2.drop('Ticket', axis=1) # Esta informacion ya esta en billete\n",
    "DF2=DF2.drop('Cabin', axis=1) # Esta informacion ya esta en Planta\n",
    "DF2=DF2.drop('Fare', axis=1) # Esta informacion ya esta en precio\n",
    "\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2['precio']=DF2['precio'].astype(int)\n",
    "DF2['Age']=DF2['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repasamos en primer lugar los datos con los que trabajamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion conventimos los datos categoricos en numeros creando dummies cuando sea necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titulos = pd.get_dummies(DF2['Title'], prefix = \"Titulo\")\n",
    "DF2 = pd.concat([DF2, Titulos], axis=1)\n",
    "DF2=DF2.drop('Title', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Puerto = pd.get_dummies(DF2['Embarked'], prefix = \"Puerto\")\n",
    "DF2 = pd.concat([DF2, Puerto], axis=1)\n",
    "DF2=DF2.drop('Embarked', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sexo = pd.get_dummies(DF2['Sex'], prefix = \"Sexo\")\n",
    "DF2 = pd.concat([DF2, Sexo], axis=1)\n",
    "DF2=DF2.drop('Sex', axis=1)\n",
    "DF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez finalizada la limpieza y preparación del *dataset* procedemos a separarlo para crear de nuevo los *dataset train* y *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = DF2[DF2.Survived.notnull()]\n",
    "Training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los datos Training (con información del target) creamos dos sets uno X con todos las caracteristicas y otro Y con el target (la supervivencia o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Training.loc[:, Training.columns != 'Survived']\n",
    "Y=Training.loc[:, Training.columns == 'Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, creamos dos *datasets* de subconjuntos de train y test. Uno para el entrenamiento de los modelos (X_train, y_train) y otro para su validacion (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También creamos un dataset con los datos limpios para hacer la predicción que se mandará a Kaggle al que llamamos XtestFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing = DF2[DF2.Survived.isnull()]\n",
    "XtestFinal=Testing.loc[:, Testing.columns != 'Survived']\n",
    "XtestFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuacion crearemos diversos modelos y comprobaremos su efectividad con la finanalidad de participar en la competición activa en Kaggle: \n",
    "\n",
    "  #### 1. Modelos de regresión.\n",
    "  #### 2. Combinación de modelos regresión.\n",
    "  #### 3. Modelo de redes neuronal.\n",
    "  #### 4. Combinación del modelo de red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id31'/>\n",
    "\n",
    "### [1. Modelos de regresión](#id00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestFinal = Testing.loc[:, Testing.columns != 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Escogemos las funciones con las que queremos generar modelos para predecir la supervivencia\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = LogisticRegressionCV()\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "# Creamos un vector en el que recogeremos los resultados de la precision de cada metodo en funcion de un proceso de cross validation sobre los datos X_train, y_train \n",
    "resultados =[]\n",
    "\n",
    "# Creamos un df para recoger los resultados de la prediccion final de cada uno de los metodos\n",
    "submission= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "models = [logreg, logreg_cv, rf, gboost]\n",
    "\n",
    "for model in models:\n",
    "    clf=model\n",
    "    Crossval = cross_val_score(clf,X_train, y_train.values.ravel(), cv = 5, scoring='accuracy')\n",
    "    #recogemos la precision de cada una de las 5 cross validation y también la media total.\n",
    "    resultados.append(Crossval)\n",
    "    resultados.append(np.mean(Crossval))\n",
    "    \n",
    "    # A continuacion, entrenamos el metodo una vez mas, pero ahora con todos los datos para cada uno de los metodos\n",
    "    # ravel() returns contiguous flattened array\n",
    "    clf.fit(X, Y.values.ravel())\n",
    "    \n",
    "    # A partir del metodo entrenado, se recoge una prediccion a partir de los datos sin taget para entregar, en el df submission\n",
    "    submission[str(model)] = clf.predict(XtestFinal).astype(int)\n",
    "\n",
    "# Identificamos cada columna del df con el nombre del metodo de predicción\n",
    "submission.columns = ['PassengerId','logreg', 'logreg_cv', 'rf', 'gboost']\n",
    "resultados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en general los resultados son bastante inestables. Por ejemplo, vemos que los resultados del método de Random Forest Classifier oscila entre el 69 y el 94% de aciertos según donde se haya hecho el corte de la cross validation. Aún así, este metodo es el que consigue de media un mayor numero de aciertos, llegando al 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los resultados predichos generados por el metodo Random Forest Classifier creamos un csv para comprobar su grado de acierto en Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "submission_rf['Survived'] =  submission.rf\n",
    "submission_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rf.to_csv(\"Submision_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un 0.79425 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id32'/>\n",
    "\n",
    "### [2. Combinación de modelos de regresión](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechamos para hacer también un combinado de los resultados de los 3 métodos con los mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['suma_mejores']=(np.round((submission.logreg+submission.logreg_cv + submission.rf)/3)).astype(int) \n",
    "submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_suma_mejores= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "submission_suma_mejores['Survived'] =  submission.suma_mejores\n",
    "submission_suma_mejores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_suma_mejores.to_csv(\"Submision_suma_mejores1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta predicción ha conseguido un 0.78947 en Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id33'/>\n",
    "\n",
    "### [3. Modelo de red neuronal](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion preparamos los datos para utilizar una red neuronal completamente conectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizamos por el max-min scaling para que los numeros dentro del rango [0,1]\n",
    "DF2 = (DF2 - DF2.min()) / (DF2.max() - DF2.min())\n",
    "DF2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training = DF2[DF2.Survived.notnull()]\n",
    "X=Training.loc[:, Training.columns != 'Survived']\n",
    "Y=Training.loc[:, Training.columns == 'Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.2)\n",
    "\n",
    "Testing = DF2[DF2.Survived.isna()]\n",
    "XtestFinal = Testing.loc[:, Testing.columns != 'Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de la red neuronal\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "# Modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Capa de entrada\n",
    "model.add(Dense(23, input_shape=(23,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Capas ocultas\n",
    "model.add(Dense(50))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "    \n",
    "# Capa de salida con funcion sigmoide que da un numero entre 0 y 1\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# learning\n",
    "model.fit(X_train, y_train, nb_epoch=400, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluamos ahora el metodo sobre todos los datos de los que conocemos la respuesta\n",
    "\n",
    "results = model.evaluate(X, Y, batch_size=30)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo hemos hecho correr varias veces hasta conseguir un resultado superior al 81%\n",
    "\n",
    "Seguimos entrenando el mismo metodo con los datos del test antes de mandarlo a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, nb_epoch=400, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un df para la entrega a Kaggle\n",
    "submission_NN= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "prediccion = model.predict(XtestFinal)\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobreviven = np.round(prediccion)\n",
    "arr = np.array(sobreviven)\n",
    "data=arr.flatten()\n",
    "submission_NN['Survived']=data\n",
    "submission_NN['Survived'] = submission_NN['Survived'].astype(int)\n",
    "submission_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN.to_csv(\"Submision_NN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un   0.80382  en Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratar de mejorar este resultado se crea una función específica. Esta funcion recoge la precision sobre los datos test en el *dataframe* contador para valorar si añadiendo una capa o aumentando o reduciendo el numero de neuronas y su activacion se pueden mejorar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_0(activacion, neurona, capa):\n",
    "    #print('dentro')\n",
    "    # Model \n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(23, input_shape=(23,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activacion))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    for x in range(capa):\n",
    "        # hidden layers\n",
    "        model.add(Dense(neurona))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activacion))\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "    \n",
    "    model.add(Dense(neurona, activation=\"relu\"))    \n",
    "           \n",
    "    # output layer\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # model compile for binary classification\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # learning\n",
    "    model.fit(X_train, y_train, nb_epoch=400, batch_size=30)\n",
    "    \n",
    "    \n",
    "    result = model.evaluate(X_test, y_test, batch_size=30)\n",
    "\n",
    "    #LO ENTRENAMOS CON TODOS LOS DATOS PARA SACAR LOS RESULTADOS FINALES\n",
    "    \n",
    "    model.fit(X, Y, nb_epoch=400, batch_size=30)\n",
    "    \n",
    "    sobreviven = np.round(model.predict(XtestFinal))\n",
    "    arr = np.array(sobreviven)\n",
    "    data=arr.flatten()\n",
    "\n",
    "    \n",
    "    return result,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contador2 = pd.DataFrame()\n",
    "\n",
    "submission_NN4= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "Activacion= [\"relu\",'sigmoid']\n",
    "\n",
    "Neuronas = [25, 50, 100] #,'300']\n",
    "\n",
    "Capas = [1, 2] #,4]\n",
    "\n",
    "\n",
    "\n",
    "for activacion in Activacion:\n",
    "    for neurona in Neuronas:\n",
    "        for capa in Capas:\n",
    "            \n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print (str(str(activacion)+', '+ str(neurona)+', '+str(capa)))\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "            print ('********************************************************************************************************************************************************************************')\n",
    "         \n",
    "            result,data = NN_0(activacion, neurona, capa)\n",
    "            Contador2[str(str(activacion)+', '+ str(neurona)+', '+str(capa))] = result\n",
    "            submission_NN4[str(str(activacion)+', '+ str(neurona)+', '+str(capa))]=data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Contador2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contador2=Contador2.sort_values(by=1, ascending=False, axis=1)\n",
    "Contador2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un df para la entrega a Kaggle\n",
    "submission_Best_NN_Original= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "arr = np.array(submission_NN4['sigmoid, 100, 2'])\n",
    "data=arr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_Best_NN_Original['Survived']= data\n",
    "submission_Best_NN_Original['Survived'] = submission_Best_NN_Original['Survived'].astype(int)\n",
    "submission_Best_NN_Original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_Best_NN_Original.to_csv((\"submission_Best_NN_Original2.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta prediccion ha conseguido un 0.78947 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id34'/>\n",
    "\n",
    "### [3.4. Combinación del modelo de red neuronal](#id00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se obtiene una combinación de los 6 resultados con redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN42= pd.DataFrame(data=DF[DF.Survived.isnull()].PassengerId)\n",
    "\n",
    "submission_NN42['Survived'] = (np.round((submission_NN4['sigmoid, 100, 2'] + submission_NN4['sigmoid, 25, 1'] + submission_NN4['sigmoid, 50, 1'] + submission_NN4['sigmoid, 50, 2'] + submission_NN4['relu, 25, 2'] + submission_NN4['sigmoid, 100, 1'])/6)).astype(int) \n",
    "submission_NN42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_NN42.to_csv((\"submission_sum_NN42.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esta predicción ha conseguido un 0.78947 en Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de muchos otros intentos no parece que ninguna estructura en la red neuronal pueda mejorar estos resultados.\n",
    "\n",
    "Entendemos que para seguir mejorando, deberíamos volver a modificar aspectos de la limpieza original de datos o crear nuevas combinaciones de elementos a partir de los ya existentes. \n",
    "\n",
    "Aun así, una predicción del 0.80382, que nos situa entre los 9% mejores de los 23000 participantes en este concurso de Kaggle nos parece bastante aceptable, de momento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
